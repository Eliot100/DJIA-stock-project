{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DJIA stock project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUQkKf_jq-p"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8X7Wvabnrfg"
      },
      "source": [
        "df_RedditNews = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/RedditNews.csv')\n",
        "df_DJIA = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/upload_DJIA_table.csv')\n",
        "df_Combined_News_DJIA = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/Combined_News_DJIA.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "08KB3HKENk3T",
        "outputId": "2af6d954-b431-4fa7-f41e-b3e5926ab737"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "df_DJIA2 = df_DJIA.copy()\n",
        "df_DJIA2[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']] = \\\n",
        "  scaler.fit_transform(df_DJIA2[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']])\n",
        "  \n",
        "df_DJIA2.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.940047</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>-0.778698</td>\n",
              "      <td>0.938290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-06-29</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-06-27</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date      Open      High       Low     Close    Volume  Adj Close\n",
              "0  2016-07-01  0.933579  0.940047  0.939734  0.938290 -0.778698   0.938290\n",
              "1  2016-06-30  0.897638  0.927717  0.904977  0.934995 -0.626052   0.934995\n",
              "2  2016-06-29  0.854005  0.888874  0.861634  0.894995 -0.706021   0.894995\n",
              "3  2016-06-28  0.808881  0.838231  0.816642  0.846554 -0.688587   0.846554\n",
              "4  2016-06-27  0.836872  0.828866  0.795049  0.800745 -0.608918   0.800745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXldyEiwMHFQ",
        "outputId": "7a460c3c-6433-4084-bbf5-44e84526afc7"
      },
      "source": [
        "df_Combined = df_DJIA2.copy()\n",
        "for i in range(0,59):\n",
        "  df_Combined[str(i+1)+\" day before Open\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before High\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Low\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Close\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Volume\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Adj Close\"] = \"\"\n",
        "\n",
        "for i in range(0,25):\n",
        "  df_Combined[\"Top\"+str(i+1)] = \"\"\n",
        "\n",
        "for j in range(0, df_DJIA2.shape[0]-59):\n",
        "  for i in range(0, 59):\n",
        "    df_Combined[str(i+1)+\" day before Open\"][j] = df_Combined[\"Open\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before High\"][j] = df_Combined[\"High\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Low\"][j] = df_Combined[\"Low\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Close\"][j] = df_Combined[\"Close\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Volume\"][j] = df_Combined[\"Volume\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Adj Close\"][j] = df_Combined[\"Adj Close\"][j+i+1]\n",
        "\n",
        "for i in range(0,25):\n",
        "  df_Combined[\"Top\"+str(i+1)] = \"\"\n",
        "\n",
        "for i in range(0, df_DJIA2.shape[0]):\n",
        "  News_Date_array = df_RedditNews[df_RedditNews[\"Date\"] == df_Combined[\"Date\"][i]][\"News\"].to_numpy()\n",
        "  for j in range(0, News_Date_array.shape[0]):\n",
        "    df_Combined[\"Top\"+str(j+1)][i] = News_Date_array[j]\n",
        "\n",
        "df_Combined = df_Combined[:-59]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "Te1WmkTyv64J",
        "outputId": "e5157822-46ce-45d5-94af-544001076b0c"
      },
      "source": [
        "df_Combined.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>1 day before Open</th>\n",
              "      <th>1 day before High</th>\n",
              "      <th>1 day before Low</th>\n",
              "      <th>1 day before Close</th>\n",
              "      <th>1 day before Volume</th>\n",
              "      <th>1 day before Adj Close</th>\n",
              "      <th>2 day before Open</th>\n",
              "      <th>2 day before High</th>\n",
              "      <th>2 day before Low</th>\n",
              "      <th>2 day before Close</th>\n",
              "      <th>2 day before Volume</th>\n",
              "      <th>2 day before Adj Close</th>\n",
              "      <th>3 day before Open</th>\n",
              "      <th>3 day before High</th>\n",
              "      <th>3 day before Low</th>\n",
              "      <th>3 day before Close</th>\n",
              "      <th>3 day before Volume</th>\n",
              "      <th>3 day before Adj Close</th>\n",
              "      <th>4 day before Open</th>\n",
              "      <th>4 day before High</th>\n",
              "      <th>4 day before Low</th>\n",
              "      <th>4 day before Close</th>\n",
              "      <th>4 day before Volume</th>\n",
              "      <th>4 day before Adj Close</th>\n",
              "      <th>5 day before Open</th>\n",
              "      <th>5 day before High</th>\n",
              "      <th>5 day before Low</th>\n",
              "      <th>5 day before Close</th>\n",
              "      <th>5 day before Volume</th>\n",
              "      <th>5 day before Adj Close</th>\n",
              "      <th>6 day before Open</th>\n",
              "      <th>6 day before High</th>\n",
              "      <th>6 day before Low</th>\n",
              "      <th>...</th>\n",
              "      <th>57 day before Close</th>\n",
              "      <th>57 day before Volume</th>\n",
              "      <th>57 day before Adj Close</th>\n",
              "      <th>58 day before Open</th>\n",
              "      <th>58 day before High</th>\n",
              "      <th>58 day before Low</th>\n",
              "      <th>58 day before Close</th>\n",
              "      <th>58 day before Volume</th>\n",
              "      <th>58 day before Adj Close</th>\n",
              "      <th>59 day before Open</th>\n",
              "      <th>59 day before High</th>\n",
              "      <th>59 day before Low</th>\n",
              "      <th>59 day before Close</th>\n",
              "      <th>59 day before Volume</th>\n",
              "      <th>59 day before Adj Close</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.940047</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>-0.778698</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>-0.782119</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>0.876177</td>\n",
              "      <td>0.893533</td>\n",
              "      <td>0.878559</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
              "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
              "      <td>The president of France says if Brexit won, so...</td>\n",
              "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
              "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
              "      <td>Brazil: Huge spike in number of police killing...</td>\n",
              "      <td>Austria's highest court annuls presidential el...</td>\n",
              "      <td>Facebook wins privacy case, can track any Belg...</td>\n",
              "      <td>Switzerland denies Muslim girls citizenship af...</td>\n",
              "      <td>China kills millions of innocent meditators fo...</td>\n",
              "      <td>France Cracks Down on Factory Farms - A viral ...</td>\n",
              "      <td>Abbas PLO Faction Calls Killer of 13-Year-Old ...</td>\n",
              "      <td>Taiwanese warship accidentally fires missile t...</td>\n",
              "      <td>Iran celebrates American Human Rights Week, mo...</td>\n",
              "      <td>U.N. panel moves to curb bias against L.G.B.T....</td>\n",
              "      <td>The United States has placed Myanmar, Uzbekist...</td>\n",
              "      <td>S&amp;amp;P revises European Union credit rating t...</td>\n",
              "      <td>India gets $1 billion loan from World Bank for...</td>\n",
              "      <td>U.S. sailors detained by Iran spoke too much u...</td>\n",
              "      <td>Mass fish kill in Vietnam solved as Taiwan ste...</td>\n",
              "      <td>Philippines president Rodrigo Duterte urges pe...</td>\n",
              "      <td>Spain arrests three Pakistanis accused of prom...</td>\n",
              "      <td>Venezuela, where anger over food shortages is ...</td>\n",
              "      <td>A Hindu temple worker has been killed by three...</td>\n",
              "      <td>Ozone layer hole seems to be healing - US &amp;amp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>0.918017</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>0.9149</td>\n",
              "      <td>...</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>0.893308</td>\n",
              "      <td>0.885914</td>\n",
              "      <td>0.866414</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>-0.754812</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
              "      <td>Stephen Hawking says pollution and 'stupidity'...</td>\n",
              "      <td>Boris Johnson says he will not run for Tory pa...</td>\n",
              "      <td>Six gay men in Ivory Coast were abused and for...</td>\n",
              "      <td>Switzerland denies citizenship to Muslim immig...</td>\n",
              "      <td>Palestinian terrorist stabs israeli teen girl ...</td>\n",
              "      <td>Puerto Rico will default on $1 billion of debt...</td>\n",
              "      <td>Republic of Ireland fans to be awarded medal f...</td>\n",
              "      <td>Afghan suicide bomber 'kills up to 40' - BBC News</td>\n",
              "      <td>US airstrikes kill at least 250 ISIS fighters ...</td>\n",
              "      <td>Turkish Cop Who Took Down Istanbul Gunman Hail...</td>\n",
              "      <td>Cannabis compounds could treat Alzheimer's by ...</td>\n",
              "      <td>Japan's top court has approved blanket surveil...</td>\n",
              "      <td>CIA Gave Romania Millions to Host Secret Prisons</td>\n",
              "      <td>Groups urge U.N. to suspend Saudi Arabia from ...</td>\n",
              "      <td>Googles free wifi at Indian railway stations i...</td>\n",
              "      <td>Mounting evidence suggests 'hobbits' were wipe...</td>\n",
              "      <td>The men who carried out Tuesday's terror attac...</td>\n",
              "      <td>Calls to suspend Saudi Arabia from UN Human Ri...</td>\n",
              "      <td>More Than 100 Nobel Laureates Call Out Greenpe...</td>\n",
              "      <td>British pedophile sentenced to 85 years in US ...</td>\n",
              "      <td>US permitted 1,200 offshore fracks in Gulf of ...</td>\n",
              "      <td>We will be swimming in ridicule - French beach...</td>\n",
              "      <td>UEFA says no minutes of silence for Istanbul v...</td>\n",
              "      <td>Law Enforcement Sources: Gun Used in Paris Ter...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 386 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  ...                                              Top25\n",
              "0  2016-07-01  ...  Ozone layer hole seems to be healing - US &amp...\n",
              "1  2016-06-30  ...  Law Enforcement Sources: Gun Used in Paris Ter...\n",
              "\n",
              "[2 rows x 386 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PPyrouheS8-",
        "outputId": "ee406018-38b2-4dfd-a832-4f8a337c6033"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sna = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgTom4oVeTCb",
        "outputId": "aa1f32c6-fa08-42fc-dc49-63422fa06415"
      },
      "source": [
        "df_Combined2 = df_Combined.copy()\n",
        "for i in range(0, df_Combined2.shape[0]):\n",
        "  News_Date_array = df_RedditNews[df_RedditNews[\"Date\"] == df_Combined2[\"Date\"][i]][\"News\"].to_numpy()\n",
        "\n",
        "  for j in range(0, 25):\n",
        "    df_Combined2[\"Top\"+str(j+1)][i] = sna.polarity_scores(df_Combined2[\"Top\"+str(j+1)][i])[\"compound\"]\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9Dxqnp3wAt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nos3er2mkS"
      },
      "source": [
        "df_final = df_Combined2.drop(['Date', 'High', 'Low', 'Volume', 'Adj Close'], axis=1)\n",
        "X_df = df_final.drop(['Close'], axis=1)\n",
        "Y_df = df_final['Close']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmyHXqsBHDNM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "a8a9bad3-11a6-48f8-8e02-70f8672883cf"
      },
      "source": [
        "df_final.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>1 day before Open</th>\n",
              "      <th>1 day before High</th>\n",
              "      <th>1 day before Low</th>\n",
              "      <th>1 day before Close</th>\n",
              "      <th>1 day before Volume</th>\n",
              "      <th>1 day before Adj Close</th>\n",
              "      <th>2 day before Open</th>\n",
              "      <th>2 day before High</th>\n",
              "      <th>2 day before Low</th>\n",
              "      <th>2 day before Close</th>\n",
              "      <th>2 day before Volume</th>\n",
              "      <th>2 day before Adj Close</th>\n",
              "      <th>3 day before Open</th>\n",
              "      <th>3 day before High</th>\n",
              "      <th>3 day before Low</th>\n",
              "      <th>3 day before Close</th>\n",
              "      <th>3 day before Volume</th>\n",
              "      <th>3 day before Adj Close</th>\n",
              "      <th>4 day before Open</th>\n",
              "      <th>4 day before High</th>\n",
              "      <th>4 day before Low</th>\n",
              "      <th>4 day before Close</th>\n",
              "      <th>4 day before Volume</th>\n",
              "      <th>4 day before Adj Close</th>\n",
              "      <th>5 day before Open</th>\n",
              "      <th>5 day before High</th>\n",
              "      <th>5 day before Low</th>\n",
              "      <th>5 day before Close</th>\n",
              "      <th>5 day before Volume</th>\n",
              "      <th>5 day before Adj Close</th>\n",
              "      <th>6 day before Open</th>\n",
              "      <th>6 day before High</th>\n",
              "      <th>6 day before Low</th>\n",
              "      <th>6 day before Close</th>\n",
              "      <th>6 day before Volume</th>\n",
              "      <th>6 day before Adj Close</th>\n",
              "      <th>7 day before Open</th>\n",
              "      <th>7 day before High</th>\n",
              "      <th>...</th>\n",
              "      <th>57 day before Close</th>\n",
              "      <th>57 day before Volume</th>\n",
              "      <th>57 day before Adj Close</th>\n",
              "      <th>58 day before Open</th>\n",
              "      <th>58 day before High</th>\n",
              "      <th>58 day before Low</th>\n",
              "      <th>58 day before Close</th>\n",
              "      <th>58 day before Volume</th>\n",
              "      <th>58 day before Adj Close</th>\n",
              "      <th>59 day before Open</th>\n",
              "      <th>59 day before High</th>\n",
              "      <th>59 day before Low</th>\n",
              "      <th>59 day before Close</th>\n",
              "      <th>59 day before Volume</th>\n",
              "      <th>59 day before Adj Close</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>0.918017</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>-0.782119</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>0.876177</td>\n",
              "      <td>0.893533</td>\n",
              "      <td>0.878559</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.5574</td>\n",
              "      <td>-0.0516</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>-0.8658</td>\n",
              "      <td>-0.296</td>\n",
              "      <td>-0.4404</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0.5612</td>\n",
              "      <td>-0.7351</td>\n",
              "      <td>-0.2732</td>\n",
              "      <td>-0.8402</td>\n",
              "      <td>-0.6486</td>\n",
              "      <td>-0.4767</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>-0.1027</td>\n",
              "      <td>-0.5859</td>\n",
              "      <td>0.3818</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.4019</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.9509</td>\n",
              "      <td>-0.3818</td>\n",
              "      <td>-0.9618</td>\n",
              "      <td>-0.9432</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>0.918017</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>0.9149</td>\n",
              "      <td>0.90964</td>\n",
              "      <td>-0.756853</td>\n",
              "      <td>0.90964</td>\n",
              "      <td>0.917109</td>\n",
              "      <td>0.918651</td>\n",
              "      <td>...</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>0.893308</td>\n",
              "      <td>0.885914</td>\n",
              "      <td>0.866414</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>-0.754812</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.4141</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>-0.8934</td>\n",
              "      <td>-0.6124</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>0.7003</td>\n",
              "      <td>-0.8402</td>\n",
              "      <td>-0.7096</td>\n",
              "      <td>0.6705</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>-0.5423</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.7579</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.9578</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.872</td>\n",
              "      <td>-0.5423</td>\n",
              "      <td>-0.875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 381 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Open     Close 1 day before Open  ...   Top23   Top24  Top25\n",
              "0  0.933579  0.938290          0.897638  ... -0.9618 -0.9432      0\n",
              "1  0.897638  0.934995          0.854005  ...  -0.872 -0.5423 -0.875\n",
              "\n",
              "[2 rows x 381 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jjkCDh51cOd"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df, Y_df, test_size=0.3, random_state=1)\n",
        "import tensorflow as tf"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQffrPhz3ZRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656e6ebf-b776-4b7e-9208-1b99e1b711ed"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0jZT19bZcfD"
      },
      "source": [
        "y_train = np.array(y_train,ndmin=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxjOxcZ21Ap6"
      },
      "source": [
        "features = x_train.shape[1]\n",
        "x = tf.placeholder(tf.float32, shape=[x_train.shape[0],x_train.shape[1]])\n",
        "y_ = tf.placeholder(tf.float32, shape=[y_train.shape[0],y_train.shape[1]])\n",
        "W = tf.Variable(tf.zeros([features,1]))\n",
        "b = tf.Variable(tf.zeros([1]))\n",
        "predict = tf.matmul(x,W) + b\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\n",
        "update = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
        "data_x = x_train.to_numpy()\n",
        "data_y = y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2anyebtU_LP"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGphoG1d_6q8"
      },
      "source": [
        "for i in range(0,5000):\n",
        "    sess.run(update, feed_dict = {x:data_x, y_:data_y})\n",
        "    # if i+1 % 10 == 0 :\n",
        "    #     print('Iteration:' , i+1 , ' W(1->5):' , sess.run(W[0:5]) , ' b:' , sess.run(b), ' loss:', loss.eval(session=sess, feed_dict = {x:data_x, y_:data_y}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeuQdHMBhS43"
      },
      "source": [
        "y_test = np.array(y_test, ndmin=2)\n",
        "x_test_p = tf.placeholder(tf.float32, shape=[None,x_test.shape[1]])\n",
        "y_test_p = tf.placeholder(tf.float32, shape=[None,y_test.shape[1]])\n",
        "predict = tf.matmul(x_test_p,W) + b\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_test_p, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhsXbLHrhS7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866bfa49-fa58-476e-9716-346736615f48"
      },
      "source": [
        "sess.run(loss, feed_dict = {x_test_p: x_test, y_test_p: y_test})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28245184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASRzbReOZBV3"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df, Y_df, test_size=0.3, random_state=1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy3NsGSLOU0i"
      },
      "source": [
        "train_size = x_train.shape[0]\n",
        "test_size = x_test.shape[0]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcwH3YPEc9RQ"
      },
      "source": [
        "# https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data\n",
        "def next_batch(num, data, labels):\n",
        "    data['y'] = labels\n",
        "    data = data.sample(num)\n",
        "    data_shuffle = data.sample(num)\n",
        "    labels_shuffle = np.array(data['y'], ndmin=2)\n",
        "    return np.asarray(data_shuffle), labels_shuffle.reshape((data.shape[0], 1))"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCQ7gkN3KoVJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc7uHRWYKorM"
      },
      "source": [
        "y_train = np.array(y_train,ndmin=2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX45HVuNSgIK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAo33rgzRctw"
      },
      "source": [
        "step_size = 0.01\n",
        "(hidden1_size, hidden2_size, hidden3_size, hidden4_size, hidden5_size) = (1228, 1228, 612, 1, 1 )"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5vzlppZRKzV",
        "outputId": "e11dc3a1-13f2-4128-f7b7-ecf0d5796f5f"
      },
      "source": [
        "minVal=-0.0001\n",
        "maxVal=0.0001\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, x_train.shape[1]])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W1 = tf.Variable(tf.random.uniform(shape=[x_train.shape[1], hidden1_size], minval=minVal, maxval=maxVal))\n",
        "b1 = tf.Variable(tf.random.uniform(shape=[hidden1_size], minval=minVal, maxval=maxVal))\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random.uniform([hidden1_size, hidden2_size], minval=minVal, maxval=maxVal))\n",
        "b2 = tf.Variable(tf.random.uniform(shape=[hidden2_size], minval=minVal, maxval=maxVal))\n",
        "z2 = tf.nn.relu(tf.matmul(z1,W2)+b2)\n",
        "\n",
        "W3 = tf.Variable(tf.random.uniform([hidden2_size, hidden3_size], minval=minVal, maxval=maxVal))\n",
        "b3 = tf.Variable(tf.random.uniform(shape=[hidden3_size], minval=minVal, maxval=maxVal))\n",
        "z3 = tf.nn.relu(tf.matmul(z2,W3)+b3)\n",
        "\n",
        "W4 = tf.Variable(tf.random.uniform([hidden3_size, hidden4_size], minval=minVal, maxval=maxVal))\n",
        "b4 = tf.Variable(tf.random.uniform(shape=[hidden4_size], minval=minVal, maxval=maxVal))\n",
        "z4 = tf.nn.relu(tf.matmul(z3,W4)+b4)\n",
        "\n",
        "W5 = tf.Variable(tf.random.uniform([hidden4_size, hidden5_size], minval=minVal, maxval=maxVal))\n",
        "b5 = tf.Variable(tf.random.uniform(shape=[hidden5_size], minval=minVal, maxval=maxVal))\n",
        "# z5 = tf.nn.relu(tf.matmul(z4,W5)+b5)\n",
        "\n",
        "# W6 = tf.Variable(tf.random.uniform([hidden5_size, 1], minval=minVal, maxval=maxVal))\n",
        "# b6 = tf.Variable(tf.random.uniform(shape=[1], minval=minVal, maxval=maxVal))\n",
        "\n",
        "predict = tf.matmul(z4,W5) + b5\n",
        "# predict = tf.matmul(z5,W6) + b6\n",
        "\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "batch_xn, batch_yn = next_batch(train_size, x_train, y_train)\n",
        "batch_xt, batch_yt = next_batch(test_size, x_test, y_test)\n",
        "sess.run(init)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h78yXovxc9VT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c012f8-ec51-4e41-fce4-19b91024f050"
      },
      "source": [
        "for i in range (10):\n",
        "    for _ in range(10):\n",
        "      sess.run(train_step, feed_dict={x: batch_xn, y_: batch_yn})\n",
        "    temp_loss = sess.run(loss, feed_dict={x: batch_xn, y_: batch_yn})\n",
        "    train_losses.append(temp_loss)\n",
        "    temp_loss = sess.run(loss, feed_dict={x: batch_xt, y_: batch_yt})\n",
        "    test_losses.append(temp_loss)\n",
        "    print('iter:', i+1,', loss:', temp_loss)"
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter: 1 , loss: 0.30149427\n",
            "iter: 2 , loss: 0.2941124\n",
            "iter: 3 , loss: 0.28937545\n",
            "iter: 4 , loss: 0.2863692\n",
            "iter: 5 , loss: 0.28448984\n",
            "iter: 6 , loss: 0.28333947\n",
            "iter: 7 , loss: 0.28265667\n",
            "iter: 8 , loss: 0.28227046\n",
            "iter: 9 , loss: 0.28206953\n",
            "iter: 10 , loss: 0.28198186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMqmSbKNq3jk"
      },
      "source": [
        "step_size = step_size/50\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psXg4_b8q6vk",
        "outputId": "5a508f99-ec10-4e56-b828-8b2f2e3a81d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range (20):\n",
        "    for _ in range(10):\n",
        "      sess.run(train_step, feed_dict={x: batch_xn, y_: batch_yn})\n",
        "    temp_loss = sess.run(loss, feed_dict={x: batch_xn, y_: batch_yn})\n",
        "    train_losses.append(temp_loss)\n",
        "    temp_loss = sess.run(loss, feed_dict={x: batch_xt, y_: batch_yt})\n",
        "    test_losses.append(temp_loss)\n",
        "    print('iter:', i+1,', loss:', temp_loss)"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter: 1 , loss: 0.2819809\n",
            "iter: 2 , loss: 0.28198\n",
            "iter: 3 , loss: 0.2819791\n",
            "iter: 4 , loss: 0.28197825\n",
            "iter: 5 , loss: 0.2819774\n",
            "iter: 6 , loss: 0.28197658\n",
            "iter: 7 , loss: 0.2819758\n",
            "iter: 8 , loss: 0.28197503\n",
            "iter: 9 , loss: 0.28197432\n",
            "iter: 10 , loss: 0.2819736\n",
            "iter: 11 , loss: 0.2819729\n",
            "iter: 12 , loss: 0.28197217\n",
            "iter: 13 , loss: 0.28197157\n",
            "iter: 14 , loss: 0.28197092\n",
            "iter: 15 , loss: 0.28197032\n",
            "iter: 16 , loss: 0.28196976\n",
            "iter: 17 , loss: 0.28196916\n",
            "iter: 18 , loss: 0.28196862\n",
            "iter: 19 , loss: 0.28196812\n",
            "iter: 20 , loss: 0.2819676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRsC5OC-SgLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d5619919-72e6-4874-de63-1d4b68015876"
      },
      "source": [
        "iter = np.arange(1,len(test_losses)+1)\n",
        "plt.title('Testing Mean Squerd Error minimization')\n",
        "plt.plot(iter, test_losses, label='Testing loss')\n",
        "plt.plot(iter, train_losses, label='Training loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Mean Squerd Error')\n",
        "plt.show()"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0uQG8nzLzN_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFYlKQKL5OB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8RIQ4WCL5KG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}