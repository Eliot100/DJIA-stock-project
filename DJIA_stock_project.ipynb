{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DJIA stock project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUQkKf_jq-p"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8X7Wvabnrfg"
      },
      "source": [
        "df_RedditNews = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/RedditNews.csv')\n",
        "df_DJIA = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/upload_DJIA_table.csv')\n",
        "df_Combined_News_DJIA = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/Combined_News_DJIA.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "08KB3HKENk3T",
        "outputId": "178f1558-6369-440a-d625-a6ab6c521483"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "df_DJIA2 = df_DJIA.copy()\n",
        "df_DJIA2[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']] = \\\n",
        "  scaler.fit_transform(df_DJIA2[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']])\n",
        "  \n",
        "df_DJIA2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.940047</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>-0.778698</td>\n",
              "      <td>0.938290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-06-29</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-06-27</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date      Open      High       Low     Close    Volume  Adj Close\n",
              "0  2016-07-01  0.933579  0.940047  0.939734  0.938290 -0.778698   0.938290\n",
              "1  2016-06-30  0.897638  0.927717  0.904977  0.934995 -0.626052   0.934995\n",
              "2  2016-06-29  0.854005  0.888874  0.861634  0.894995 -0.706021   0.894995\n",
              "3  2016-06-28  0.808881  0.838231  0.816642  0.846554 -0.688587   0.846554\n",
              "4  2016-06-27  0.836872  0.828866  0.795049  0.800745 -0.608918   0.800745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXldyEiwMHFQ",
        "outputId": "68a5eea1-fff6-4aa3-c918-c3fe3083f428"
      },
      "source": [
        "df_Combined = df_DJIA2.copy()\n",
        "for i in range(0,59):\n",
        "  df_Combined[str(i+1)+\" day before Open\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before High\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Low\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Close\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Volume\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Adj Close\"] = \"\"\n",
        "\n",
        "for i in range(0,25):\n",
        "  df_Combined[\"Top\"+str(i+1)] = \"\"\n",
        "\n",
        "for j in range(0, df_DJIA2.shape[0]-59):\n",
        "  for i in range(0, 59):\n",
        "    df_Combined[str(i+1)+\" day before Open\"][j] = df_Combined[\"Open\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before High\"][j] = df_Combined[\"High\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Low\"][j] = df_Combined[\"Low\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Close\"][j] = df_Combined[\"Close\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Volume\"][j] = df_Combined[\"Volume\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Adj Close\"][j] = df_Combined[\"Adj Close\"][j+i+1]\n",
        "\n",
        "for i in range(0,25):\n",
        "  df_Combined[\"Top\"+str(i+1)] = \"\"\n",
        "\n",
        "for i in range(0, df_DJIA2.shape[0]):\n",
        "  News_Date_array = df_RedditNews[df_RedditNews[\"Date\"] == df_Combined[\"Date\"][i]][\"News\"].to_numpy()\n",
        "  for j in range(0, News_Date_array.shape[0]):\n",
        "    df_Combined[\"Top\"+str(j+1)][i] = News_Date_array[j]\n",
        "\n",
        "df_Combined = df_Combined[:-59]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "Te1WmkTyv64J",
        "outputId": "e5157822-46ce-45d5-94af-544001076b0c"
      },
      "source": [
        "df_Combined.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>1 day before Open</th>\n",
              "      <th>1 day before High</th>\n",
              "      <th>1 day before Low</th>\n",
              "      <th>1 day before Close</th>\n",
              "      <th>1 day before Volume</th>\n",
              "      <th>1 day before Adj Close</th>\n",
              "      <th>2 day before Open</th>\n",
              "      <th>2 day before High</th>\n",
              "      <th>2 day before Low</th>\n",
              "      <th>2 day before Close</th>\n",
              "      <th>2 day before Volume</th>\n",
              "      <th>2 day before Adj Close</th>\n",
              "      <th>3 day before Open</th>\n",
              "      <th>3 day before High</th>\n",
              "      <th>3 day before Low</th>\n",
              "      <th>3 day before Close</th>\n",
              "      <th>3 day before Volume</th>\n",
              "      <th>3 day before Adj Close</th>\n",
              "      <th>4 day before Open</th>\n",
              "      <th>4 day before High</th>\n",
              "      <th>4 day before Low</th>\n",
              "      <th>4 day before Close</th>\n",
              "      <th>4 day before Volume</th>\n",
              "      <th>4 day before Adj Close</th>\n",
              "      <th>5 day before Open</th>\n",
              "      <th>5 day before High</th>\n",
              "      <th>5 day before Low</th>\n",
              "      <th>5 day before Close</th>\n",
              "      <th>5 day before Volume</th>\n",
              "      <th>5 day before Adj Close</th>\n",
              "      <th>6 day before Open</th>\n",
              "      <th>6 day before High</th>\n",
              "      <th>6 day before Low</th>\n",
              "      <th>...</th>\n",
              "      <th>57 day before Close</th>\n",
              "      <th>57 day before Volume</th>\n",
              "      <th>57 day before Adj Close</th>\n",
              "      <th>58 day before Open</th>\n",
              "      <th>58 day before High</th>\n",
              "      <th>58 day before Low</th>\n",
              "      <th>58 day before Close</th>\n",
              "      <th>58 day before Volume</th>\n",
              "      <th>58 day before Adj Close</th>\n",
              "      <th>59 day before Open</th>\n",
              "      <th>59 day before High</th>\n",
              "      <th>59 day before Low</th>\n",
              "      <th>59 day before Close</th>\n",
              "      <th>59 day before Volume</th>\n",
              "      <th>59 day before Adj Close</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.940047</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>-0.778698</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>-0.782119</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>0.876177</td>\n",
              "      <td>0.893533</td>\n",
              "      <td>0.878559</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
              "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
              "      <td>The president of France says if Brexit won, so...</td>\n",
              "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
              "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
              "      <td>Brazil: Huge spike in number of police killing...</td>\n",
              "      <td>Austria's highest court annuls presidential el...</td>\n",
              "      <td>Facebook wins privacy case, can track any Belg...</td>\n",
              "      <td>Switzerland denies Muslim girls citizenship af...</td>\n",
              "      <td>China kills millions of innocent meditators fo...</td>\n",
              "      <td>France Cracks Down on Factory Farms - A viral ...</td>\n",
              "      <td>Abbas PLO Faction Calls Killer of 13-Year-Old ...</td>\n",
              "      <td>Taiwanese warship accidentally fires missile t...</td>\n",
              "      <td>Iran celebrates American Human Rights Week, mo...</td>\n",
              "      <td>U.N. panel moves to curb bias against L.G.B.T....</td>\n",
              "      <td>The United States has placed Myanmar, Uzbekist...</td>\n",
              "      <td>S&amp;amp;P revises European Union credit rating t...</td>\n",
              "      <td>India gets $1 billion loan from World Bank for...</td>\n",
              "      <td>U.S. sailors detained by Iran spoke too much u...</td>\n",
              "      <td>Mass fish kill in Vietnam solved as Taiwan ste...</td>\n",
              "      <td>Philippines president Rodrigo Duterte urges pe...</td>\n",
              "      <td>Spain arrests three Pakistanis accused of prom...</td>\n",
              "      <td>Venezuela, where anger over food shortages is ...</td>\n",
              "      <td>A Hindu temple worker has been killed by three...</td>\n",
              "      <td>Ozone layer hole seems to be healing - US &amp;amp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>0.918017</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>0.9149</td>\n",
              "      <td>...</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>0.893308</td>\n",
              "      <td>0.885914</td>\n",
              "      <td>0.866414</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>-0.754812</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
              "      <td>Stephen Hawking says pollution and 'stupidity'...</td>\n",
              "      <td>Boris Johnson says he will not run for Tory pa...</td>\n",
              "      <td>Six gay men in Ivory Coast were abused and for...</td>\n",
              "      <td>Switzerland denies citizenship to Muslim immig...</td>\n",
              "      <td>Palestinian terrorist stabs israeli teen girl ...</td>\n",
              "      <td>Puerto Rico will default on $1 billion of debt...</td>\n",
              "      <td>Republic of Ireland fans to be awarded medal f...</td>\n",
              "      <td>Afghan suicide bomber 'kills up to 40' - BBC News</td>\n",
              "      <td>US airstrikes kill at least 250 ISIS fighters ...</td>\n",
              "      <td>Turkish Cop Who Took Down Istanbul Gunman Hail...</td>\n",
              "      <td>Cannabis compounds could treat Alzheimer's by ...</td>\n",
              "      <td>Japan's top court has approved blanket surveil...</td>\n",
              "      <td>CIA Gave Romania Millions to Host Secret Prisons</td>\n",
              "      <td>Groups urge U.N. to suspend Saudi Arabia from ...</td>\n",
              "      <td>Googles free wifi at Indian railway stations i...</td>\n",
              "      <td>Mounting evidence suggests 'hobbits' were wipe...</td>\n",
              "      <td>The men who carried out Tuesday's terror attac...</td>\n",
              "      <td>Calls to suspend Saudi Arabia from UN Human Ri...</td>\n",
              "      <td>More Than 100 Nobel Laureates Call Out Greenpe...</td>\n",
              "      <td>British pedophile sentenced to 85 years in US ...</td>\n",
              "      <td>US permitted 1,200 offshore fracks in Gulf of ...</td>\n",
              "      <td>We will be swimming in ridicule - French beach...</td>\n",
              "      <td>UEFA says no minutes of silence for Istanbul v...</td>\n",
              "      <td>Law Enforcement Sources: Gun Used in Paris Ter...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 386 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  ...                                              Top25\n",
              "0  2016-07-01  ...  Ozone layer hole seems to be healing - US &amp...\n",
              "1  2016-06-30  ...  Law Enforcement Sources: Gun Used in Paris Ter...\n",
              "\n",
              "[2 rows x 386 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PPyrouheS8-",
        "outputId": "cad43575-b472-4768-cd64-5969e00acb8f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sna = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgTom4oVeTCb",
        "outputId": "33a6aba2-2c6e-4c00-f12d-3ded46dd6a6f"
      },
      "source": [
        "df_Combined2 = df_Combined.copy()\n",
        "for i in range(0, df_Combined2.shape[0]):\n",
        "  News_Date_array = df_RedditNews[df_RedditNews[\"Date\"] == df_Combined2[\"Date\"][i]][\"News\"].to_numpy()\n",
        "\n",
        "  for j in range(0, 25):\n",
        "    df_Combined2[\"Top\"+str(j+1)][i] = sna.polarity_scores(df_Combined2[\"Top\"+str(j+1)][i])[\"compound\"]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9Dxqnp3wAt"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nos3er2mkS"
      },
      "source": [
        "df_final = df_Combined2.drop(['Date', 'High', 'Low', 'Volume', 'Adj Close'], axis=1)\n",
        "X_df = df_final.drop(['Close'], axis=1)\n",
        "Y_df = df_final['Close']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmyHXqsBHDNM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "732d7c0e-000d-4c25-b841-f326a745ae64"
      },
      "source": [
        "df_final.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>1 day before Open</th>\n",
              "      <th>1 day before High</th>\n",
              "      <th>1 day before Low</th>\n",
              "      <th>1 day before Close</th>\n",
              "      <th>1 day before Volume</th>\n",
              "      <th>1 day before Adj Close</th>\n",
              "      <th>2 day before Open</th>\n",
              "      <th>2 day before High</th>\n",
              "      <th>2 day before Low</th>\n",
              "      <th>2 day before Close</th>\n",
              "      <th>2 day before Volume</th>\n",
              "      <th>2 day before Adj Close</th>\n",
              "      <th>3 day before Open</th>\n",
              "      <th>3 day before High</th>\n",
              "      <th>3 day before Low</th>\n",
              "      <th>3 day before Close</th>\n",
              "      <th>3 day before Volume</th>\n",
              "      <th>3 day before Adj Close</th>\n",
              "      <th>4 day before Open</th>\n",
              "      <th>4 day before High</th>\n",
              "      <th>4 day before Low</th>\n",
              "      <th>4 day before Close</th>\n",
              "      <th>4 day before Volume</th>\n",
              "      <th>4 day before Adj Close</th>\n",
              "      <th>5 day before Open</th>\n",
              "      <th>5 day before High</th>\n",
              "      <th>5 day before Low</th>\n",
              "      <th>5 day before Close</th>\n",
              "      <th>5 day before Volume</th>\n",
              "      <th>5 day before Adj Close</th>\n",
              "      <th>6 day before Open</th>\n",
              "      <th>6 day before High</th>\n",
              "      <th>6 day before Low</th>\n",
              "      <th>6 day before Close</th>\n",
              "      <th>6 day before Volume</th>\n",
              "      <th>6 day before Adj Close</th>\n",
              "      <th>7 day before Open</th>\n",
              "      <th>7 day before High</th>\n",
              "      <th>...</th>\n",
              "      <th>57 day before Close</th>\n",
              "      <th>57 day before Volume</th>\n",
              "      <th>57 day before Adj Close</th>\n",
              "      <th>58 day before Open</th>\n",
              "      <th>58 day before High</th>\n",
              "      <th>58 day before Low</th>\n",
              "      <th>58 day before Close</th>\n",
              "      <th>58 day before Volume</th>\n",
              "      <th>58 day before Adj Close</th>\n",
              "      <th>59 day before Open</th>\n",
              "      <th>59 day before High</th>\n",
              "      <th>59 day before Low</th>\n",
              "      <th>59 day before Close</th>\n",
              "      <th>59 day before Volume</th>\n",
              "      <th>59 day before Adj Close</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>0.918017</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>-0.782119</td>\n",
              "      <td>0.899512</td>\n",
              "      <td>0.876177</td>\n",
              "      <td>0.893533</td>\n",
              "      <td>0.878559</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.5574</td>\n",
              "      <td>-0.0516</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>-0.8658</td>\n",
              "      <td>-0.296</td>\n",
              "      <td>-0.4404</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0.5612</td>\n",
              "      <td>-0.7351</td>\n",
              "      <td>-0.2732</td>\n",
              "      <td>-0.8402</td>\n",
              "      <td>-0.6486</td>\n",
              "      <td>-0.4767</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>-0.1027</td>\n",
              "      <td>-0.5859</td>\n",
              "      <td>0.3818</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.4019</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>-0.9509</td>\n",
              "      <td>-0.3818</td>\n",
              "      <td>-0.9618</td>\n",
              "      <td>-0.9432</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>-0.730957</td>\n",
              "      <td>0.948778</td>\n",
              "      <td>0.918017</td>\n",
              "      <td>0.925922</td>\n",
              "      <td>0.9149</td>\n",
              "      <td>0.90964</td>\n",
              "      <td>-0.756853</td>\n",
              "      <td>0.90964</td>\n",
              "      <td>0.917109</td>\n",
              "      <td>0.918651</td>\n",
              "      <td>...</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>-0.70386</td>\n",
              "      <td>0.87149</td>\n",
              "      <td>0.870893</td>\n",
              "      <td>0.887156</td>\n",
              "      <td>0.873858</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>-0.78521</td>\n",
              "      <td>0.874984</td>\n",
              "      <td>0.893308</td>\n",
              "      <td>0.885914</td>\n",
              "      <td>0.866414</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>-0.754812</td>\n",
              "      <td>0.869034</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.4141</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>-0.8934</td>\n",
              "      <td>-0.6124</td>\n",
              "      <td>-0.91</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>0.7003</td>\n",
              "      <td>-0.8402</td>\n",
              "      <td>-0.7096</td>\n",
              "      <td>0.6705</td>\n",
              "      <td>0.4019</td>\n",
              "      <td>-0.5423</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0.7351</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.7579</td>\n",
              "      <td>-0.3182</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.9578</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.872</td>\n",
              "      <td>-0.5423</td>\n",
              "      <td>-0.875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 381 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Open     Close 1 day before Open  ...   Top23   Top24  Top25\n",
              "0  0.933579  0.938290          0.897638  ... -0.9618 -0.9432      0\n",
              "1  0.897638  0.934995          0.854005  ...  -0.872 -0.5423 -0.875\n",
              "\n",
              "[2 rows x 381 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jjkCDh51cOd"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df, Y_df, test_size=0.3, random_state=1)\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQffrPhz3ZRU"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0jZT19bZcfD"
      },
      "source": [
        "y_train = np.array(y_train,ndmin=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxjOxcZ21Ap6"
      },
      "source": [
        "features = x_train.shape[1]\n",
        "x = tf.placeholder(tf.float32, shape=[x_train.shape[0],x_train.shape[1]])\n",
        "y_ = tf.placeholder(tf.float32, shape=[y_train.shape[0],y_train.shape[1]])\n",
        "W = tf.Variable(tf.zeros([features,1]))\n",
        "b = tf.Variable(tf.zeros([1]))\n",
        "predict = tf.matmul(x,W) + b\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\n",
        "update = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
        "data_x = x_train.to_numpy()\n",
        "data_y = y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2anyebtU_LP"
      },
      "source": [
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGphoG1d_6q8"
      },
      "source": [
        "for i in range(0,5000):\n",
        "    sess.run(update, feed_dict = {x:data_x, y_:data_y})\n",
        "    # if i+1 % 10 == 0 :\n",
        "    #     print('Iteration:' , i+1 , ' W(1->5):' , sess.run(W[0:5]) , ' b:' , sess.run(b), ' loss:', loss.eval(session=sess, feed_dict = {x:data_x, y_:data_y}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeuQdHMBhS43"
      },
      "source": [
        "y_test = np.array(y_test, ndmin=2)\n",
        "x_test_p = tf.placeholder(tf.float32, shape=[None,x_test.shape[1]])\n",
        "y_test_p = tf.placeholder(tf.float32, shape=[None,y_test.shape[1]])\n",
        "predict = tf.matmul(x_test_p,W) + b\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_test_p, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhsXbLHrhS7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d94cccc-e868-4582-ea9c-3b2f2c933f44"
      },
      "source": [
        "sess.run(loss, feed_dict = {x_test_p: x_test, y_test_p: y_test})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28245184"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdcsnU76hS_T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXWup-AohUDc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASRzbReOZBV3"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X_df, Y_df, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcwH3YPEc9RQ"
      },
      "source": [
        "# https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data\n",
        "def next_batch(num, data, labels):\n",
        "    data['y'] = labels\n",
        "    data = data.sample(num)\n",
        "    data_shuffle = data.sample(num)\n",
        "    labels_shuffle = np.array(data['y'], ndmin=2)\n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle).reshape((data.shape[0], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h78yXovxc9VT"
      },
      "source": [
        "batch_size = 579\n",
        "step_size = 0.001\n",
        "(hidden1_size, hidden2_size, hidden3_size, hidden4_size) = (248, 138, 24, 8)\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[batch_size, x_train.shape[1]])\n",
        "y_ = tf.placeholder(tf.float32, shape=[batch_size, 1])\n",
        "\n",
        "W1 = tf.Variable(tf.truncated_normal([x_train.shape[1], hidden1_size], stddev=0.1))\n",
        "b1 = tf.Variable(tf.constant(0.01, shape=[hidden1_size]))\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
        "\n",
        "# W2 = tf.Variable(tf.truncated_normal([hidden1_size, 1], stddev=0.1))\n",
        "# b2 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
        "W2 = tf.Variable(tf.truncated_normal([hidden1_size, hidden2_size], stddev=0.1))\n",
        "b2 = tf.Variable(tf.constant(0.1, shape=[hidden2_size]))\n",
        "z2 = tf.nn.relu(tf.matmul(z1,W2)+b2)\n",
        "\n",
        "# W3 = tf.Variable(tf.truncated_normal([hidden2_size, 1], stddev=0.1))\n",
        "# b3 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
        "W3 = tf.Variable(tf.truncated_normal([hidden2_size, hidden3_size], stddev=0.1))\n",
        "b3 = tf.Variable(tf.constant(0.01, shape=[hidden3_size]))\n",
        "z3 = tf.nn.relu(tf.matmul(z2,W3)+b3)\n",
        "\n",
        "# W4 = tf.Variable(tf.truncated_normal([hidden3_size, 1], stddev=0.1))\n",
        "# b4 = tf.Variable(tf.constant(0.01, shape=[1]))\n",
        "W4 = tf.Variable(tf.truncated_normal([hidden3_size, hidden4_size], stddev=0.1))\n",
        "b4 = tf.Variable(tf.constant(0.01, shape=[hidden4_size]))\n",
        "z4 = tf.nn.relu(tf.matmul(z3,W4)+b4)\n",
        "\n",
        "W5 = tf.Variable(tf.truncated_normal([hidden4_size, 1], stddev=0.1))\n",
        "b5 = tf.Variable(tf.constant(0.01, shape=[1]))\n",
        "\n",
        "predict = tf.matmul(z4,W5) + b5\n",
        "# predict = tf.matmul(z3,W4) + b4\n",
        "# predict = tf.matmul(z2,W3) + b3\n",
        "# predict = tf.matmul(z1,W2) + b2\n",
        "\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "train_losses = []\n",
        "sess.run(init)\n",
        "test_losses = []\n",
        "for i in range (100):\n",
        "    for _ in range(2000):\n",
        "      batch_xn, batch_yn = next_batch(batch_size, x_train, y_train)\n",
        "      sess.run(train_step, feed_dict={x: batch_xn, y_: batch_yn})\n",
        "    batch_xn, batch_yn = next_batch(batch_size, x_train, y_train)\n",
        "    temp_loss = sess.run(loss, feed_dict={x: batch_xn, y_: batch_yn})\n",
        "    train_losses.append(temp_loss)\n",
        "    batch_xt, batch_yt = next_batch(batch_size, x_test, y_test)\n",
        "    temp_loss = sess.run(loss, feed_dict={x: batch_xt, y_: batch_yt})\n",
        "    test_losses.append(temp_loss)\n",
        "    print('iter', i+1, temp_loss)\n",
        "    step_size *= 0.99"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX45HVuNSgIK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRsC5OC-SgLF"
      },
      "source": [
        "iter = np.arange(1,101)\n",
        "plt.title('Testing Mean Squerd Error minimization')\n",
        "plt.plot(iter, test_losses, label='Testing loss')\n",
        "plt.plot(iter, train_losses, label='Training loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Mean Squerd Error')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khlsn3AvSgOR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxXANjQ61vex"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0uQG8nzLzN_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HFYlKQKL5OB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8RIQ4WCL5KG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}