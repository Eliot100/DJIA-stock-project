{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_DJIA_stock_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjup7Ljx-7K5"
      },
      "source": [
        "# Welcome to our stock prediction notebook!\r\n",
        "# In this notebook we are trying to predict closing price of the DJIA stock using the last 59 stock data and the opening price of the day from Yahoo Finance, and also the top 25 rated news of the current day from Reddit WorldNews Channel.\r\n",
        "\r\n",
        "# The matirials for this project was taken from kaggle: https://www.kaggle.com/aaron7sun/stocknews?select=Combined_News_DJIA.csv\r\n",
        " \r\n",
        "# In the next cell we are importing the libraries that we using in this project to manipulate the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDUQkKf_jq-p"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGRslYvnEyaX"
      },
      "source": [
        "# In the next cell we importing the data from our github project: https://github.com/Eliot100/DJIA-stock-project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8X7Wvabnrfg"
      },
      "source": [
        "df_RedditNews = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/RedditNews.csv')\n",
        "df_DJIA = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/upload_DJIA_table.csv')\n",
        "df_Combined_News_DJIA = pd.read_csv('https://raw.githubusercontent.com/Eliot100/DJIA-stock-project/main/Combined_News_DJIA.csv')\n",
        "df_Combined_News_DJIA2 = pd.read_csv('https://raw.githubusercontent.com/ShreyamsJain/Stock-Price-Prediction-Model/master/Sentence_Polarity/combined_stock_data.csv')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "ZBvM_n26XPTb",
        "outputId": "94a5190e-afab-4ab2-e88a-44d0bd749b31"
      },
      "source": [
        "df_Combined_News_DJIA2.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>Label</th>\n",
              "      <th>Top1</th>\n",
              "      <th>Top2</th>\n",
              "      <th>Top3</th>\n",
              "      <th>Top4</th>\n",
              "      <th>Top5</th>\n",
              "      <th>Top6</th>\n",
              "      <th>Top7</th>\n",
              "      <th>Top8</th>\n",
              "      <th>Top9</th>\n",
              "      <th>Top10</th>\n",
              "      <th>Top11</th>\n",
              "      <th>Top12</th>\n",
              "      <th>Top13</th>\n",
              "      <th>Top14</th>\n",
              "      <th>Top15</th>\n",
              "      <th>Top16</th>\n",
              "      <th>Top17</th>\n",
              "      <th>Top18</th>\n",
              "      <th>Top19</th>\n",
              "      <th>Top20</th>\n",
              "      <th>Top21</th>\n",
              "      <th>Top22</th>\n",
              "      <th>Top23</th>\n",
              "      <th>Top24</th>\n",
              "      <th>Top25</th>\n",
              "      <th>Para</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Objectivity</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Negative</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-08-08</td>\n",
              "      <td>0</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
              "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
              "      <td>b'Russian tanks are moving towards the capital...</td>\n",
              "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
              "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
              "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
              "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
              "      <td>b'Georgian troops retreat from S. Osettain cap...</td>\n",
              "      <td>b'Did the U.S. Prep Georgia for War with Russia?'</td>\n",
              "      <td>b'Rice Gives Green Light for Israel to Attack ...</td>\n",
              "      <td>b'Announcing:Class Action Lawsuit on Behalf of...</td>\n",
              "      <td>b\"So---Russia and Georgia are at war and the N...</td>\n",
              "      <td>b\"China tells Bush to stay out of other countr...</td>\n",
              "      <td>b'Did World War III start today?'</td>\n",
              "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
              "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
              "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
              "      <td>b'This is a busy day:  The European Union has ...</td>\n",
              "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
              "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
              "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
              "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
              "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
              "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
              "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>56.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2008-08-11</td>\n",
              "      <td>1</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
              "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
              "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
              "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
              "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
              "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
              "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
              "      <td>b'Welcome To World War IV! Now In High Definit...</td>\n",
              "      <td>b\"Georgia's move, a mistake of monumental prop...</td>\n",
              "      <td>b'Russia presses deeper into Georgia; U.S. say...</td>\n",
              "      <td>b'Abhinav Bindra wins first ever Individual Ol...</td>\n",
              "      <td>b' U.S. ship heads for Arctic to define territ...</td>\n",
              "      <td>b'Drivers in a Jerusalem taxi station threaten...</td>\n",
              "      <td>b'The French Team is Stunned by Phelps and the...</td>\n",
              "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
              "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
              "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
              "      <td>b'China to overtake US as largest manufacturer'</td>\n",
              "      <td>b'War in South Ossetia [PICS]'</td>\n",
              "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
              "      <td>b' Russia has just beaten the United States ov...</td>\n",
              "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
              "      <td>b'Russia is so much better at war'</td>\n",
              "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
              "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
              "      <td>83.333333</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>41.666667</td>\n",
              "      <td>16.666667</td>\n",
              "      <td>41.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2008-08-12</td>\n",
              "      <td>0</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
              "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
              "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
              "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
              "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
              "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
              "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
              "      <td>b\"The US military was surprised by the timing ...</td>\n",
              "      <td>b'U.S. Beats War Drum as Iran Dumps the Dollar'</td>\n",
              "      <td>b'Gorbachev: \"Georgian military attacked the S...</td>\n",
              "      <td>b'CNN use footage of Tskhinvali ruins to cover...</td>\n",
              "      <td>b'Beginning a war as the Olympics were opening...</td>\n",
              "      <td>b'55 pyramids as large as the Luxor stacked in...</td>\n",
              "      <td>b'The 11 Top Party Cities in the World'</td>\n",
              "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
              "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
              "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
              "      <td>b'War in Georgia: The Israeli connection'</td>\n",
              "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
              "      <td>b'Christopher King argues that the US and NATO...</td>\n",
              "      <td>b'America: The New Mexico?'</td>\n",
              "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
              "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
              "      <td>56.250000</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>37.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2008-08-13</td>\n",
              "      <td>0</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
              "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
              "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
              "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
              "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
              "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
              "      <td>b'Russian forces sink Georgian ships '</td>\n",
              "      <td>b\"The commander of a Navy air reconnaissance s...</td>\n",
              "      <td>b\"92% of CNN readers: Russia's actions in Geor...</td>\n",
              "      <td>b'USA to send fleet into Black Sea to help Geo...</td>\n",
              "      <td>b\"US warns against Israeli plan to strike agai...</td>\n",
              "      <td>b\"In an intriguing cyberalliance, two Estonian...</td>\n",
              "      <td>b'The CNN Effect: Georgia Schools Russia in In...</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Elephants extinct by 2020?'</td>\n",
              "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
              "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
              "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
              "      <td>b'Israeli defence minister: US against strike ...</td>\n",
              "      <td>b'Gorbachev: We Had No Choice'</td>\n",
              "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
              "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
              "      <td>b'Georgian president  says US military will ta...</td>\n",
              "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
              "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
              "      <td>38.461538</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>15.384615</td>\n",
              "      <td>61.538462</td>\n",
              "      <td>23.076923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2008-08-14</td>\n",
              "      <td>1</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
              "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
              "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
              "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
              "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
              "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
              "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
              "      <td>b'Russia exaggerating South Ossetian death tol...</td>\n",
              "      <td>b' Musharraf expected to resign rather than fa...</td>\n",
              "      <td>b'Moscow Made Plans Months Ago to Invade Georgia'</td>\n",
              "      <td>b'Why Russias response to Georgia was right'</td>\n",
              "      <td>b'Nigeria has handed over the potentially oil-...</td>\n",
              "      <td>b'The US and Poland have agreed a preliminary ...</td>\n",
              "      <td>b'Russia apparently is sabotaging infrastructu...</td>\n",
              "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
              "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
              "      <td>b'War in the Caucasus is as much the product o...</td>\n",
              "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
              "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
              "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
              "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
              "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
              "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
              "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
              "      <td>b'All the experts admit that we should legalis...</td>\n",
              "      <td>45.454545</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>36.363636</td>\n",
              "      <td>54.545455</td>\n",
              "      <td>9.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        Date  Label  ...   Positive    Neutral   Negative\n",
              "0           0  2008-08-08      0  ...  18.750000  25.000000  56.250000\n",
              "1           1  2008-08-11      1  ...  41.666667  16.666667  41.666667\n",
              "2           2  2008-08-12      0  ...  18.750000  43.750000  37.500000\n",
              "3           3  2008-08-13      0  ...  15.384615  61.538462  23.076923\n",
              "4           4  2008-08-14      1  ...  36.363636  54.545455   9.090909\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7xkbxFTGz5g"
      },
      "source": [
        "# In the cell below we copying the stock data, and normalize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "08KB3HKENk3T",
        "outputId": "e8bdc393-2072-4b58-a098-37e575fa0da2"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "df_DJIA2 = df_DJIA.copy()\n",
        "df_DJIA2[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']] = \\\n",
        "  scaler.fit_transform(df_DJIA2[['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']])\n",
        "  \n",
        "df_DJIA2.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.940047</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>-0.778698</td>\n",
              "      <td>0.938290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-06-29</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-06-28</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-06-27</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date      Open      High       Low     Close    Volume  Adj Close\n",
              "0  2016-07-01  0.933579  0.940047  0.939734  0.938290 -0.778698   0.938290\n",
              "1  2016-06-30  0.897638  0.927717  0.904977  0.934995 -0.626052   0.934995\n",
              "2  2016-06-29  0.854005  0.888874  0.861634  0.894995 -0.706021   0.894995\n",
              "3  2016-06-28  0.808881  0.838231  0.816642  0.846554 -0.688587   0.846554\n",
              "4  2016-06-27  0.836872  0.828866  0.795049  0.800745 -0.608918   0.800745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BZ2PUhzHssd"
      },
      "source": [
        "# In the cell below we recognize the data. Every line contains stock data of 60 days in a row, the date of the stock data last day and top 25 rated news this day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiVtx0IjaAY5"
      },
      "source": [
        "num_day_before = 30"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXldyEiwMHFQ",
        "outputId": "118ad70d-2474-497e-8803-eb9a143de359"
      },
      "source": [
        "df_Combined = df_DJIA2.copy()\n",
        "for i in range(0,num_day_before):\n",
        "  df_Combined[str(i+1)+\" day before Open\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before High\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Low\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Close\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Volume\"] = \"\"\n",
        "  df_Combined[str(i+1)+\" day before Adj Close\"] = \"\"\n",
        "\n",
        "# for i in range(0,25):\n",
        "#   df_Combined[\"Top\"+str(i+1)] = \"\"\n",
        "\n",
        "for j in range(0, df_DJIA2.shape[0]-num_day_before):\n",
        "  for i in range(0, num_day_before):\n",
        "    df_Combined[str(i+1)+\" day before Open\"][j] = df_Combined[\"Open\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before High\"][j] = df_Combined[\"High\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Low\"][j] = df_Combined[\"Low\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Close\"][j] = df_Combined[\"Close\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Volume\"][j] = df_Combined[\"Volume\"][j+i+1]\n",
        "    df_Combined[str(i+1)+\" day before Adj Close\"][j] = df_Combined[\"Adj Close\"][j+i+1]\n",
        "\n",
        "# for i in range(0,25):\n",
        "#   df_Combined[\"Top\"+str(i+1)] = \"\"\n",
        "\n",
        "# for i in range(0, df_DJIA2.shape[0]):\n",
        "#   News_Date_array = df_RedditNews[df_RedditNews[\"Date\"] == df_Combined[\"Date\"][i]][\"News\"].to_numpy()\n",
        "#   for j in range(0, News_Date_array.shape[0]):\n",
        "#     df_Combined[\"Top\"+str(j+1)][i] = News_Date_array[j]\n",
        "\n",
        "df_Combined = df_Combined[:-num_day_before]\n",
        "    \n",
        "merged_dataframe = df_Combined_News_DJIA2[['Date', 'Label', 'Subjectivity', 'Objectivity', 'Positive', 'Negative', 'Neutral']].merge(df_Combined, how='inner', on='Date', left_index=True)\n",
        "#Subjectivity\tObjectivity\tPositive\tNeutral\tNegative\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Te1WmkTyv64J",
        "outputId": "71c62f2b-b56b-4d5f-8728-eab1483d9305"
      },
      "source": [
        "merged_dataframe.head(2)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Label</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Objectivity</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>1 day before Open</th>\n",
              "      <th>1 day before High</th>\n",
              "      <th>1 day before Low</th>\n",
              "      <th>1 day before Close</th>\n",
              "      <th>1 day before Volume</th>\n",
              "      <th>1 day before Adj Close</th>\n",
              "      <th>2 day before Open</th>\n",
              "      <th>2 day before High</th>\n",
              "      <th>2 day before Low</th>\n",
              "      <th>2 day before Close</th>\n",
              "      <th>2 day before Volume</th>\n",
              "      <th>2 day before Adj Close</th>\n",
              "      <th>3 day before Open</th>\n",
              "      <th>3 day before High</th>\n",
              "      <th>3 day before Low</th>\n",
              "      <th>3 day before Close</th>\n",
              "      <th>3 day before Volume</th>\n",
              "      <th>3 day before Adj Close</th>\n",
              "      <th>4 day before Open</th>\n",
              "      <th>4 day before High</th>\n",
              "      <th>4 day before Low</th>\n",
              "      <th>4 day before Close</th>\n",
              "      <th>4 day before Volume</th>\n",
              "      <th>4 day before Adj Close</th>\n",
              "      <th>5 day before Open</th>\n",
              "      <th>5 day before High</th>\n",
              "      <th>5 day before Low</th>\n",
              "      <th>...</th>\n",
              "      <th>24 day before Low</th>\n",
              "      <th>24 day before Close</th>\n",
              "      <th>24 day before Volume</th>\n",
              "      <th>24 day before Adj Close</th>\n",
              "      <th>25 day before Open</th>\n",
              "      <th>25 day before High</th>\n",
              "      <th>25 day before Low</th>\n",
              "      <th>25 day before Close</th>\n",
              "      <th>25 day before Volume</th>\n",
              "      <th>25 day before Adj Close</th>\n",
              "      <th>26 day before Open</th>\n",
              "      <th>26 day before High</th>\n",
              "      <th>26 day before Low</th>\n",
              "      <th>26 day before Close</th>\n",
              "      <th>26 day before Volume</th>\n",
              "      <th>26 day before Adj Close</th>\n",
              "      <th>27 day before Open</th>\n",
              "      <th>27 day before High</th>\n",
              "      <th>27 day before Low</th>\n",
              "      <th>27 day before Close</th>\n",
              "      <th>27 day before Volume</th>\n",
              "      <th>27 day before Adj Close</th>\n",
              "      <th>28 day before Open</th>\n",
              "      <th>28 day before High</th>\n",
              "      <th>28 day before Low</th>\n",
              "      <th>28 day before Close</th>\n",
              "      <th>28 day before Volume</th>\n",
              "      <th>28 day before Adj Close</th>\n",
              "      <th>29 day before Open</th>\n",
              "      <th>29 day before High</th>\n",
              "      <th>29 day before Low</th>\n",
              "      <th>29 day before Close</th>\n",
              "      <th>29 day before Volume</th>\n",
              "      <th>29 day before Adj Close</th>\n",
              "      <th>30 day before Open</th>\n",
              "      <th>30 day before High</th>\n",
              "      <th>30 day before Low</th>\n",
              "      <th>30 day before Close</th>\n",
              "      <th>30 day before Volume</th>\n",
              "      <th>30 day before Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>2008-09-22</td>\n",
              "      <td>0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>-0.176175</td>\n",
              "      <td>-0.195143</td>\n",
              "      <td>-0.233686</td>\n",
              "      <td>-0.240372</td>\n",
              "      <td>-0.385456</td>\n",
              "      <td>-0.240372</td>\n",
              "      <td>-0.238531</td>\n",
              "      <td>-0.179945</td>\n",
              "      <td>-0.22784</td>\n",
              "      <td>-0.177008</td>\n",
              "      <td>0.940556</td>\n",
              "      <td>-0.177008</td>\n",
              "      <td>-0.309656</td>\n",
              "      <td>-0.249798</td>\n",
              "      <td>-0.323965</td>\n",
              "      <td>-0.239692</td>\n",
              "      <td>0.439288</td>\n",
              "      <td>-0.239692</td>\n",
              "      <td>-0.233591</td>\n",
              "      <td>-0.253085</td>\n",
              "      <td>-0.300841</td>\n",
              "      <td>-0.309394</td>\n",
              "      <td>0.364691</td>\n",
              "      <td>-0.309394</td>\n",
              "      <td>-0.259247</td>\n",
              "      <td>-0.246916</td>\n",
              "      <td>-0.275965</td>\n",
              "      <td>-0.233007</td>\n",
              "      <td>0.459393</td>\n",
              "      <td>-0.233007</td>\n",
              "      <td>-0.172444</td>\n",
              "      <td>-0.191386</td>\n",
              "      <td>-0.246343</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.158801</td>\n",
              "      <td>-0.161547</td>\n",
              "      <td>-0.556256</td>\n",
              "      <td>-0.161547</td>\n",
              "      <td>-0.139331</td>\n",
              "      <td>-0.140975</td>\n",
              "      <td>-0.130738</td>\n",
              "      <td>-0.130862</td>\n",
              "      <td>-0.379964</td>\n",
              "      <td>-0.130862</td>\n",
              "      <td>-0.152781</td>\n",
              "      <td>-0.139533</td>\n",
              "      <td>-0.15596</td>\n",
              "      <td>-0.138337</td>\n",
              "      <td>-0.545753</td>\n",
              "      <td>-0.138337</td>\n",
              "      <td>-0.13566</td>\n",
              "      <td>-0.15405</td>\n",
              "      <td>-0.155544</td>\n",
              "      <td>-0.152441</td>\n",
              "      <td>-0.477457</td>\n",
              "      <td>-0.152441</td>\n",
              "      <td>-0.110356</td>\n",
              "      <td>-0.128526</td>\n",
              "      <td>-0.130435</td>\n",
              "      <td>-0.133825</td>\n",
              "      <td>-0.504344</td>\n",
              "      <td>-0.133825</td>\n",
              "      <td>-0.119198</td>\n",
              "      <td>-0.113965</td>\n",
              "      <td>-0.117893</td>\n",
              "      <td>-0.110047</td>\n",
              "      <td>-0.475537</td>\n",
              "      <td>-0.110047</td>\n",
              "      <td>-0.169772</td>\n",
              "      <td>-0.132373</td>\n",
              "      <td>-0.16661</td>\n",
              "      <td>-0.118212</td>\n",
              "      <td>-0.386596</td>\n",
              "      <td>-0.118212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1957</th>\n",
              "      <td>2008-09-23</td>\n",
              "      <td>0</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>66.666667</td>\n",
              "      <td>-0.240540</td>\n",
              "      <td>-0.238328</td>\n",
              "      <td>-0.260504</td>\n",
              "      <td>-0.267829</td>\n",
              "      <td>-0.411652</td>\n",
              "      <td>-0.267829</td>\n",
              "      <td>-0.176175</td>\n",
              "      <td>-0.195143</td>\n",
              "      <td>-0.233686</td>\n",
              "      <td>-0.240372</td>\n",
              "      <td>-0.385456</td>\n",
              "      <td>-0.240372</td>\n",
              "      <td>-0.238531</td>\n",
              "      <td>-0.179945</td>\n",
              "      <td>-0.22784</td>\n",
              "      <td>-0.177008</td>\n",
              "      <td>0.940556</td>\n",
              "      <td>-0.177008</td>\n",
              "      <td>-0.309656</td>\n",
              "      <td>-0.249798</td>\n",
              "      <td>-0.323965</td>\n",
              "      <td>-0.239692</td>\n",
              "      <td>0.439288</td>\n",
              "      <td>-0.239692</td>\n",
              "      <td>-0.233591</td>\n",
              "      <td>-0.253085</td>\n",
              "      <td>-0.300841</td>\n",
              "      <td>-0.309394</td>\n",
              "      <td>0.364691</td>\n",
              "      <td>-0.309394</td>\n",
              "      <td>-0.259247</td>\n",
              "      <td>-0.246916</td>\n",
              "      <td>-0.275965</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.178394</td>\n",
              "      <td>-0.183789</td>\n",
              "      <td>-0.510375</td>\n",
              "      <td>-0.183789</td>\n",
              "      <td>-0.131098</td>\n",
              "      <td>-0.144318</td>\n",
              "      <td>-0.158801</td>\n",
              "      <td>-0.161547</td>\n",
              "      <td>-0.556256</td>\n",
              "      <td>-0.161547</td>\n",
              "      <td>-0.139331</td>\n",
              "      <td>-0.140975</td>\n",
              "      <td>-0.130738</td>\n",
              "      <td>-0.130862</td>\n",
              "      <td>-0.379964</td>\n",
              "      <td>-0.130862</td>\n",
              "      <td>-0.152781</td>\n",
              "      <td>-0.139533</td>\n",
              "      <td>-0.15596</td>\n",
              "      <td>-0.138337</td>\n",
              "      <td>-0.545753</td>\n",
              "      <td>-0.138337</td>\n",
              "      <td>-0.13566</td>\n",
              "      <td>-0.15405</td>\n",
              "      <td>-0.155544</td>\n",
              "      <td>-0.152441</td>\n",
              "      <td>-0.477457</td>\n",
              "      <td>-0.152441</td>\n",
              "      <td>-0.110356</td>\n",
              "      <td>-0.128526</td>\n",
              "      <td>-0.130435</td>\n",
              "      <td>-0.133825</td>\n",
              "      <td>-0.504344</td>\n",
              "      <td>-0.133825</td>\n",
              "      <td>-0.119198</td>\n",
              "      <td>-0.113965</td>\n",
              "      <td>-0.117893</td>\n",
              "      <td>-0.110047</td>\n",
              "      <td>-0.475537</td>\n",
              "      <td>-0.110047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  Label  ...  30 day before Volume  30 day before Adj Close\n",
              "1958  2008-09-22      0  ...             -0.386596                -0.118212\n",
              "1957  2008-09-23      0  ...             -0.475537                -0.110047\n",
              "\n",
              "[2 rows x 193 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "hvaHZs7AaRDy",
        "outputId": "5d59d397-bb15-4a74-c289-896c97bdf2c7"
      },
      "source": [
        "merged_dataframe.tail(2)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Label</th>\n",
              "      <th>Subjectivity</th>\n",
              "      <th>Objectivity</th>\n",
              "      <th>Positive</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Neutral</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>1 day before Open</th>\n",
              "      <th>1 day before High</th>\n",
              "      <th>1 day before Low</th>\n",
              "      <th>1 day before Close</th>\n",
              "      <th>1 day before Volume</th>\n",
              "      <th>1 day before Adj Close</th>\n",
              "      <th>2 day before Open</th>\n",
              "      <th>2 day before High</th>\n",
              "      <th>2 day before Low</th>\n",
              "      <th>2 day before Close</th>\n",
              "      <th>2 day before Volume</th>\n",
              "      <th>2 day before Adj Close</th>\n",
              "      <th>3 day before Open</th>\n",
              "      <th>3 day before High</th>\n",
              "      <th>3 day before Low</th>\n",
              "      <th>3 day before Close</th>\n",
              "      <th>3 day before Volume</th>\n",
              "      <th>3 day before Adj Close</th>\n",
              "      <th>4 day before Open</th>\n",
              "      <th>4 day before High</th>\n",
              "      <th>4 day before Low</th>\n",
              "      <th>4 day before Close</th>\n",
              "      <th>4 day before Volume</th>\n",
              "      <th>4 day before Adj Close</th>\n",
              "      <th>5 day before Open</th>\n",
              "      <th>5 day before High</th>\n",
              "      <th>5 day before Low</th>\n",
              "      <th>...</th>\n",
              "      <th>24 day before Low</th>\n",
              "      <th>24 day before Close</th>\n",
              "      <th>24 day before Volume</th>\n",
              "      <th>24 day before Adj Close</th>\n",
              "      <th>25 day before Open</th>\n",
              "      <th>25 day before High</th>\n",
              "      <th>25 day before Low</th>\n",
              "      <th>25 day before Close</th>\n",
              "      <th>25 day before Volume</th>\n",
              "      <th>25 day before Adj Close</th>\n",
              "      <th>26 day before Open</th>\n",
              "      <th>26 day before High</th>\n",
              "      <th>26 day before Low</th>\n",
              "      <th>26 day before Close</th>\n",
              "      <th>26 day before Volume</th>\n",
              "      <th>26 day before Adj Close</th>\n",
              "      <th>27 day before Open</th>\n",
              "      <th>27 day before High</th>\n",
              "      <th>27 day before Low</th>\n",
              "      <th>27 day before Close</th>\n",
              "      <th>27 day before Volume</th>\n",
              "      <th>27 day before Adj Close</th>\n",
              "      <th>28 day before Open</th>\n",
              "      <th>28 day before High</th>\n",
              "      <th>28 day before Low</th>\n",
              "      <th>28 day before Close</th>\n",
              "      <th>28 day before Volume</th>\n",
              "      <th>28 day before Adj Close</th>\n",
              "      <th>29 day before Open</th>\n",
              "      <th>29 day before High</th>\n",
              "      <th>29 day before Low</th>\n",
              "      <th>29 day before Close</th>\n",
              "      <th>29 day before Volume</th>\n",
              "      <th>29 day before Adj Close</th>\n",
              "      <th>30 day before Open</th>\n",
              "      <th>30 day before High</th>\n",
              "      <th>30 day before Low</th>\n",
              "      <th>30 day before Close</th>\n",
              "      <th>30 day before Volume</th>\n",
              "      <th>30 day before Adj Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-06-30</td>\n",
              "      <td>1</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>-0.308067</td>\n",
              "      <td>0.845029</td>\n",
              "      <td>0.919961</td>\n",
              "      <td>0.94154</td>\n",
              "      <td>0.927397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.92057</td>\n",
              "      <td>0.917707</td>\n",
              "      <td>-0.818367</td>\n",
              "      <td>0.917707</td>\n",
              "      <td>0.901433</td>\n",
              "      <td>0.921034</td>\n",
              "      <td>0.908923</td>\n",
              "      <td>0.921654</td>\n",
              "      <td>-0.78764</td>\n",
              "      <td>0.921654</td>\n",
              "      <td>0.86576</td>\n",
              "      <td>0.895416</td>\n",
              "      <td>0.873355</td>\n",
              "      <td>0.896928</td>\n",
              "      <td>-0.765735</td>\n",
              "      <td>0.896928</td>\n",
              "      <td>0.862675</td>\n",
              "      <td>0.86245</td>\n",
              "      <td>0.865706</td>\n",
              "      <td>0.860699</td>\n",
              "      <td>-0.761804</td>\n",
              "      <td>0.860699</td>\n",
              "      <td>0.850827</td>\n",
              "      <td>0.866067</td>\n",
              "      <td>0.858465</td>\n",
              "      <td>0.862061</td>\n",
              "      <td>-0.689187</td>\n",
              "      <td>0.862061</td>\n",
              "      <td>0.863886</td>\n",
              "      <td>0.856173</td>\n",
              "      <td>0.840461</td>\n",
              "      <td>0.85092</td>\n",
              "      <td>-0.738579</td>\n",
              "      <td>0.85092</td>\n",
              "      <td>0.861697</td>\n",
              "      <td>0.877142</td>\n",
              "      <td>0.855227</td>\n",
              "      <td>0.866426</td>\n",
              "      <td>-0.78782</td>\n",
              "      <td>0.866426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-07-01</td>\n",
              "      <td>1</td>\n",
              "      <td>60.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.933579</td>\n",
              "      <td>0.940047</td>\n",
              "      <td>0.939734</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>-0.778698</td>\n",
              "      <td>0.938290</td>\n",
              "      <td>0.897638</td>\n",
              "      <td>0.927717</td>\n",
              "      <td>0.904977</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>-0.626052</td>\n",
              "      <td>0.934995</td>\n",
              "      <td>0.854005</td>\n",
              "      <td>0.888874</td>\n",
              "      <td>0.861634</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>-0.706021</td>\n",
              "      <td>0.894995</td>\n",
              "      <td>0.808881</td>\n",
              "      <td>0.838231</td>\n",
              "      <td>0.816642</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>-0.688587</td>\n",
              "      <td>0.846554</td>\n",
              "      <td>0.836872</td>\n",
              "      <td>0.828866</td>\n",
              "      <td>0.795049</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>-0.608918</td>\n",
              "      <td>0.800745</td>\n",
              "      <td>0.937385</td>\n",
              "      <td>0.930469</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924113</td>\n",
              "      <td>0.925345</td>\n",
              "      <td>-0.805614</td>\n",
              "      <td>0.925345</td>\n",
              "      <td>0.92258</td>\n",
              "      <td>0.92051</td>\n",
              "      <td>0.92057</td>\n",
              "      <td>0.917707</td>\n",
              "      <td>-0.818367</td>\n",
              "      <td>0.917707</td>\n",
              "      <td>0.901433</td>\n",
              "      <td>0.921034</td>\n",
              "      <td>0.908923</td>\n",
              "      <td>0.921654</td>\n",
              "      <td>-0.78764</td>\n",
              "      <td>0.921654</td>\n",
              "      <td>0.86576</td>\n",
              "      <td>0.895416</td>\n",
              "      <td>0.873355</td>\n",
              "      <td>0.896928</td>\n",
              "      <td>-0.765735</td>\n",
              "      <td>0.896928</td>\n",
              "      <td>0.862675</td>\n",
              "      <td>0.86245</td>\n",
              "      <td>0.865706</td>\n",
              "      <td>0.860699</td>\n",
              "      <td>-0.761804</td>\n",
              "      <td>0.860699</td>\n",
              "      <td>0.850827</td>\n",
              "      <td>0.866067</td>\n",
              "      <td>0.858465</td>\n",
              "      <td>0.862061</td>\n",
              "      <td>-0.689187</td>\n",
              "      <td>0.862061</td>\n",
              "      <td>0.863886</td>\n",
              "      <td>0.856173</td>\n",
              "      <td>0.840461</td>\n",
              "      <td>0.85092</td>\n",
              "      <td>-0.738579</td>\n",
              "      <td>0.85092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  Label  ...  30 day before Volume  30 day before Adj Close\n",
              "1  2016-06-30      1  ...              -0.78782                 0.866426\n",
              "0  2016-07-01      1  ...             -0.738579                  0.85092\n",
              "\n",
              "[2 rows x 193 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdD8OLuheJKq"
      },
      "source": [
        "merged_final = merged_dataframe.dropna()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7u_Iy9Rb3d2"
      },
      "source": [
        "df_train = merged_final[merged_final['Date'] <= '20150101']\r\n",
        "df_test = merged_final[merged_final['Date']  > '20150101']\r\n",
        "\r\n",
        "X_train = df_train.drop(['Date', 'High', 'Low', 'Volume', 'Adj Close', 'Label'], axis=1)\r\n",
        "Y_train = df_train['Close']\r\n",
        "\r\n",
        "X_test = df_test.drop(['Date', 'High', 'Low', 'Volume', 'Adj Close', 'Label'], axis=1)\r\n",
        "Y_test = df_test['Close']\r\n",
        "Open_test = df_test['Open']\r\n",
        "Dates = df_test.Date"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryx-6f8xWl5J"
      },
      "source": [
        "X_train = X_train.to_numpy() # converting to numpy array\r\n",
        "X_test = X_test.to_numpy()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0RkQc14VyMp"
      },
      "source": [
        "trainX = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\r\n",
        "testX = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dN8MWOrcguk"
      },
      "source": [
        ""
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPhtmW2cgyS"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers, Sequential\r\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\r\n",
        "from keras.layers.core import Dense, Activation, Dropout"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14bMCRKjUhas"
      },
      "source": [
        "model = Sequential()\r\n",
        " \r\n",
        "model.add(LSTM( input_shape=(None, 187),  units=100,  return_sequences=True))\r\n",
        "model.add(Dropout(0.2))\r\n",
        " \r\n",
        "model.add(LSTM(100, return_sequences=False))\r\n",
        "# model.add(Dropout(0.2))\r\n",
        "model.add(Activation('linear'))\r\n",
        " \r\n",
        "model.add(Dense( units=1))\r\n",
        "\r\n",
        "model.compile(loss='mse', optimizer='rmsprop',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kfdk_nwU2IU",
        "outputId": "7b4c0a39-10d8-4de3-c33a-57d59ac0cf49"
      },
      "source": [
        "history = model.fit(trainX.tolist(), Y_train.tolist(), epochs=2000, validation_data=(testX.tolist(), Y_test.tolist()))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "58/58 [==============================] - 4s 18ms/step - loss: 0.0785 - accuracy: 1.5427e-04 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0095 - accuracy: 2.8908e-04 - val_loss: 0.0120 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 2.5923e-04 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0068 - accuracy: 5.3953e-04 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 2.0415e-04 - val_loss: 0.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 4.2880e-04 - val_loss: 0.0275 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 3.9026e-04 - val_loss: 0.0227 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 0.0014 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 2.3098e-04 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 0.0012 - val_loss: 0.0081 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 6.7969e-04 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 4.7035e-04 - val_loss: 0.0140 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 9.7871e-05 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 4.7035e-04 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0868e-04 - val_loss: 0.0225 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.0010 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 8.2668e-04 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 2.3098e-04 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 8.2668e-04 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 7.1279e-04 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 3.3726e-04 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 7.8594e-04 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 0.0017 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 8.7082e-04 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 2.0415e-04 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 3.7274e-05 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.0025 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 3.0465e-04 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 3.0465e-04 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.7862e-04 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.3098e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 3.9026e-04 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 4.0918e-04 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.0015 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.0017 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 0.0013 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 4.9242e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 4.2880e-04 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.1972e-04 - val_loss: 0.0150 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 6.1911e-04 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 2.7394e-04 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 2.4492e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.0012 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.5427e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 2.3098e-04 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.6631e-04 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 9.7871e-05 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 9.1897e-04 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.0011 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 9.7194e-04 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 4.0918e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 4.4917e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 2.7816e-05 - val_loss: 0.0090 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 3.7200e-04 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 0.0015 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0017 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.0011 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 4.6904e-05 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.7862e-04 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.0013 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0868e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 3.9026e-04 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 2.3098e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.0012 - val_loss: 0.0087 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 4.2880e-04 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 9.7871e-05 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.6631e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 4.7035e-04 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 7.1279e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.0017 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 3.3726e-04 - val_loss: 0.0146 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 6.7969e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.0015 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 5.1545e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 5.3953e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 7.4811e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.6631e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 2.7394e-04 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.0014 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 6.7969e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.5427e-04 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.0014 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 7.6892e-05 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 2.5923e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 2.5923e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.0017 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 9.1897e-04 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 4.0918e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.0012 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 3.3726e-04 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0868e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 3.2070e-04 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 3.5434e-04 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 3.2070e-04 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 7.6892e-05 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 2.7816e-05 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 2.7816e-05 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.0025 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.0010 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 0.0014 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.5427e-04 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 9.7871e-05 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.3098e-04 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 2.4492e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 5.6713e-05 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 5.6713e-05 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.4250e-04 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.0014 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.9124e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 3.9026e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.9124e-04 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 5.9123e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 7.6892e-05 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 4.4917e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.7862e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 6.7969e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 3.9026e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.9124e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 3.2070e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 2.8908e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 2.7394e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.0011 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 2.8908e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 7.1279e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 6.7969e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.0017 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 2.4492e-04 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 5.3953e-04 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 3.0465e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 7.6892e-05 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.5427e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.0011 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 8.7278e-05 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.3098e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.7862e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 3.0465e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 9.7871e-05 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.0025 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 6.7969e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.0019 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 3.2070e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 8.7082e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.0010 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 3.2070e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.0015 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 4.2880e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.9124e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 3.0465e-04 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 9.7871e-05 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 9.7871e-05 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 6.6707e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 9.7194e-04 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 6.6707e-05 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.0013 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.7862e-04 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 2.7816e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.8524e-05 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 3.5434e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 2.0415e-04 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 7.6892e-05 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.0013 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 2.0415e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 9.7194e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 5.3953e-04 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0868e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 2.4492e-04 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.0011 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.9171e-04 - accuracy: 0.0025 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 6.4853e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 6.1911e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 6.4853e-04 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.0013 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 5.1545e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.3643e-04 - accuracy: 2.0415e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.9124e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 6.6707e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 7.4811e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 5.9123e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.0015 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 4.7035e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.7862e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.9047e-04 - accuracy: 2.0415e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 2.7816e-05 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 5.9123e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 6.1911e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 5.6713e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 1.3098e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 9.7871e-05 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 7.4811e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 9.7194e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 9.7871e-05 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.3256e-04 - accuracy: 0.0013 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 6.1911e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.9860e-04 - accuracy: 7.1279e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 3.0465e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.8271e-04 - accuracy: 3.9026e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.8531e-04 - accuracy: 0.0013 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.5064e-04 - accuracy: 4.7035e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 5.6475e-04 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 3.2070e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.0832e-04 - accuracy: 6.6707e-05 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 5.1545e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.8164e-04 - accuracy: 4.2880e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.3502e-04 - accuracy: 2.4492e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.0019 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.6245e-04 - accuracy: 1.9124e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.5941e-04 - accuracy: 0.0014 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.2116e-04 - accuracy: 8.7278e-05 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5736e-04 - accuracy: 4.0918e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 6.4853e-04 - val_loss: 9.2038e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.3859e-04 - accuracy: 2.5923e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.3189e-04 - accuracy: 3.5434e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.9246e-04 - accuracy: 2.8908e-04 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.9710e-04 - accuracy: 9.7871e-05 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.4256e-04 - accuracy: 0.0017 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.3084e-04 - accuracy: 2.4492e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 6.4853e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 0.0011 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.4601e-04 - accuracy: 1.8524e-05 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5127e-04 - accuracy: 6.1911e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.3366e-04 - accuracy: 0.0012 - val_loss: 9.8699e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.0085e-04 - accuracy: 3.3726e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.5126e-04 - accuracy: 3.7274e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.7423e-04 - accuracy: 5.3953e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.8226e-04 - accuracy: 0.0014 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.9507e-04 - accuracy: 4.4917e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.9644e-04 - accuracy: 2.0415e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.2790e-04 - accuracy: 7.4811e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 8.9473e-04 - accuracy: 1.9124e-04 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 9.7194e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.5161e-04 - accuracy: 8.7278e-05 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.1481e-04 - accuracy: 7.8594e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.8898e-04 - accuracy: 5.3953e-04 - val_loss: 8.7991e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.1313e-04 - accuracy: 8.7082e-04 - val_loss: 9.5231e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5987e-04 - accuracy: 5.6475e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.7811e-04 - accuracy: 4.7035e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.2738e-04 - accuracy: 4.9242e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5353e-04 - accuracy: 6.4853e-04 - val_loss: 9.5659e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.2575e-04 - accuracy: 0.0010 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.2486e-04 - accuracy: 1.6631e-04 - val_loss: 9.3372e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.2612e-04 - accuracy: 8.2668e-04 - val_loss: 9.4942e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.9745e-04 - accuracy: 1.1972e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5146e-04 - accuracy: 8.7278e-05 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 9.4499e-04 - accuracy: 6.1911e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5087e-04 - accuracy: 0.0012 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.2871e-04 - accuracy: 7.8594e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.9759e-04 - accuracy: 3.7274e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7189e-04 - accuracy: 0.0013 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.6662e-04 - accuracy: 1.3098e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.2627e-04 - accuracy: 0.0013 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.0600e-04 - accuracy: 5.6713e-05 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 5.1545e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.5098e-04 - accuracy: 6.6707e-05 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.4611e-04 - accuracy: 1.1972e-04 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0868e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.4158e-04 - accuracy: 8.7278e-05 - val_loss: 8.1186e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.2283e-04 - accuracy: 0.0015 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5484e-04 - accuracy: 1.6631e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.7676e-04 - accuracy: 1.7862e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.7240e-04 - accuracy: 1.6631e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.6937e-04 - accuracy: 2.7394e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.8217e-04 - accuracy: 2.4492e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.0615e-04 - accuracy: 0.0017 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.5391e-04 - accuracy: 0.0025 - val_loss: 9.7279e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.9078e-04 - accuracy: 3.2070e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.4480e-04 - accuracy: 7.1279e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.0230e-04 - accuracy: 4.4917e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.4162e-04 - accuracy: 3.2070e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.3047e-04 - accuracy: 7.8594e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.0288e-04 - accuracy: 6.7969e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.9327e-04 - accuracy: 0.0012 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.9868e-04 - accuracy: 5.1545e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 7.8594e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.9055e-04 - accuracy: 3.5434e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2333e-04 - accuracy: 0.0012 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2731e-04 - accuracy: 1.8524e-05 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.7376e-04 - accuracy: 1.3098e-04 - val_loss: 9.9865e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.2411e-04 - accuracy: 4.0918e-04 - val_loss: 9.5902e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.4031e-04 - accuracy: 4.2880e-04 - val_loss: 9.5891e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.6113e-04 - accuracy: 3.9026e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.5295e-04 - accuracy: 1.4250e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.5022e-04 - accuracy: 0.0017 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.6928e-04 - accuracy: 9.1897e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.6843e-04 - accuracy: 1.5427e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.7845e-04 - accuracy: 3.3726e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.3174e-04 - accuracy: 3.0465e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.3253e-04 - accuracy: 2.3098e-04 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.8869e-04 - accuracy: 6.4853e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3160e-04 - accuracy: 1.5427e-04 - val_loss: 8.2394e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.1935e-04 - accuracy: 2.0415e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.4401e-04 - accuracy: 4.7035e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2910e-04 - accuracy: 4.2880e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.0365e-04 - accuracy: 2.3098e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.5111e-04 - accuracy: 8.7278e-05 - val_loss: 7.3793e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.5658e-04 - accuracy: 5.1545e-04 - val_loss: 8.6446e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.9841e-04 - accuracy: 4.9242e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.4872e-04 - accuracy: 1.5427e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.7002e-04 - accuracy: 8.7278e-05 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.6765e-04 - accuracy: 5.1545e-04 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.7968e-04 - accuracy: 2.1740e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 8.2466e-04 - accuracy: 6.6707e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 7.1119e-04 - accuracy: 7.8594e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2915e-04 - accuracy: 7.8594e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.0742e-04 - accuracy: 4.4917e-04 - val_loss: 9.3114e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.6828e-04 - accuracy: 8.7278e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.6017e-04 - accuracy: 1.1972e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.0617e-04 - accuracy: 1.3098e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.0609e-04 - accuracy: 0.0025 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.2163e-04 - accuracy: 5.1545e-04 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.7952e-04 - accuracy: 1.8524e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.2241e-04 - accuracy: 5.1545e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.0899e-04 - accuracy: 7.4811e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.7448e-04 - accuracy: 0.0015 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3814e-04 - accuracy: 3.7200e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.5492e-04 - accuracy: 1.4250e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.3130e-04 - accuracy: 3.9026e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.1292e-04 - accuracy: 2.8908e-04 - val_loss: 8.8887e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.0760e-04 - accuracy: 4.4917e-04 - val_loss: 9.3183e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.4805e-04 - accuracy: 0.0015 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.9920e-04 - accuracy: 3.2070e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.0184e-04 - accuracy: 7.1279e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.8553e-04 - accuracy: 3.2070e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.9583e-04 - accuracy: 3.0465e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2713e-04 - accuracy: 3.2070e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 7.7855e-04 - accuracy: 0.0014 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.1078e-04 - accuracy: 2.7816e-05 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.0307e-04 - accuracy: 6.6707e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.9378e-04 - accuracy: 9.1897e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3583e-04 - accuracy: 1.7862e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2157e-04 - accuracy: 0.0019 - val_loss: 9.0813e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.1580e-04 - accuracy: 1.7862e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.0769e-04 - accuracy: 4.6904e-05 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.5134e-04 - accuracy: 7.8594e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7580e-04 - accuracy: 1.7862e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7085e-04 - accuracy: 3.7200e-04 - val_loss: 9.4320e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.8390e-04 - accuracy: 0.0013 - val_loss: 9.1155e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.8000e-04 - accuracy: 4.7035e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.5561e-04 - accuracy: 9.7871e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6417e-04 - accuracy: 7.6892e-05 - val_loss: 9.9730e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2863e-04 - accuracy: 0.0025 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3766e-04 - accuracy: 2.7394e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.9540e-04 - accuracy: 4.2880e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7045e-04 - accuracy: 2.7394e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.9947e-04 - accuracy: 4.9242e-04 - val_loss: 8.1391e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.7291e-04 - accuracy: 3.3726e-04 - val_loss: 8.4182e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5832e-04 - accuracy: 3.2070e-04 - val_loss: 7.1929e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0827e-04 - accuracy: 8.2668e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3404e-04 - accuracy: 5.9123e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.0615e-04 - accuracy: 2.7394e-04 - val_loss: 8.6562e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6523e-04 - accuracy: 6.6707e-05 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.6082e-04 - accuracy: 1.1972e-04 - val_loss: 8.2402e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.7653e-04 - accuracy: 3.7274e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.5117e-04 - accuracy: 0.0017 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.7070e-04 - accuracy: 1.3098e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.6321e-04 - accuracy: 7.6892e-05 - val_loss: 7.8426e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.8554e-04 - accuracy: 0.0012 - val_loss: 8.7655e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.8300e-04 - accuracy: 2.7816e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6690e-04 - accuracy: 3.2070e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.8440e-04 - accuracy: 0.0013 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9228e-04 - accuracy: 7.8594e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6488e-04 - accuracy: 0.0011 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.9873e-04 - accuracy: 6.4853e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6436e-04 - accuracy: 9.7194e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.8211e-04 - accuracy: 7.1279e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4058e-04 - accuracy: 7.6892e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4984e-04 - accuracy: 8.7082e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.1729e-04 - accuracy: 2.5923e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6942e-04 - accuracy: 6.6707e-05 - val_loss: 9.8046e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3346e-04 - accuracy: 3.2070e-04 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.4066e-04 - accuracy: 7.4811e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6129e-04 - accuracy: 7.6892e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 6.0164e-04 - accuracy: 1.4250e-04 - val_loss: 9.1193e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6673e-04 - accuracy: 1.4250e-04 - val_loss: 9.9603e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4974e-04 - accuracy: 3.7274e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4259e-04 - accuracy: 1.8524e-05 - val_loss: 9.7713e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4859e-04 - accuracy: 6.6707e-05 - val_loss: 9.9923e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.0567e-04 - accuracy: 5.6475e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.8243e-04 - accuracy: 7.4811e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.5759e-04 - accuracy: 1.5427e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8976e-04 - accuracy: 5.1545e-04 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2114e-04 - accuracy: 7.6892e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.0397e-04 - accuracy: 2.8908e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.7838e-04 - accuracy: 1.4250e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6747e-04 - accuracy: 9.7871e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2931e-04 - accuracy: 0.0012 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.4891e-04 - accuracy: 2.4492e-04 - val_loss: 9.1326e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5529e-04 - accuracy: 3.9026e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6672e-04 - accuracy: 1.4250e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6161e-04 - accuracy: 5.1545e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.1328e-04 - accuracy: 2.0415e-04 - val_loss: 9.8877e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.6763e-04 - accuracy: 1.7862e-04 - val_loss: 9.0772e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6071e-04 - accuracy: 7.6892e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9523e-04 - accuracy: 9.7194e-04 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.0822e-04 - accuracy: 1.4250e-04 - val_loss: 9.0262e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.1143e-04 - accuracy: 1.6631e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5763e-04 - accuracy: 2.8908e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.8212e-04 - accuracy: 1.1972e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3721e-04 - accuracy: 1.5427e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5065e-04 - accuracy: 5.1545e-04 - val_loss: 9.3876e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.4485e-04 - accuracy: 2.7816e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.7884e-04 - accuracy: 2.8908e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5210e-04 - accuracy: 4.9242e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.4171e-04 - accuracy: 0.0014 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3257e-04 - accuracy: 7.8594e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5621e-04 - accuracy: 7.4811e-04 - val_loss: 9.3040e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7426e-04 - accuracy: 0.0017 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8926e-04 - accuracy: 3.7200e-04 - val_loss: 8.4398e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3624e-04 - accuracy: 2.4492e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9613e-04 - accuracy: 7.1279e-04 - val_loss: 8.7434e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7288e-04 - accuracy: 1.9124e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3480e-04 - accuracy: 7.8594e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6579e-04 - accuracy: 4.4917e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4622e-04 - accuracy: 4.9242e-04 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.6272e-04 - accuracy: 2.7394e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4483e-04 - accuracy: 0.0014 - val_loss: 8.3155e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0435e-04 - accuracy: 8.2668e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3384e-04 - accuracy: 0.0025 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2035e-04 - accuracy: 0.0010 - val_loss: 9.4909e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3897e-04 - accuracy: 2.3098e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.4334e-04 - accuracy: 1.4250e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2732e-04 - accuracy: 5.6713e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2089e-04 - accuracy: 8.7082e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4014e-04 - accuracy: 5.1545e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9935e-04 - accuracy: 5.6713e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/2000\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 6.4429e-04 - accuracy: 0.0014 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.2962e-04 - accuracy: 5.6713e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.1942e-04 - accuracy: 0.0012 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9527e-04 - accuracy: 2.5923e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5668e-04 - accuracy: 8.7278e-05 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 430/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5699e-04 - accuracy: 1.4250e-04 - val_loss: 7.7174e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 431/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9845e-04 - accuracy: 3.5434e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 432/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4838e-04 - accuracy: 4.0918e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 433/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 5.6647e-04 - accuracy: 7.8594e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 434/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8799e-04 - accuracy: 0.0013 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 435/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5393e-04 - accuracy: 9.7871e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 436/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3069e-04 - accuracy: 3.7200e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 437/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.3599e-04 - accuracy: 5.6713e-05 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\n",
            "Epoch 438/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.5937e-04 - accuracy: 5.3953e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 439/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2938e-04 - accuracy: 4.7035e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 440/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3689e-04 - accuracy: 0.0011 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 441/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.1609e-04 - accuracy: 4.4917e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 442/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4827e-04 - accuracy: 0.0011 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 443/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2196e-04 - accuracy: 5.6713e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 444/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2876e-04 - accuracy: 3.5434e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 445/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9372e-04 - accuracy: 3.2070e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 446/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.4702e-04 - accuracy: 3.0465e-04 - val_loss: 8.3123e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 447/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.8166e-04 - accuracy: 1.1972e-04 - val_loss: 9.6555e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 448/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3835e-04 - accuracy: 9.1897e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 449/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9125e-04 - accuracy: 9.1897e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 450/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3799e-04 - accuracy: 2.4492e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 451/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8677e-04 - accuracy: 1.6631e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 452/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5593e-04 - accuracy: 8.7082e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 453/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3545e-04 - accuracy: 4.2880e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 454/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.1014e-04 - accuracy: 3.2070e-04 - val_loss: 7.9787e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 455/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6304e-04 - accuracy: 5.6475e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 456/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9016e-04 - accuracy: 3.2070e-04 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 457/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0202e-04 - accuracy: 4.2880e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 458/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.6705e-04 - accuracy: 3.0465e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 459/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6330e-04 - accuracy: 6.1911e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 460/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.2515e-04 - accuracy: 1.9124e-04 - val_loss: 9.9046e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 461/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7199e-04 - accuracy: 4.4917e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 462/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0394e-04 - accuracy: 0.0012 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 463/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8572e-04 - accuracy: 0.0012 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 464/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8411e-04 - accuracy: 2.1740e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 465/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5955e-04 - accuracy: 0.0012 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 466/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3387e-04 - accuracy: 2.5923e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 467/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4750e-04 - accuracy: 1.5427e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 468/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0603e-04 - accuracy: 6.6707e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 469/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.8200e-04 - accuracy: 1.9124e-04 - val_loss: 7.7696e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 470/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9008e-04 - accuracy: 5.6713e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 471/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9869e-04 - accuracy: 2.8908e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 472/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0167e-04 - accuracy: 1.1972e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 473/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5570e-04 - accuracy: 6.1911e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 474/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.9829e-04 - accuracy: 6.7969e-04 - val_loss: 9.7520e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 475/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6646e-04 - accuracy: 1.3098e-04 - val_loss: 9.4902e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 476/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7931e-04 - accuracy: 3.0465e-04 - val_loss: 8.2454e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 477/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.9974e-04 - accuracy: 1.3098e-04 - val_loss: 9.2289e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 478/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5454e-04 - accuracy: 2.3098e-04 - val_loss: 8.6285e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 479/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1978e-04 - accuracy: 9.7194e-04 - val_loss: 8.1506e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 480/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9224e-04 - accuracy: 3.7200e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 481/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3104e-04 - accuracy: 7.6892e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 482/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9282e-04 - accuracy: 4.0918e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 483/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6717e-04 - accuracy: 8.7082e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 484/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9618e-04 - accuracy: 9.1897e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0649e-04 - accuracy: 0.0025 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4865e-04 - accuracy: 2.7816e-05 - val_loss: 8.1415e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 7.1499e-04 - accuracy: 2.1740e-04 - val_loss: 8.7822e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0842e-04 - accuracy: 4.0918e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7086e-04 - accuracy: 8.7082e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0122e-04 - accuracy: 9.7871e-05 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9749e-04 - accuracy: 4.6904e-05 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7562e-04 - accuracy: 0.0014 - val_loss: 7.6970e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3610e-04 - accuracy: 3.7274e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7633e-04 - accuracy: 2.4492e-04 - val_loss: 6.8971e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.4479e-04 - accuracy: 2.8908e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2731e-04 - accuracy: 2.0415e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2508e-04 - accuracy: 4.9242e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8242e-04 - accuracy: 1.3098e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3585e-04 - accuracy: 0.0019 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.1645e-04 - accuracy: 2.7394e-04 - val_loss: 8.4511e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 501/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 5.6380e-04 - accuracy: 5.1545e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 502/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7590e-04 - accuracy: 4.2880e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 503/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4965e-04 - accuracy: 5.6713e-05 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 504/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9715e-04 - accuracy: 6.4853e-04 - val_loss: 7.7607e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 505/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8595e-04 - accuracy: 1.7862e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 506/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4016e-04 - accuracy: 5.3953e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 507/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.1447e-04 - accuracy: 4.6904e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 508/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9922e-04 - accuracy: 3.7274e-05 - val_loss: 9.6520e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 509/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4449e-04 - accuracy: 1.9124e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 510/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3274e-04 - accuracy: 7.8594e-04 - val_loss: 8.2119e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 511/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4123e-04 - accuracy: 4.2880e-04 - val_loss: 8.5707e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 512/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7915e-04 - accuracy: 7.4811e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 513/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6492e-04 - accuracy: 1.7862e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 514/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2914e-04 - accuracy: 9.7871e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 515/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9595e-04 - accuracy: 0.0013 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 516/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0533e-04 - accuracy: 7.1279e-04 - val_loss: 8.4766e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 517/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0578e-04 - accuracy: 1.9124e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 518/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1298e-04 - accuracy: 7.8594e-04 - val_loss: 9.2284e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 519/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4905e-04 - accuracy: 5.1545e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 520/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4333e-04 - accuracy: 0.0025 - val_loss: 8.2350e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 521/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7304e-04 - accuracy: 5.3953e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 522/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8674e-04 - accuracy: 1.1972e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 523/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9663e-04 - accuracy: 6.7969e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 524/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3912e-04 - accuracy: 6.6707e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 525/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0678e-04 - accuracy: 4.9242e-04 - val_loss: 9.8876e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 526/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5298e-04 - accuracy: 3.7200e-04 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 527/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3705e-04 - accuracy: 0.0025 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 528/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.5795e-04 - accuracy: 3.5434e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 529/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.2509e-04 - accuracy: 3.2070e-04 - val_loss: 9.8165e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 530/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7591e-04 - accuracy: 7.1279e-04 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
            "Epoch 531/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.5771e-04 - accuracy: 2.3098e-04 - val_loss: 7.8517e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 532/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5219e-04 - accuracy: 1.6631e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 533/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4725e-04 - accuracy: 7.1279e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 534/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7403e-04 - accuracy: 2.3098e-04 - val_loss: 8.6715e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 535/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5314e-04 - accuracy: 3.5434e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 536/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.2683e-04 - accuracy: 1.9124e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 537/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3889e-04 - accuracy: 3.5434e-04 - val_loss: 9.9340e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 538/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7864e-04 - accuracy: 7.8594e-04 - val_loss: 9.2101e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 539/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5924e-04 - accuracy: 1.9124e-04 - val_loss: 6.8666e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 540/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4770e-04 - accuracy: 0.0015 - val_loss: 7.7686e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 541/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.3062e-04 - accuracy: 9.7871e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 542/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.4494e-04 - accuracy: 9.7871e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 543/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6954e-04 - accuracy: 1.9124e-04 - val_loss: 7.8503e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 544/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6384e-04 - accuracy: 0.0017 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 545/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.4644e-04 - accuracy: 1.7862e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 546/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.5325e-04 - accuracy: 3.3726e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 547/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8278e-04 - accuracy: 7.8594e-04 - val_loss: 8.4580e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 548/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6057e-04 - accuracy: 1.4250e-04 - val_loss: 6.3959e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 549/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9956e-04 - accuracy: 2.7816e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 550/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1969e-04 - accuracy: 4.9242e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 551/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3297e-04 - accuracy: 0.0025 - val_loss: 9.5633e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 552/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3658e-04 - accuracy: 4.9242e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 553/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.4177e-04 - accuracy: 3.7200e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 554/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4534e-04 - accuracy: 5.1545e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 555/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8723e-04 - accuracy: 3.0465e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 556/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6280e-04 - accuracy: 9.7194e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 557/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3159e-04 - accuracy: 0.0013 - val_loss: 8.8103e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 558/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6914e-04 - accuracy: 7.4811e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 559/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0159e-04 - accuracy: 8.7278e-05 - val_loss: 9.9867e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 560/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.6907e-04 - accuracy: 6.4853e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 561/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3032e-04 - accuracy: 4.2880e-04 - val_loss: 8.0745e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 562/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 5.4335e-04 - accuracy: 1.6631e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 563/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3152e-04 - accuracy: 3.9026e-04 - val_loss: 7.1412e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 564/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7313e-04 - accuracy: 5.6475e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 565/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0162e-04 - accuracy: 2.5923e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 566/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.9475e-04 - accuracy: 3.7200e-04 - val_loss: 8.8825e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 567/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.3415e-04 - accuracy: 8.2668e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 568/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.1639e-04 - accuracy: 4.4917e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 569/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.3843e-04 - accuracy: 6.1911e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 570/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0073e-04 - accuracy: 3.0465e-04 - val_loss: 9.7375e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 571/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7173e-04 - accuracy: 0.0010 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 572/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7187e-04 - accuracy: 8.7082e-04 - val_loss: 9.5367e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 573/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4832e-04 - accuracy: 4.0918e-04 - val_loss: 9.2866e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 574/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9483e-04 - accuracy: 5.9123e-04 - val_loss: 8.2391e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 575/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1450e-04 - accuracy: 8.7278e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 576/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8012e-04 - accuracy: 9.1897e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 577/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5522e-04 - accuracy: 0.0011 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 578/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0881e-04 - accuracy: 0.0013 - val_loss: 8.6429e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 579/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3453e-04 - accuracy: 1.3098e-04 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\n",
            "Epoch 580/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9694e-04 - accuracy: 0.0025 - val_loss: 9.9906e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 581/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5412e-04 - accuracy: 3.7274e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 582/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1367e-04 - accuracy: 5.6475e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 583/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8616e-04 - accuracy: 1.1972e-04 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
            "Epoch 584/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.3786e-04 - accuracy: 8.7278e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 585/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3315e-04 - accuracy: 2.8908e-04 - val_loss: 8.3074e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 586/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4504e-04 - accuracy: 4.7035e-04 - val_loss: 9.6718e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 587/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7139e-04 - accuracy: 0.0014 - val_loss: 9.7025e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 588/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1477e-04 - accuracy: 9.1897e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 589/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4346e-04 - accuracy: 1.9124e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 590/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.8775e-04 - accuracy: 9.7194e-04 - val_loss: 7.7993e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 591/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0524e-04 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 592/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4129e-04 - accuracy: 3.2070e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 593/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3493e-04 - accuracy: 1.3098e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 594/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.2041e-04 - accuracy: 4.4917e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 595/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2897e-04 - accuracy: 2.3098e-04 - val_loss: 7.5070e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 596/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7874e-04 - accuracy: 6.1911e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 597/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9737e-04 - accuracy: 7.8594e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 598/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.8121e-04 - accuracy: 9.1897e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 599/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8665e-04 - accuracy: 0.0010 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 600/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2903e-04 - accuracy: 6.4853e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 601/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7315e-04 - accuracy: 1.7862e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 602/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0354e-04 - accuracy: 2.1740e-04 - val_loss: 8.6454e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 603/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6637e-04 - accuracy: 5.6713e-05 - val_loss: 7.6093e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 604/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.9096e-04 - accuracy: 2.3098e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 605/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7100e-04 - accuracy: 5.6713e-05 - val_loss: 7.7738e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 606/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0716e-04 - accuracy: 3.9026e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 607/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.9941e-04 - accuracy: 6.1911e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 608/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1543e-04 - accuracy: 6.4853e-04 - val_loss: 7.5201e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 609/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8544e-04 - accuracy: 7.8594e-04 - val_loss: 8.4472e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 610/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3152e-04 - accuracy: 6.7969e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 611/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1257e-04 - accuracy: 3.5434e-04 - val_loss: 9.4270e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 612/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1743e-04 - accuracy: 5.3953e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 613/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7667e-04 - accuracy: 2.5923e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 614/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7867e-04 - accuracy: 2.4492e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 615/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9631e-04 - accuracy: 9.1897e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 616/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3995e-04 - accuracy: 2.8908e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 617/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.0452e-04 - accuracy: 8.7278e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 618/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8712e-04 - accuracy: 6.6707e-05 - val_loss: 9.2465e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 619/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.3918e-04 - accuracy: 2.0415e-04 - val_loss: 8.6687e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 620/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2720e-04 - accuracy: 0.0019 - val_loss: 9.3495e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 621/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7799e-04 - accuracy: 1.7862e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 622/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.0452e-04 - accuracy: 0.0014 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 623/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1372e-04 - accuracy: 0.0010 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 624/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0305e-04 - accuracy: 0.0010 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 625/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1218e-04 - accuracy: 5.9123e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 626/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.9787e-04 - accuracy: 5.6475e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 627/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6965e-04 - accuracy: 6.4853e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 628/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1666e-04 - accuracy: 6.4853e-04 - val_loss: 8.0189e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 629/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2291e-04 - accuracy: 7.1279e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 630/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 4.8293e-04 - accuracy: 5.9123e-04 - val_loss: 9.4711e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 631/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2402e-04 - accuracy: 0.0014 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 632/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2115e-04 - accuracy: 0.0019 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 633/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8925e-04 - accuracy: 0.0010 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 634/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9602e-04 - accuracy: 9.7194e-04 - val_loss: 8.5007e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 635/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.3618e-04 - accuracy: 7.8594e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 636/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 6.2315e-04 - accuracy: 6.4853e-04 - val_loss: 8.2270e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 637/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8903e-04 - accuracy: 5.1545e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 638/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7553e-04 - accuracy: 1.0868e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 639/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.9375e-04 - accuracy: 3.7274e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 640/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7724e-04 - accuracy: 3.9026e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 641/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6879e-04 - accuracy: 9.7871e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 642/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.4591e-04 - accuracy: 6.6707e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 643/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8801e-04 - accuracy: 3.7274e-05 - val_loss: 9.0097e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 644/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.1484e-04 - accuracy: 2.4492e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 645/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7062e-04 - accuracy: 5.1545e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 646/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0273e-04 - accuracy: 4.6904e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 647/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5200e-04 - accuracy: 1.3098e-04 - val_loss: 8.5787e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 648/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0469e-04 - accuracy: 9.1897e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 649/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8911e-04 - accuracy: 9.1897e-04 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 650/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.8028e-04 - accuracy: 3.5434e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 651/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8187e-04 - accuracy: 6.1911e-04 - val_loss: 8.9933e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 652/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3406e-04 - accuracy: 1.3098e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 653/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8304e-04 - accuracy: 1.6631e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 654/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.5865e-04 - accuracy: 1.9124e-04 - val_loss: 7.3872e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 655/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5831e-04 - accuracy: 6.1911e-04 - val_loss: 7.2124e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 656/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1488e-04 - accuracy: 1.1972e-04 - val_loss: 8.3821e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 657/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6750e-04 - accuracy: 1.4250e-04 - val_loss: 9.2855e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 658/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5594e-04 - accuracy: 7.1279e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 659/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3518e-04 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 660/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0160e-04 - accuracy: 7.4811e-04 - val_loss: 9.1852e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 661/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0356e-04 - accuracy: 1.6631e-04 - val_loss: 9.6314e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 662/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1131e-04 - accuracy: 6.6707e-05 - val_loss: 8.5065e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 663/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2534e-04 - accuracy: 3.2070e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 664/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9575e-04 - accuracy: 4.6904e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 665/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7687e-04 - accuracy: 2.7394e-04 - val_loss: 9.3242e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 666/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8739e-04 - accuracy: 8.2668e-04 - val_loss: 8.6034e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 667/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9540e-04 - accuracy: 9.1897e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 668/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4684e-04 - accuracy: 2.4492e-04 - val_loss: 7.6256e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 669/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2360e-04 - accuracy: 0.0017 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 670/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3746e-04 - accuracy: 6.6707e-05 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 671/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8833e-04 - accuracy: 2.4492e-04 - val_loss: 9.6532e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 672/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8073e-04 - accuracy: 2.3098e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 673/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7437e-04 - accuracy: 7.8594e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 674/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6864e-04 - accuracy: 2.7816e-05 - val_loss: 8.5950e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 675/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7685e-04 - accuracy: 4.6904e-05 - val_loss: 8.2473e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 676/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3218e-04 - accuracy: 1.7862e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 677/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8577e-04 - accuracy: 2.8908e-04 - val_loss: 8.8294e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 678/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6760e-04 - accuracy: 0.0011 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 679/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7550e-04 - accuracy: 3.2070e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 680/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6866e-04 - accuracy: 1.4250e-04 - val_loss: 8.8096e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 681/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.3563e-04 - accuracy: 9.1897e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 682/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6169e-04 - accuracy: 4.2880e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 683/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0219e-04 - accuracy: 0.0025 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 684/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7282e-04 - accuracy: 7.6892e-05 - val_loss: 7.6401e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 685/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6451e-04 - accuracy: 7.4811e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 686/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8683e-04 - accuracy: 3.5434e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 687/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1060e-04 - accuracy: 2.7394e-04 - val_loss: 7.2634e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 688/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7318e-04 - accuracy: 1.6631e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 689/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1521e-04 - accuracy: 4.9242e-04 - val_loss: 8.1720e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 690/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4070e-04 - accuracy: 5.3953e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 691/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 4.9444e-04 - accuracy: 5.9123e-04 - val_loss: 8.7660e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 692/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1047e-04 - accuracy: 3.9026e-04 - val_loss: 9.0558e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 693/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9148e-04 - accuracy: 0.0014 - val_loss: 8.3953e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 694/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9652e-04 - accuracy: 5.9123e-04 - val_loss: 8.1656e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 695/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8183e-04 - accuracy: 4.0918e-04 - val_loss: 8.5699e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 696/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7912e-04 - accuracy: 3.9026e-04 - val_loss: 7.3272e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 697/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0619e-04 - accuracy: 3.3726e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 698/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2223e-04 - accuracy: 5.1545e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 699/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1297e-04 - accuracy: 1.7862e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 700/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5816e-04 - accuracy: 2.1740e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 701/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3170e-04 - accuracy: 5.6475e-04 - val_loss: 9.9379e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 702/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8071e-04 - accuracy: 4.0918e-04 - val_loss: 9.8332e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 703/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7960e-04 - accuracy: 3.7274e-05 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 704/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8935e-04 - accuracy: 3.2070e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 705/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2221e-04 - accuracy: 1.0868e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 706/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7839e-04 - accuracy: 7.6892e-05 - val_loss: 7.2961e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 707/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7703e-04 - accuracy: 8.7278e-05 - val_loss: 7.9514e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 708/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7671e-04 - accuracy: 5.6713e-05 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 709/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8434e-04 - accuracy: 6.1911e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 710/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2634e-04 - accuracy: 1.0868e-04 - val_loss: 7.7515e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 711/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9265e-04 - accuracy: 2.3098e-04 - val_loss: 9.4942e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 712/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7764e-04 - accuracy: 0.0011 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 713/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.5778e-04 - accuracy: 8.7082e-04 - val_loss: 7.7982e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 714/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6621e-04 - accuracy: 3.2070e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 715/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3026e-04 - accuracy: 2.7816e-05 - val_loss: 9.7422e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 716/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0685e-04 - accuracy: 7.8594e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 717/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2709e-04 - accuracy: 7.1279e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 718/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2155e-04 - accuracy: 3.5434e-04 - val_loss: 9.7341e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 719/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9734e-04 - accuracy: 2.5923e-04 - val_loss: 9.0159e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 720/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8586e-04 - accuracy: 5.9123e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 721/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.0794e-04 - accuracy: 2.8908e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 722/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6032e-04 - accuracy: 3.3726e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 723/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6473e-04 - accuracy: 8.2668e-04 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 724/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.7275e-04 - accuracy: 6.4853e-04 - val_loss: 7.4734e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 725/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5330e-04 - accuracy: 5.6713e-05 - val_loss: 7.1449e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 726/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3330e-04 - accuracy: 4.9242e-04 - val_loss: 8.9811e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 727/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6302e-04 - accuracy: 0.0019 - val_loss: 9.2053e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 728/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.4140e-04 - accuracy: 7.6892e-05 - val_loss: 8.1763e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 729/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6397e-04 - accuracy: 7.6892e-05 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 730/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1466e-04 - accuracy: 4.0918e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 731/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.9934e-04 - accuracy: 1.6631e-04 - val_loss: 9.8683e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 732/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6586e-04 - accuracy: 4.0918e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 733/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1452e-04 - accuracy: 7.1279e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 734/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5599e-04 - accuracy: 4.6904e-05 - val_loss: 8.5087e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 735/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5990e-04 - accuracy: 6.4853e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 736/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5100e-04 - accuracy: 2.7816e-05 - val_loss: 8.9128e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 737/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8265e-04 - accuracy: 0.0012 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 738/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5611e-04 - accuracy: 9.7194e-04 - val_loss: 8.1537e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 739/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1238e-04 - accuracy: 4.0918e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 740/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1736e-04 - accuracy: 5.1545e-04 - val_loss: 8.4864e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 741/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1435e-04 - accuracy: 0.0019 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 742/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8368e-04 - accuracy: 1.4250e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 743/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2654e-04 - accuracy: 7.6892e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 744/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5416e-04 - accuracy: 7.1279e-04 - val_loss: 8.6705e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 745/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5618e-04 - accuracy: 5.1545e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 746/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.2294e-04 - accuracy: 0.0013 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\n",
            "Epoch 747/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.8952e-04 - accuracy: 7.6892e-05 - val_loss: 8.6246e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 748/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5852e-04 - accuracy: 1.5427e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 749/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6398e-04 - accuracy: 3.2070e-04 - val_loss: 9.1753e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 750/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 5.0486e-04 - accuracy: 2.0415e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 751/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3892e-04 - accuracy: 0.0011 - val_loss: 9.6783e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 752/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4379e-04 - accuracy: 4.0918e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 753/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5567e-04 - accuracy: 7.6892e-05 - val_loss: 9.3075e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 754/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5185e-04 - accuracy: 0.0014 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 755/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8003e-04 - accuracy: 6.7969e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 756/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6330e-04 - accuracy: 6.4853e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 757/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8092e-04 - accuracy: 9.7194e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 758/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2595e-04 - accuracy: 1.0868e-04 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 759/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.2745e-04 - accuracy: 3.7200e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 760/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8216e-04 - accuracy: 6.1911e-04 - val_loss: 8.1467e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 761/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2918e-04 - accuracy: 2.7816e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 762/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7145e-04 - accuracy: 1.0868e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 763/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.8163e-04 - accuracy: 3.5434e-04 - val_loss: 7.6737e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 764/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4541e-04 - accuracy: 2.7816e-05 - val_loss: 8.1522e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 765/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.3119e-04 - accuracy: 8.7082e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 766/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4061e-04 - accuracy: 2.3098e-04 - val_loss: 8.1066e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 767/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4388e-04 - accuracy: 8.7082e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 768/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3461e-04 - accuracy: 2.3098e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 769/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7934e-04 - accuracy: 2.8908e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 770/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6271e-04 - accuracy: 1.8524e-05 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 771/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8486e-04 - accuracy: 4.7035e-04 - val_loss: 8.8634e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 772/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3676e-04 - accuracy: 7.6892e-05 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 773/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.9200e-04 - accuracy: 5.9123e-04 - val_loss: 8.1299e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 774/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3763e-04 - accuracy: 7.1279e-04 - val_loss: 9.5163e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 775/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8351e-04 - accuracy: 0.0011 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 776/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2999e-04 - accuracy: 1.6631e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 777/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8131e-04 - accuracy: 3.7200e-04 - val_loss: 7.5235e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 778/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4110e-04 - accuracy: 1.5427e-04 - val_loss: 7.4669e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 779/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4250e-04 - accuracy: 0.0019 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 780/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3231e-04 - accuracy: 1.5427e-04 - val_loss: 9.6064e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 781/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6730e-04 - accuracy: 3.0465e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 782/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5954e-04 - accuracy: 1.4250e-04 - val_loss: 9.6483e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 783/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6465e-04 - accuracy: 4.9242e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 784/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5727e-04 - accuracy: 7.6892e-05 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 785/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4329e-04 - accuracy: 1.7862e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 786/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 5.1838e-04 - accuracy: 0.0014 - val_loss: 7.5935e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 787/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7688e-04 - accuracy: 6.6707e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 788/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4682e-04 - accuracy: 5.1545e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 789/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5902e-04 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 790/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4022e-04 - accuracy: 4.0918e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 791/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0600e-04 - accuracy: 7.8594e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 792/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6759e-04 - accuracy: 8.7278e-05 - val_loss: 9.3980e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 793/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4580e-04 - accuracy: 4.2880e-04 - val_loss: 9.5170e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 794/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4315e-04 - accuracy: 9.1897e-04 - val_loss: 9.8560e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 795/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2229e-04 - accuracy: 7.1279e-04 - val_loss: 8.9796e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 796/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5703e-04 - accuracy: 6.7969e-04 - val_loss: 9.3774e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 797/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2918e-04 - accuracy: 1.5427e-04 - val_loss: 9.7429e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 798/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.1525e-04 - accuracy: 4.4917e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 799/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2064e-04 - accuracy: 6.7969e-04 - val_loss: 9.3364e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 800/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3106e-04 - accuracy: 8.7278e-05 - val_loss: 8.2977e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 801/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5073e-04 - accuracy: 1.6631e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 802/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2435e-04 - accuracy: 5.3953e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 803/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5260e-04 - accuracy: 9.7194e-04 - val_loss: 8.6905e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 804/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4913e-04 - accuracy: 4.2880e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 805/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8804e-04 - accuracy: 1.3098e-04 - val_loss: 9.5671e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 806/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3440e-04 - accuracy: 1.6631e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 807/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5788e-04 - accuracy: 0.0010 - val_loss: 9.7897e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 808/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2526e-04 - accuracy: 0.0012 - val_loss: 8.0000e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 809/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2178e-04 - accuracy: 5.9123e-04 - val_loss: 7.4243e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 810/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8901e-04 - accuracy: 6.7969e-04 - val_loss: 8.0383e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 811/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0238e-04 - accuracy: 7.6892e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 812/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5169e-04 - accuracy: 4.6904e-05 - val_loss: 8.0620e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 813/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4552e-04 - accuracy: 3.7200e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 814/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.7950e-04 - accuracy: 1.3098e-04 - val_loss: 9.2218e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 815/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.8269e-04 - accuracy: 8.2668e-04 - val_loss: 8.9441e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 816/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3893e-04 - accuracy: 1.5427e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 817/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8552e-04 - accuracy: 7.6892e-05 - val_loss: 9.5832e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 818/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3.9878e-04 - accuracy: 0.0012 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 819/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7574e-04 - accuracy: 4.6904e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 820/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3828e-04 - accuracy: 1.0868e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 821/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5550e-04 - accuracy: 2.5923e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 822/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0070e-04 - accuracy: 2.0415e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 823/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2228e-04 - accuracy: 7.8594e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 824/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5656e-04 - accuracy: 8.2668e-04 - val_loss: 0.0031 - val_accuracy: 0.0000e+00\n",
            "Epoch 825/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.1023e-04 - accuracy: 8.7082e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 826/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3853e-04 - accuracy: 2.7816e-05 - val_loss: 7.4884e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 827/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9522e-04 - accuracy: 1.4250e-04 - val_loss: 7.9631e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 828/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.5003e-04 - accuracy: 4.2880e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 829/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1737e-04 - accuracy: 9.7194e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 830/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3388e-04 - accuracy: 1.5427e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 831/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6753e-04 - accuracy: 9.7194e-04 - val_loss: 8.4154e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 832/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9846e-04 - accuracy: 2.7394e-04 - val_loss: 8.1273e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 833/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2954e-04 - accuracy: 4.2880e-04 - val_loss: 9.5210e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 834/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5147e-04 - accuracy: 2.4492e-04 - val_loss: 7.8611e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 835/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3519e-04 - accuracy: 2.8908e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 836/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3186e-04 - accuracy: 9.1897e-04 - val_loss: 8.6170e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 837/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0854e-04 - accuracy: 9.1897e-04 - val_loss: 9.5149e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 838/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6365e-04 - accuracy: 0.0012 - val_loss: 6.8890e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 839/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2846e-04 - accuracy: 2.0415e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 840/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8969e-04 - accuracy: 2.5923e-04 - val_loss: 8.1443e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 841/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9232e-04 - accuracy: 4.9242e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 842/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1833e-04 - accuracy: 1.7862e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 843/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7981e-04 - accuracy: 3.9026e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 844/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6095e-04 - accuracy: 4.6904e-05 - val_loss: 9.2790e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 845/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4282e-04 - accuracy: 6.1911e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 846/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5050e-04 - accuracy: 5.9123e-04 - val_loss: 8.3375e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 847/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6809e-04 - accuracy: 0.0014 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 848/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1580e-04 - accuracy: 7.4811e-04 - val_loss: 9.3777e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 849/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0626e-04 - accuracy: 5.6713e-05 - val_loss: 9.2873e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 850/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6944e-04 - accuracy: 8.7082e-04 - val_loss: 7.4982e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 851/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0848e-04 - accuracy: 9.7194e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 852/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.7228e-04 - accuracy: 7.1279e-04 - val_loss: 8.1741e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 853/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5959e-04 - accuracy: 1.5427e-04 - val_loss: 7.9819e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 854/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.5559e-04 - accuracy: 6.4853e-04 - val_loss: 8.9209e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 855/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2565e-04 - accuracy: 0.0014 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 856/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2063e-04 - accuracy: 9.7194e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 857/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7166e-04 - accuracy: 1.6631e-04 - val_loss: 7.7718e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 858/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2482e-04 - accuracy: 3.5434e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 859/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4646e-04 - accuracy: 1.5427e-04 - val_loss: 8.5932e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 860/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0704e-04 - accuracy: 1.0868e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 861/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0080e-04 - accuracy: 9.7194e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 862/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6392e-04 - accuracy: 1.0868e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 863/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7802e-04 - accuracy: 4.6904e-05 - val_loss: 7.8999e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 864/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3434e-04 - accuracy: 0.0012 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 865/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7288e-04 - accuracy: 6.1911e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 866/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0825e-04 - accuracy: 2.7394e-04 - val_loss: 9.1195e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 867/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2168e-04 - accuracy: 2.0415e-04 - val_loss: 8.5665e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 868/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0424e-04 - accuracy: 2.3098e-04 - val_loss: 8.3299e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 869/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4034e-04 - accuracy: 8.7278e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 870/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0274e-04 - accuracy: 4.2880e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 871/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0837e-04 - accuracy: 2.3098e-04 - val_loss: 7.6484e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 872/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9962e-04 - accuracy: 2.7816e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 873/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1215e-04 - accuracy: 5.6475e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 874/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3014e-04 - accuracy: 7.6892e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 875/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8313e-04 - accuracy: 3.9026e-04 - val_loss: 8.6998e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 876/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9542e-04 - accuracy: 5.9123e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 877/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4588e-04 - accuracy: 4.9242e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 878/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4700e-04 - accuracy: 6.6707e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 879/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8944e-04 - accuracy: 4.7035e-04 - val_loss: 9.6769e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 880/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1530e-04 - accuracy: 2.4492e-04 - val_loss: 8.2113e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 881/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0361e-04 - accuracy: 5.1545e-04 - val_loss: 7.3877e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 882/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1275e-04 - accuracy: 4.7035e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 883/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 5.0251e-04 - accuracy: 1.9124e-04 - val_loss: 8.2082e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 884/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2105e-04 - accuracy: 2.0415e-04 - val_loss: 7.8499e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 885/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9982e-04 - accuracy: 9.7871e-05 - val_loss: 9.9509e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 886/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9917e-04 - accuracy: 6.1911e-04 - val_loss: 7.5160e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 887/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9052e-04 - accuracy: 1.6631e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 888/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1293e-04 - accuracy: 1.3098e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 889/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.9690e-04 - accuracy: 4.6904e-05 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 890/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 5.7994e-04 - accuracy: 5.9123e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 891/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9638e-04 - accuracy: 8.2668e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 892/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4366e-04 - accuracy: 3.5434e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 893/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 4.7694e-04 - accuracy: 8.7278e-05 - val_loss: 8.3730e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 894/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3758e-04 - accuracy: 4.2880e-04 - val_loss: 7.1050e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 895/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4733e-04 - accuracy: 2.8908e-04 - val_loss: 6.8645e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 896/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9421e-04 - accuracy: 3.7274e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 897/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4501e-04 - accuracy: 6.7969e-04 - val_loss: 6.5474e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 898/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0373e-04 - accuracy: 3.3726e-04 - val_loss: 7.6769e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 899/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0916e-04 - accuracy: 3.5434e-04 - val_loss: 7.5140e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 900/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2342e-04 - accuracy: 1.0868e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 901/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3077e-04 - accuracy: 5.6475e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 902/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2705e-04 - accuracy: 6.6707e-05 - val_loss: 7.2160e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 903/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.7480e-04 - accuracy: 2.7816e-05 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 904/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6245e-04 - accuracy: 3.5434e-04 - val_loss: 6.9968e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 905/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0190e-04 - accuracy: 4.9242e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 906/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.6090e-04 - accuracy: 2.4492e-04 - val_loss: 8.2083e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 907/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9132e-04 - accuracy: 5.3953e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 908/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0247e-04 - accuracy: 2.1740e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 909/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2286e-04 - accuracy: 9.7871e-05 - val_loss: 7.8146e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 910/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7618e-04 - accuracy: 6.7969e-04 - val_loss: 7.9842e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 911/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1187e-04 - accuracy: 4.4917e-04 - val_loss: 9.8968e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 912/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4064e-04 - accuracy: 3.3726e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 913/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1469e-04 - accuracy: 2.7816e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 914/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9469e-04 - accuracy: 0.0012 - val_loss: 6.4150e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 915/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0935e-04 - accuracy: 2.7816e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 916/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4875e-04 - accuracy: 5.6475e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 917/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0480e-04 - accuracy: 1.0868e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 918/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1783e-04 - accuracy: 0.0019 - val_loss: 9.9085e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 919/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7115e-04 - accuracy: 2.4492e-04 - val_loss: 8.8135e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 920/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9369e-04 - accuracy: 2.3098e-04 - val_loss: 9.0944e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 921/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6791e-04 - accuracy: 9.7194e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 922/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4681e-04 - accuracy: 3.7200e-04 - val_loss: 7.5949e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 923/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8315e-04 - accuracy: 6.4853e-04 - val_loss: 9.3765e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 924/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2247e-04 - accuracy: 6.7969e-04 - val_loss: 9.3335e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 925/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9294e-04 - accuracy: 1.5427e-04 - val_loss: 9.6019e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 926/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7354e-04 - accuracy: 0.0011 - val_loss: 7.8187e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 927/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9689e-04 - accuracy: 4.4917e-04 - val_loss: 8.6658e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 928/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7543e-04 - accuracy: 0.0025 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 929/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.4185e-04 - accuracy: 8.7278e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 930/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8230e-04 - accuracy: 6.4853e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 931/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6820e-04 - accuracy: 5.6475e-04 - val_loss: 7.4659e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 932/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4873e-04 - accuracy: 1.3098e-04 - val_loss: 6.9066e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 933/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3037e-04 - accuracy: 5.1545e-04 - val_loss: 7.1418e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 934/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8561e-04 - accuracy: 1.5427e-04 - val_loss: 8.8329e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 935/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4292e-04 - accuracy: 5.9123e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 936/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4792e-04 - accuracy: 2.0415e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 937/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2440e-04 - accuracy: 1.9124e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 938/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1756e-04 - accuracy: 0.0011 - val_loss: 8.6400e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 939/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6308e-04 - accuracy: 2.3098e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 940/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2066e-04 - accuracy: 2.1740e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 941/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1607e-04 - accuracy: 5.3953e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 942/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9699e-04 - accuracy: 5.9123e-04 - val_loss: 8.4554e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 943/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5690e-04 - accuracy: 6.4853e-04 - val_loss: 6.9671e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 944/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6306e-04 - accuracy: 4.7035e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 945/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.6714e-04 - accuracy: 2.1740e-04 - val_loss: 8.0041e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 946/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7620e-04 - accuracy: 9.1897e-04 - val_loss: 9.2918e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 947/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5419e-04 - accuracy: 4.9242e-04 - val_loss: 6.7518e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 948/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2498e-04 - accuracy: 3.5434e-04 - val_loss: 7.0840e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 949/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.0531e-04 - accuracy: 8.7082e-04 - val_loss: 8.5804e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 950/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.7764e-04 - accuracy: 6.4853e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 951/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5465e-04 - accuracy: 9.1897e-04 - val_loss: 8.3030e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 952/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 4.0511e-04 - accuracy: 2.3098e-04 - val_loss: 9.5930e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 953/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8771e-04 - accuracy: 2.8908e-04 - val_loss: 9.6164e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 954/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8585e-04 - accuracy: 1.5427e-04 - val_loss: 9.8855e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 955/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3892e-04 - accuracy: 8.7082e-04 - val_loss: 9.5658e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 956/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8353e-04 - accuracy: 9.1897e-04 - val_loss: 9.6861e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 957/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3467e-04 - accuracy: 1.0868e-04 - val_loss: 8.5079e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 958/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9259e-04 - accuracy: 6.4853e-04 - val_loss: 8.5829e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 959/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9192e-04 - accuracy: 3.3726e-04 - val_loss: 8.5172e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 960/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6641e-04 - accuracy: 5.1545e-04 - val_loss: 5.7256e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 961/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9109e-04 - accuracy: 4.7035e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 962/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1771e-04 - accuracy: 4.6904e-05 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 963/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1232e-04 - accuracy: 1.5427e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 964/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.7874e-04 - accuracy: 6.1911e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 965/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1975e-04 - accuracy: 7.4811e-04 - val_loss: 9.3097e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 966/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8842e-04 - accuracy: 9.7194e-04 - val_loss: 8.4960e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 967/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8303e-04 - accuracy: 7.6892e-05 - val_loss: 7.3355e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 968/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6900e-04 - accuracy: 5.9123e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 969/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5988e-04 - accuracy: 7.8594e-04 - val_loss: 7.1101e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 970/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0309e-04 - accuracy: 2.4492e-04 - val_loss: 7.8627e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 971/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1547e-04 - accuracy: 0.0013 - val_loss: 8.1236e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 972/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8689e-04 - accuracy: 0.0014 - val_loss: 9.6777e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 973/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1885e-04 - accuracy: 2.3098e-04 - val_loss: 9.1045e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 974/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8738e-04 - accuracy: 1.7862e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 975/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0211e-04 - accuracy: 0.0012 - val_loss: 9.7547e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 976/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.1704e-04 - accuracy: 6.6707e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 977/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9636e-04 - accuracy: 9.7871e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 978/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7723e-04 - accuracy: 8.7082e-04 - val_loss: 8.8028e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 979/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6578e-04 - accuracy: 4.6904e-05 - val_loss: 9.7810e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 980/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2216e-04 - accuracy: 2.7394e-04 - val_loss: 8.1388e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 981/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6704e-04 - accuracy: 3.0465e-04 - val_loss: 8.0230e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 982/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.6669e-04 - accuracy: 1.1972e-04 - val_loss: 9.7918e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 983/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9701e-04 - accuracy: 2.5923e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 984/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.9984e-04 - accuracy: 0.0025 - val_loss: 9.4849e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 985/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5283e-04 - accuracy: 2.3098e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 986/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.7849e-04 - accuracy: 7.8594e-04 - val_loss: 7.3508e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 987/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5554e-04 - accuracy: 3.7274e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 988/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2611e-04 - accuracy: 6.7969e-04 - val_loss: 8.8838e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 989/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1123e-04 - accuracy: 2.1740e-04 - val_loss: 8.3856e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 990/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0884e-04 - accuracy: 0.0014 - val_loss: 9.0873e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 991/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9050e-04 - accuracy: 9.7871e-05 - val_loss: 9.1311e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 992/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8395e-04 - accuracy: 1.4250e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 993/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.7675e-04 - accuracy: 0.0014 - val_loss: 7.3692e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 994/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1577e-04 - accuracy: 1.1972e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 995/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8445e-04 - accuracy: 1.9124e-04 - val_loss: 7.0255e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 996/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9201e-04 - accuracy: 0.0015 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 997/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.2208e-04 - accuracy: 3.7200e-04 - val_loss: 9.5803e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 998/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9167e-04 - accuracy: 1.0868e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 999/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8734e-04 - accuracy: 2.7816e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1000/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 4.3175e-04 - accuracy: 3.7274e-05 - val_loss: 7.5952e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1001/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5620e-04 - accuracy: 2.0415e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1002/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8114e-04 - accuracy: 1.5427e-04 - val_loss: 6.3081e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1003/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.6152e-04 - accuracy: 8.2668e-04 - val_loss: 8.3729e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1004/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9662e-04 - accuracy: 3.2070e-04 - val_loss: 6.5946e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1005/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7291e-04 - accuracy: 6.4853e-04 - val_loss: 6.0604e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1006/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9278e-04 - accuracy: 2.0415e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1007/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9654e-04 - accuracy: 8.7278e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1008/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5278e-04 - accuracy: 6.1911e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1009/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8844e-04 - accuracy: 9.7194e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1010/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0892e-04 - accuracy: 1.3098e-04 - val_loss: 8.0691e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1011/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2152e-04 - accuracy: 2.7394e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1012/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5463e-04 - accuracy: 0.0013 - val_loss: 9.1776e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1013/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4001e-04 - accuracy: 2.5923e-04 - val_loss: 7.8293e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1014/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9613e-04 - accuracy: 5.6475e-04 - val_loss: 7.5076e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1015/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.8054e-04 - accuracy: 1.9124e-04 - val_loss: 6.4316e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1016/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5491e-04 - accuracy: 5.9123e-04 - val_loss: 7.5557e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1017/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9034e-04 - accuracy: 1.6631e-04 - val_loss: 7.2681e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1018/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3812e-04 - accuracy: 8.7278e-05 - val_loss: 8.4701e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1019/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5905e-04 - accuracy: 9.7871e-05 - val_loss: 8.0948e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1020/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.7834e-04 - accuracy: 3.0465e-04 - val_loss: 7.7844e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1021/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6714e-04 - accuracy: 6.1911e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1022/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5700e-04 - accuracy: 0.0013 - val_loss: 7.8282e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1023/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3909e-04 - accuracy: 2.4492e-04 - val_loss: 7.7995e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1024/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.6036e-04 - accuracy: 3.7274e-05 - val_loss: 6.4008e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1025/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5754e-04 - accuracy: 2.5923e-04 - val_loss: 7.1437e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1026/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4992e-04 - accuracy: 6.6707e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1027/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9587e-04 - accuracy: 5.9123e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1028/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9525e-04 - accuracy: 8.7278e-05 - val_loss: 9.8576e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1029/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9557e-04 - accuracy: 2.1740e-04 - val_loss: 7.0223e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1030/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7174e-04 - accuracy: 4.6904e-05 - val_loss: 7.4161e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1031/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6942e-04 - accuracy: 2.5923e-04 - val_loss: 7.3062e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1032/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5812e-04 - accuracy: 8.7278e-05 - val_loss: 6.8134e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1033/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5731e-04 - accuracy: 1.3098e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1034/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9806e-04 - accuracy: 4.4917e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1035/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2663e-04 - accuracy: 9.7871e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1036/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4259e-04 - accuracy: 2.0415e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1037/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2992e-04 - accuracy: 4.4917e-04 - val_loss: 8.9409e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1038/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3056e-04 - accuracy: 7.8594e-04 - val_loss: 9.1828e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1039/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.4977e-04 - accuracy: 3.2070e-04 - val_loss: 7.8136e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1040/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8711e-04 - accuracy: 3.9026e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1041/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9553e-04 - accuracy: 2.3098e-04 - val_loss: 7.0274e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1042/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8435e-04 - accuracy: 2.8908e-04 - val_loss: 6.4076e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1043/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2398e-04 - accuracy: 5.1545e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 1044/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8260e-04 - accuracy: 9.1897e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1045/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0867e-04 - accuracy: 5.1545e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1046/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7298e-04 - accuracy: 1.0868e-04 - val_loss: 7.7572e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1047/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4415e-04 - accuracy: 4.0918e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1048/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.4831e-04 - accuracy: 6.4853e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1049/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0729e-04 - accuracy: 0.0014 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1050/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9210e-04 - accuracy: 2.8908e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1051/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4619e-04 - accuracy: 4.7035e-04 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 1052/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4600e-04 - accuracy: 9.1897e-04 - val_loss: 6.3613e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1053/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7515e-04 - accuracy: 2.7816e-05 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1054/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.8399e-04 - accuracy: 5.6713e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1055/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8146e-04 - accuracy: 2.7816e-05 - val_loss: 7.0011e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1056/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6279e-04 - accuracy: 1.0868e-04 - val_loss: 9.5892e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1057/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7544e-04 - accuracy: 5.6475e-04 - val_loss: 7.6455e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1058/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3539e-04 - accuracy: 2.8908e-04 - val_loss: 9.9530e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1059/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8858e-04 - accuracy: 2.7394e-04 - val_loss: 8.0159e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1060/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9352e-04 - accuracy: 7.8594e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1061/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9781e-04 - accuracy: 4.9242e-04 - val_loss: 9.5254e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1062/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8317e-04 - accuracy: 1.4250e-04 - val_loss: 9.5523e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1063/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6745e-04 - accuracy: 1.3098e-04 - val_loss: 8.7608e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1064/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5841e-04 - accuracy: 6.7969e-04 - val_loss: 9.6888e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1065/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8806e-04 - accuracy: 2.7816e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1066/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.6049e-04 - accuracy: 4.6904e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1067/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3382e-04 - accuracy: 0.0015 - val_loss: 7.5231e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1068/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3493e-04 - accuracy: 1.9124e-04 - val_loss: 6.7424e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1069/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9664e-04 - accuracy: 2.7394e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1070/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8601e-04 - accuracy: 6.7969e-04 - val_loss: 7.0308e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1071/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6830e-04 - accuracy: 9.7871e-05 - val_loss: 9.2467e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1072/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5445e-04 - accuracy: 9.7194e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1073/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6102e-04 - accuracy: 2.7394e-04 - val_loss: 9.7231e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1074/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6767e-04 - accuracy: 1.5427e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1075/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7037e-04 - accuracy: 3.7200e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1076/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.7095e-04 - accuracy: 1.5427e-04 - val_loss: 7.7065e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1077/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3471e-04 - accuracy: 0.0011 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1078/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5304e-04 - accuracy: 0.0010 - val_loss: 7.5166e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1079/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7442e-04 - accuracy: 4.4917e-04 - val_loss: 8.7831e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1080/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3865e-04 - accuracy: 9.7871e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1081/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7271e-04 - accuracy: 1.4250e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1082/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9135e-04 - accuracy: 8.7278e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1083/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5646e-04 - accuracy: 3.3726e-04 - val_loss: 7.9630e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1084/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3685e-04 - accuracy: 2.1740e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1085/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7079e-04 - accuracy: 5.1545e-04 - val_loss: 9.9480e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1086/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.9704e-04 - accuracy: 5.1545e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1087/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0910e-04 - accuracy: 4.4917e-04 - val_loss: 9.5426e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1088/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5617e-04 - accuracy: 5.1545e-04 - val_loss: 8.7384e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1089/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4164e-04 - accuracy: 6.6707e-05 - val_loss: 8.2646e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1090/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0134e-04 - accuracy: 8.2668e-04 - val_loss: 9.5374e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1091/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.8177e-04 - accuracy: 0.0013 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1092/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5966e-04 - accuracy: 2.7816e-05 - val_loss: 8.9397e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1093/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4079e-04 - accuracy: 2.4492e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1094/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3123e-04 - accuracy: 1.3098e-04 - val_loss: 7.8685e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1095/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5366e-04 - accuracy: 6.6707e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1096/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7427e-04 - accuracy: 0.0012 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1097/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3930e-04 - accuracy: 6.4853e-04 - val_loss: 8.6119e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1098/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2211e-04 - accuracy: 0.0012 - val_loss: 8.8510e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1099/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1781e-04 - accuracy: 1.0868e-04 - val_loss: 7.1584e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1100/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0714e-04 - accuracy: 4.6904e-05 - val_loss: 7.4336e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1101/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9047e-04 - accuracy: 6.6707e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1102/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0906e-04 - accuracy: 8.7278e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1103/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.6706e-04 - accuracy: 3.9026e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1104/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4379e-04 - accuracy: 2.5923e-04 - val_loss: 9.9122e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1105/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.3716e-04 - accuracy: 1.4250e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1106/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3894e-04 - accuracy: 1.5427e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1107/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1469e-04 - accuracy: 0.0017 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 1108/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8174e-04 - accuracy: 1.0868e-04 - val_loss: 7.5714e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1109/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7742e-04 - accuracy: 2.4492e-04 - val_loss: 6.7749e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1110/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.6521e-04 - accuracy: 7.6892e-05 - val_loss: 8.6997e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1111/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4518e-04 - accuracy: 5.6713e-05 - val_loss: 7.5803e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1112/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5026e-04 - accuracy: 0.0010 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1113/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8728e-04 - accuracy: 5.6475e-04 - val_loss: 6.5279e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1114/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3060e-04 - accuracy: 2.3098e-04 - val_loss: 7.5405e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1115/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7156e-04 - accuracy: 5.9123e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1116/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2493e-04 - accuracy: 1.4250e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1117/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2791e-04 - accuracy: 4.4917e-04 - val_loss: 7.3252e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1118/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9833e-04 - accuracy: 3.0465e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1119/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9136e-04 - accuracy: 2.1740e-04 - val_loss: 7.4411e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1120/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2505e-04 - accuracy: 5.3953e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1121/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.7624e-04 - accuracy: 5.6713e-05 - val_loss: 9.3365e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1122/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6618e-04 - accuracy: 2.8908e-04 - val_loss: 9.6411e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1123/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9506e-04 - accuracy: 3.2070e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1124/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7437e-04 - accuracy: 9.7194e-04 - val_loss: 7.5845e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1125/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4944e-04 - accuracy: 8.7082e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1126/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7463e-04 - accuracy: 1.9124e-04 - val_loss: 6.6107e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1127/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4297e-04 - accuracy: 1.1972e-04 - val_loss: 8.9991e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1128/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6718e-04 - accuracy: 1.5427e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1129/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.0732e-04 - accuracy: 1.9124e-04 - val_loss: 7.6485e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1130/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4018e-04 - accuracy: 4.0918e-04 - val_loss: 6.9739e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1131/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.4492e-04 - accuracy: 0.0010 - val_loss: 5.4826e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1132/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3918e-04 - accuracy: 6.4853e-04 - val_loss: 9.3325e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1133/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.4227e-04 - accuracy: 2.7394e-04 - val_loss: 6.3185e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1134/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7188e-04 - accuracy: 7.6892e-05 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 1135/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8744e-04 - accuracy: 2.8908e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1136/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6388e-04 - accuracy: 6.4853e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1137/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2823e-04 - accuracy: 5.3953e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1138/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8908e-04 - accuracy: 9.7871e-05 - val_loss: 7.4273e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1139/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7672e-04 - accuracy: 0.0013 - val_loss: 6.7595e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1140/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4093e-04 - accuracy: 5.6475e-04 - val_loss: 9.0291e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1141/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4465e-04 - accuracy: 1.9124e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1142/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2188e-04 - accuracy: 3.3726e-04 - val_loss: 7.0331e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1143/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.2872e-04 - accuracy: 5.3953e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1144/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7461e-04 - accuracy: 4.4917e-04 - val_loss: 9.3462e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1145/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7321e-04 - accuracy: 7.8594e-04 - val_loss: 9.5419e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1146/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.3123e-04 - accuracy: 1.9124e-04 - val_loss: 6.5251e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1147/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4752e-04 - accuracy: 7.1279e-04 - val_loss: 8.2348e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1148/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9156e-04 - accuracy: 7.4811e-04 - val_loss: 7.2779e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1149/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.5793e-04 - accuracy: 3.7200e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1150/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7187e-04 - accuracy: 7.1279e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1151/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9437e-04 - accuracy: 9.7871e-05 - val_loss: 7.2153e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1152/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.8811e-04 - accuracy: 3.5434e-04 - val_loss: 8.2956e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1153/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2060e-04 - accuracy: 2.1740e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1154/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.1360e-04 - accuracy: 0.0013 - val_loss: 6.3787e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1155/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6270e-04 - accuracy: 7.1279e-04 - val_loss: 8.0795e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1156/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5232e-04 - accuracy: 1.6631e-04 - val_loss: 7.0586e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1157/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3898e-04 - accuracy: 4.9242e-04 - val_loss: 7.5233e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1158/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1568e-04 - accuracy: 2.0415e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1159/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6739e-04 - accuracy: 1.3098e-04 - val_loss: 7.0895e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1160/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3701e-04 - accuracy: 4.9242e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1161/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4251e-04 - accuracy: 3.7274e-05 - val_loss: 7.4487e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1162/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2450e-04 - accuracy: 9.7194e-04 - val_loss: 6.3155e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1163/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5571e-04 - accuracy: 3.2070e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1164/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3.6180e-04 - accuracy: 2.0415e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1165/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5260e-04 - accuracy: 6.4853e-04 - val_loss: 8.4321e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1166/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5913e-04 - accuracy: 2.7394e-04 - val_loss: 7.8513e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1167/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2255e-04 - accuracy: 3.5434e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1168/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5377e-04 - accuracy: 0.0019 - val_loss: 8.6418e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1169/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6148e-04 - accuracy: 0.0025 - val_loss: 8.6717e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1170/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9951e-04 - accuracy: 6.4853e-04 - val_loss: 7.8733e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1171/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4435e-04 - accuracy: 3.7274e-05 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1172/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4057e-04 - accuracy: 2.1740e-04 - val_loss: 7.5253e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1173/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3400e-04 - accuracy: 6.4853e-04 - val_loss: 8.6838e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1174/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5188e-04 - accuracy: 4.2880e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1175/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2961e-04 - accuracy: 6.1911e-04 - val_loss: 7.4741e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1176/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3639e-04 - accuracy: 1.6631e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1177/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4383e-04 - accuracy: 9.7871e-05 - val_loss: 6.4550e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1178/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4010e-04 - accuracy: 4.0918e-04 - val_loss: 6.9350e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1179/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.8539e-04 - accuracy: 0.0010 - val_loss: 6.6761e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1180/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2072e-04 - accuracy: 7.4811e-04 - val_loss: 7.2736e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1181/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.9923e-04 - accuracy: 3.5434e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1182/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3145e-04 - accuracy: 2.7816e-05 - val_loss: 6.7335e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1183/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4438e-04 - accuracy: 2.1740e-04 - val_loss: 7.1183e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1184/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.4109e-04 - accuracy: 4.6904e-05 - val_loss: 7.3546e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1185/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5164e-04 - accuracy: 9.7194e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1186/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8730e-04 - accuracy: 6.4853e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1187/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6657e-04 - accuracy: 0.0014 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1188/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5224e-04 - accuracy: 3.9026e-04 - val_loss: 6.6649e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1189/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0353e-04 - accuracy: 1.0868e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1190/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.3995e-04 - accuracy: 3.9026e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1191/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.4836e-04 - accuracy: 8.7278e-05 - val_loss: 7.2644e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1192/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2703e-04 - accuracy: 2.7394e-04 - val_loss: 8.2300e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1193/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2376e-04 - accuracy: 1.6631e-04 - val_loss: 5.9604e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1194/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3884e-04 - accuracy: 0.0025 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1195/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8462e-04 - accuracy: 4.7035e-04 - val_loss: 7.7000e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1196/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1307e-04 - accuracy: 0.0012 - val_loss: 7.3650e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1197/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6100e-04 - accuracy: 3.2070e-04 - val_loss: 6.5567e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1198/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9742e-04 - accuracy: 2.7394e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1199/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0719e-04 - accuracy: 8.7278e-05 - val_loss: 9.5554e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1200/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2135e-04 - accuracy: 0.0011 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1201/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3815e-04 - accuracy: 4.7035e-04 - val_loss: 7.9767e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1202/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4697e-04 - accuracy: 2.4492e-04 - val_loss: 6.7059e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1203/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3818e-04 - accuracy: 7.6892e-05 - val_loss: 8.7967e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1204/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1719e-04 - accuracy: 2.7394e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1205/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.2650e-04 - accuracy: 0.0011 - val_loss: 8.6208e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1206/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3241e-04 - accuracy: 0.0012 - val_loss: 8.1409e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1207/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0758e-04 - accuracy: 1.5427e-04 - val_loss: 7.4887e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1208/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6751e-04 - accuracy: 0.0011 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1209/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3681e-04 - accuracy: 4.4917e-04 - val_loss: 7.1087e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1210/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4051e-04 - accuracy: 1.9124e-04 - val_loss: 6.8696e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1211/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2203e-04 - accuracy: 7.1279e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1212/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3872e-04 - accuracy: 2.0415e-04 - val_loss: 7.1972e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1213/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5337e-04 - accuracy: 1.3098e-04 - val_loss: 6.2639e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1214/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.2439e-04 - accuracy: 5.9123e-04 - val_loss: 7.8816e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1215/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2042e-04 - accuracy: 3.0465e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1216/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4939e-04 - accuracy: 1.6631e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1217/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5728e-04 - accuracy: 1.6631e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1218/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3712e-04 - accuracy: 1.3098e-04 - val_loss: 7.6139e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1219/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.6718e-04 - accuracy: 1.9124e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 1220/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.4619e-04 - accuracy: 3.9026e-04 - val_loss: 7.4486e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1221/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2478e-04 - accuracy: 9.7871e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1222/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.1775e-04 - accuracy: 1.5427e-04 - val_loss: 8.4228e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1223/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6437e-04 - accuracy: 2.8908e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1224/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8531e-04 - accuracy: 0.0012 - val_loss: 6.5087e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1225/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2117e-04 - accuracy: 8.7278e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1226/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6354e-04 - accuracy: 0.0013 - val_loss: 9.9434e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1227/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4304e-04 - accuracy: 3.3726e-04 - val_loss: 7.7057e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1228/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5316e-04 - accuracy: 4.7035e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1229/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.9177e-04 - accuracy: 2.3098e-04 - val_loss: 7.0432e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1230/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3273e-04 - accuracy: 6.4853e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1231/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 4.2156e-04 - accuracy: 4.6904e-05 - val_loss: 6.3000e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1232/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2685e-04 - accuracy: 1.4250e-04 - val_loss: 7.1291e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1233/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.6981e-04 - accuracy: 3.7200e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1234/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3993e-04 - accuracy: 2.7816e-05 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1235/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5576e-04 - accuracy: 0.0015 - val_loss: 9.9850e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1236/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0507e-04 - accuracy: 1.5427e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1237/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.6313e-04 - accuracy: 3.0465e-04 - val_loss: 7.9957e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1238/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6534e-04 - accuracy: 9.7871e-05 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1239/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6898e-04 - accuracy: 6.6707e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1240/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3306e-04 - accuracy: 2.5923e-04 - val_loss: 5.9001e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1241/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4099e-04 - accuracy: 0.0014 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1242/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6053e-04 - accuracy: 1.5427e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1243/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4204e-04 - accuracy: 1.9124e-04 - val_loss: 6.9406e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1244/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3720e-04 - accuracy: 7.1279e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1245/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3424e-04 - accuracy: 3.2070e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1246/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4006e-04 - accuracy: 1.5427e-04 - val_loss: 6.6590e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1247/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7177e-04 - accuracy: 0.0012 - val_loss: 6.1428e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1248/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5780e-04 - accuracy: 4.4917e-04 - val_loss: 7.3647e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1249/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4100e-04 - accuracy: 0.0010 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1250/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6069e-04 - accuracy: 3.3726e-04 - val_loss: 7.0741e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1251/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0814e-04 - accuracy: 5.3953e-04 - val_loss: 8.3135e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1252/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4825e-04 - accuracy: 4.4917e-04 - val_loss: 7.6699e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1253/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.1683e-04 - accuracy: 2.8908e-04 - val_loss: 8.1583e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1254/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3265e-04 - accuracy: 1.7862e-04 - val_loss: 9.9430e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1255/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6016e-04 - accuracy: 9.7871e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1256/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4389e-04 - accuracy: 4.0918e-04 - val_loss: 8.5751e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1257/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2052e-04 - accuracy: 3.3726e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1258/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6496e-04 - accuracy: 1.9124e-04 - val_loss: 9.6735e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1259/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2608e-04 - accuracy: 8.7278e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1260/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1296e-04 - accuracy: 9.7194e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1261/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4584e-04 - accuracy: 0.0012 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1262/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4272e-04 - accuracy: 0.0015 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1263/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0404e-04 - accuracy: 2.1740e-04 - val_loss: 7.5827e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1264/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0816e-04 - accuracy: 5.9123e-04 - val_loss: 8.6958e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1265/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6418e-04 - accuracy: 0.0012 - val_loss: 7.5482e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1266/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5541e-04 - accuracy: 4.0918e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1267/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4304e-04 - accuracy: 3.7200e-04 - val_loss: 7.0140e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1268/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3796e-04 - accuracy: 1.4250e-04 - val_loss: 8.2529e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1269/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5779e-04 - accuracy: 1.5427e-04 - val_loss: 7.5968e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1270/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.0752e-04 - accuracy: 4.4917e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1271/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2626e-04 - accuracy: 0.0025 - val_loss: 6.9279e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1272/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2335e-04 - accuracy: 0.0013 - val_loss: 6.5649e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1273/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0983e-04 - accuracy: 4.0918e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1274/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5975e-04 - accuracy: 7.1279e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1275/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4559e-04 - accuracy: 6.1911e-04 - val_loss: 8.4519e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1276/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1586e-04 - accuracy: 2.4492e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1277/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5776e-04 - accuracy: 0.0013 - val_loss: 6.9162e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1278/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4444e-04 - accuracy: 0.0011 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1279/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5010e-04 - accuracy: 2.7816e-05 - val_loss: 8.6618e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1280/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7875e-04 - accuracy: 0.0019 - val_loss: 8.2977e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1281/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7237e-04 - accuracy: 2.3098e-04 - val_loss: 6.8178e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1282/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2623e-04 - accuracy: 8.7278e-05 - val_loss: 9.9011e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1283/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4089e-04 - accuracy: 1.3098e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1284/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.3503e-04 - accuracy: 1.3098e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1285/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2078e-04 - accuracy: 3.2070e-04 - val_loss: 7.8484e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1286/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1882e-04 - accuracy: 9.1897e-04 - val_loss: 6.7809e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1287/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5180e-04 - accuracy: 9.7194e-04 - val_loss: 5.9871e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1288/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2400e-04 - accuracy: 0.0012 - val_loss: 9.0051e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1289/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3252e-04 - accuracy: 0.0013 - val_loss: 7.1991e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1290/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1969e-04 - accuracy: 7.1279e-04 - val_loss: 7.8528e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1291/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.7811e-04 - accuracy: 0.0019 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1292/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3831e-04 - accuracy: 1.3098e-04 - val_loss: 8.5020e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1293/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4737e-04 - accuracy: 5.3953e-04 - val_loss: 9.0047e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1294/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4323e-04 - accuracy: 4.7035e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1295/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.4682e-04 - accuracy: 8.7082e-04 - val_loss: 6.7564e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1296/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4458e-04 - accuracy: 4.4917e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1297/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1628e-04 - accuracy: 0.0012 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1298/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3859e-04 - accuracy: 4.4917e-04 - val_loss: 8.3269e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1299/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2635e-04 - accuracy: 2.7394e-04 - val_loss: 9.0976e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1300/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5669e-04 - accuracy: 3.2070e-04 - val_loss: 7.3457e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1301/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4960e-04 - accuracy: 2.4492e-04 - val_loss: 7.2871e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1302/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2768e-04 - accuracy: 1.1972e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1303/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1208e-04 - accuracy: 4.2880e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1304/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4459e-04 - accuracy: 0.0015 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1305/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3405e-04 - accuracy: 4.0918e-04 - val_loss: 8.0972e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1306/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2742e-04 - accuracy: 6.6707e-05 - val_loss: 9.5768e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1307/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3485e-04 - accuracy: 0.0025 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1308/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9727e-04 - accuracy: 0.0019 - val_loss: 7.4286e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1309/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9570e-04 - accuracy: 4.4917e-04 - val_loss: 8.7116e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1310/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0892e-04 - accuracy: 0.0019 - val_loss: 9.0692e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1311/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0580e-04 - accuracy: 0.0025 - val_loss: 7.1949e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1312/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5414e-04 - accuracy: 4.6904e-05 - val_loss: 6.3479e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1313/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 4.0748e-04 - accuracy: 9.7194e-04 - val_loss: 7.0858e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1314/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 2.6686e-04 - accuracy: 6.4853e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1315/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4838e-04 - accuracy: 4.0918e-04 - val_loss: 8.1719e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1316/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2263e-04 - accuracy: 7.8594e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1317/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4152e-04 - accuracy: 0.0014 - val_loss: 6.6647e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1318/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5703e-04 - accuracy: 5.1545e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1319/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4187e-04 - accuracy: 4.2880e-04 - val_loss: 7.5825e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1320/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1198e-04 - accuracy: 7.6892e-05 - val_loss: 8.8844e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1321/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0821e-04 - accuracy: 3.2070e-04 - val_loss: 7.0091e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1322/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2188e-04 - accuracy: 1.5427e-04 - val_loss: 6.7836e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1323/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8197e-04 - accuracy: 6.6707e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1324/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5053e-04 - accuracy: 1.1972e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1325/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4202e-04 - accuracy: 2.0415e-04 - val_loss: 7.0949e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1326/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5936e-04 - accuracy: 7.4811e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1327/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0907e-04 - accuracy: 4.7035e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1328/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3708e-04 - accuracy: 8.7082e-04 - val_loss: 5.5930e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1329/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0025e-04 - accuracy: 0.0013 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1330/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2186e-04 - accuracy: 2.5923e-04 - val_loss: 6.7919e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1331/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5697e-04 - accuracy: 6.7969e-04 - val_loss: 6.0943e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1332/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2703e-04 - accuracy: 2.5923e-04 - val_loss: 7.3588e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1333/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7957e-04 - accuracy: 2.3098e-04 - val_loss: 8.3855e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1334/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1475e-04 - accuracy: 1.9124e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1335/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1580e-04 - accuracy: 6.4853e-04 - val_loss: 9.1056e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1336/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2021e-04 - accuracy: 2.8908e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1337/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3744e-04 - accuracy: 2.4492e-04 - val_loss: 9.2663e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1338/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2988e-04 - accuracy: 6.1911e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1339/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1267e-04 - accuracy: 3.0465e-04 - val_loss: 9.2777e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1340/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9927e-04 - accuracy: 2.1740e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1341/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4910e-04 - accuracy: 6.4853e-04 - val_loss: 7.4295e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1342/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3601e-04 - accuracy: 2.4492e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1343/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4258e-04 - accuracy: 3.9026e-04 - val_loss: 8.4983e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1344/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2860e-04 - accuracy: 8.7082e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1345/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1639e-04 - accuracy: 2.3098e-04 - val_loss: 7.0407e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1346/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9604e-04 - accuracy: 8.7082e-04 - val_loss: 9.2260e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1347/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2244e-04 - accuracy: 0.0013 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1348/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9956e-04 - accuracy: 6.6707e-05 - val_loss: 8.7318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1349/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1804e-04 - accuracy: 0.0011 - val_loss: 8.6765e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1350/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0521e-04 - accuracy: 2.7816e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1351/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0072e-04 - accuracy: 9.7194e-04 - val_loss: 8.4768e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1352/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3523e-04 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1353/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.1153e-04 - accuracy: 2.1740e-04 - val_loss: 8.2608e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1354/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3219e-04 - accuracy: 0.0012 - val_loss: 7.4873e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1355/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0678e-04 - accuracy: 5.1545e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1356/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3805e-04 - accuracy: 1.6631e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1357/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9836e-04 - accuracy: 2.0415e-04 - val_loss: 6.9089e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1358/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9532e-04 - accuracy: 2.0415e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1359/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0570e-04 - accuracy: 2.5923e-04 - val_loss: 9.3211e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1360/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9260e-04 - accuracy: 2.4492e-04 - val_loss: 6.2511e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1361/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9700e-04 - accuracy: 5.6475e-04 - val_loss: 8.2770e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1362/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5539e-04 - accuracy: 3.2070e-04 - val_loss: 9.1334e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1363/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5423e-04 - accuracy: 2.0415e-04 - val_loss: 9.4614e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1364/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0960e-04 - accuracy: 0.0011 - val_loss: 5.8026e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1365/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2231e-04 - accuracy: 4.9242e-04 - val_loss: 6.9944e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1366/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8217e-04 - accuracy: 0.0010 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1367/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2003e-04 - accuracy: 0.0015 - val_loss: 7.3473e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1368/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9683e-04 - accuracy: 8.7278e-05 - val_loss: 8.5996e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1369/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3975e-04 - accuracy: 7.4811e-04 - val_loss: 8.6127e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1370/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0317e-04 - accuracy: 6.7969e-04 - val_loss: 9.4002e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1371/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4852e-04 - accuracy: 9.7194e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1372/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.8992e-04 - accuracy: 5.1545e-04 - val_loss: 8.7220e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1373/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9769e-04 - accuracy: 5.9123e-04 - val_loss: 8.8367e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1374/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5025e-04 - accuracy: 1.6631e-04 - val_loss: 7.9332e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1375/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9656e-04 - accuracy: 4.7035e-04 - val_loss: 7.9159e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1376/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9955e-04 - accuracy: 7.1279e-04 - val_loss: 6.5632e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1377/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0368e-04 - accuracy: 4.0918e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1378/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3070e-04 - accuracy: 9.1897e-04 - val_loss: 7.9798e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1379/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0282e-04 - accuracy: 3.7200e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1380/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3231e-04 - accuracy: 5.1545e-04 - val_loss: 6.6196e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1381/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3153e-04 - accuracy: 2.8908e-04 - val_loss: 7.8190e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1382/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0155e-04 - accuracy: 6.6707e-05 - val_loss: 7.5588e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1383/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9632e-04 - accuracy: 1.9124e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1384/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0963e-04 - accuracy: 6.7969e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1385/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8808e-04 - accuracy: 9.1897e-04 - val_loss: 9.1386e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1386/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0405e-04 - accuracy: 8.2668e-04 - val_loss: 7.0168e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1387/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8790e-04 - accuracy: 6.7969e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1388/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5663e-04 - accuracy: 0.0017 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 1389/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3039e-04 - accuracy: 5.3953e-04 - val_loss: 7.5858e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1390/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0155e-04 - accuracy: 2.3098e-04 - val_loss: 8.3218e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1391/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0213e-04 - accuracy: 3.7274e-05 - val_loss: 7.0837e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1392/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0019e-04 - accuracy: 0.0019 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1393/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4129e-04 - accuracy: 9.7194e-04 - val_loss: 5.7947e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1394/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6897e-04 - accuracy: 6.6707e-05 - val_loss: 9.6515e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1395/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0686e-04 - accuracy: 2.8908e-04 - val_loss: 6.8290e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1396/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0707e-04 - accuracy: 2.7816e-05 - val_loss: 9.7149e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1397/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0029e-04 - accuracy: 4.7035e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1398/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0508e-04 - accuracy: 4.4917e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1399/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1732e-04 - accuracy: 3.5434e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1400/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 2.9546e-04 - accuracy: 0.0013 - val_loss: 8.3029e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1401/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0596e-04 - accuracy: 9.7871e-05 - val_loss: 8.1332e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1402/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0085e-04 - accuracy: 9.7194e-04 - val_loss: 8.3743e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1403/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2117e-04 - accuracy: 6.1911e-04 - val_loss: 9.3132e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1404/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0477e-04 - accuracy: 8.7082e-04 - val_loss: 9.7901e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1405/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8774e-04 - accuracy: 2.1740e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1406/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3612e-04 - accuracy: 6.1911e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1407/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0698e-04 - accuracy: 2.1740e-04 - val_loss: 8.5977e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1408/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9569e-04 - accuracy: 8.7278e-05 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1409/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3266e-04 - accuracy: 4.0918e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1410/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0398e-04 - accuracy: 2.8908e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 1411/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1146e-04 - accuracy: 4.9242e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1412/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0171e-04 - accuracy: 4.6904e-05 - val_loss: 8.0686e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1413/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5120e-04 - accuracy: 2.4492e-04 - val_loss: 9.6630e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1414/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.0273e-04 - accuracy: 1.9124e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1415/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0687e-04 - accuracy: 2.0415e-04 - val_loss: 8.9985e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1416/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0429e-04 - accuracy: 0.0017 - val_loss: 6.9550e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1417/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6419e-04 - accuracy: 6.1911e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1418/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9488e-04 - accuracy: 4.9242e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1419/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9649e-04 - accuracy: 6.4853e-04 - val_loss: 9.2939e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1420/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1627e-04 - accuracy: 1.1972e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1421/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8355e-04 - accuracy: 3.0465e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1422/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1454e-04 - accuracy: 5.6475e-04 - val_loss: 9.9040e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1423/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3498e-04 - accuracy: 2.0415e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1424/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1804e-04 - accuracy: 6.6707e-05 - val_loss: 9.8365e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1425/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2700e-04 - accuracy: 1.4250e-04 - val_loss: 7.3448e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1426/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8980e-04 - accuracy: 3.0465e-04 - val_loss: 6.0799e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1427/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0683e-04 - accuracy: 1.7862e-04 - val_loss: 6.8240e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1428/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1155e-04 - accuracy: 3.2070e-04 - val_loss: 9.1607e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1429/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1014e-04 - accuracy: 9.7871e-05 - val_loss: 7.9030e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1430/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2193e-04 - accuracy: 3.7200e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1431/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8039e-04 - accuracy: 5.9123e-04 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 1432/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2097e-04 - accuracy: 6.6707e-05 - val_loss: 6.8477e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1433/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9397e-04 - accuracy: 2.3098e-04 - val_loss: 9.0337e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1434/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1040e-04 - accuracy: 8.7278e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1435/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4187e-04 - accuracy: 5.1545e-04 - val_loss: 7.4284e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1436/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0593e-04 - accuracy: 8.2668e-04 - val_loss: 5.5900e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1437/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3872e-04 - accuracy: 8.7082e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1438/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5576e-04 - accuracy: 1.0868e-04 - val_loss: 7.8449e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1439/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9171e-04 - accuracy: 0.0011 - val_loss: 8.0660e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1440/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2869e-04 - accuracy: 6.6707e-05 - val_loss: 9.3694e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1441/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0465e-04 - accuracy: 6.7969e-04 - val_loss: 8.7689e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1442/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1933e-04 - accuracy: 6.6707e-05 - val_loss: 9.5530e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1443/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2501e-04 - accuracy: 4.7035e-04 - val_loss: 8.7491e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1444/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9626e-04 - accuracy: 8.2668e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1445/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0336e-04 - accuracy: 5.3953e-04 - val_loss: 8.1633e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1446/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0851e-04 - accuracy: 0.0013 - val_loss: 5.3579e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1447/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1213e-04 - accuracy: 7.1279e-04 - val_loss: 7.1103e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1448/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2875e-04 - accuracy: 6.4853e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1449/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8321e-04 - accuracy: 4.4917e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1450/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8700e-04 - accuracy: 3.5434e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1451/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2846e-04 - accuracy: 2.7394e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1452/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1145e-04 - accuracy: 0.0019 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1453/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9318e-04 - accuracy: 2.7394e-04 - val_loss: 6.8081e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1454/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1359e-04 - accuracy: 1.9124e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 1455/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2051e-04 - accuracy: 1.7862e-04 - val_loss: 8.5879e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1456/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0717e-04 - accuracy: 2.3098e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1457/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9566e-04 - accuracy: 2.0415e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 1458/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3687e-04 - accuracy: 4.6904e-05 - val_loss: 8.6456e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1459/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3192e-04 - accuracy: 4.7035e-04 - val_loss: 8.6524e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1460/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1010e-04 - accuracy: 4.0918e-04 - val_loss: 7.1749e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1461/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7784e-04 - accuracy: 3.5434e-04 - val_loss: 7.5608e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1462/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7290e-04 - accuracy: 4.2880e-04 - val_loss: 5.5228e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1463/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0363e-04 - accuracy: 3.5434e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1464/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8348e-04 - accuracy: 2.1740e-04 - val_loss: 9.9379e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1465/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1030e-04 - accuracy: 7.1279e-04 - val_loss: 5.4945e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1466/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0997e-04 - accuracy: 7.4811e-04 - val_loss: 5.4338e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1467/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3372e-04 - accuracy: 6.4853e-04 - val_loss: 7.0763e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1468/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2018e-04 - accuracy: 1.3098e-04 - val_loss: 5.3255e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1469/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0720e-04 - accuracy: 4.7035e-04 - val_loss: 6.7185e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1470/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6745e-04 - accuracy: 5.6713e-05 - val_loss: 6.0233e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1471/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2389e-04 - accuracy: 0.0015 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1472/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3460e-04 - accuracy: 4.2880e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1473/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1479e-04 - accuracy: 2.3098e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1474/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0784e-04 - accuracy: 3.3726e-04 - val_loss: 7.5540e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1475/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8193e-04 - accuracy: 2.7816e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1476/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3877e-04 - accuracy: 6.1911e-04 - val_loss: 5.9602e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1477/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9363e-04 - accuracy: 0.0014 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1478/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2723e-04 - accuracy: 4.2880e-04 - val_loss: 7.0040e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1479/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1246e-04 - accuracy: 2.0415e-04 - val_loss: 6.8715e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1480/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0676e-04 - accuracy: 1.4250e-04 - val_loss: 6.2386e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1481/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8882e-04 - accuracy: 3.0465e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1482/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 3.1073e-04 - accuracy: 9.1897e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1483/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8441e-04 - accuracy: 6.1911e-04 - val_loss: 8.4853e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1484/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9582e-04 - accuracy: 1.7862e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1485/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8006e-04 - accuracy: 1.9124e-04 - val_loss: 9.6867e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1486/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3127e-04 - accuracy: 1.7862e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1487/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3685e-04 - accuracy: 8.2668e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1488/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8043e-04 - accuracy: 0.0025 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1489/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.3416e-04 - accuracy: 0.0025 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1490/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4987e-04 - accuracy: 7.8594e-04 - val_loss: 5.3440e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1491/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8040e-04 - accuracy: 8.2668e-04 - val_loss: 6.3089e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1492/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1117e-04 - accuracy: 9.7194e-04 - val_loss: 6.7712e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1493/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8305e-04 - accuracy: 5.9123e-04 - val_loss: 7.4958e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1494/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.5665e-04 - accuracy: 6.4853e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1495/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2415e-04 - accuracy: 6.4853e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1496/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2098e-04 - accuracy: 2.7394e-04 - val_loss: 0.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 1497/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.5577e-04 - accuracy: 2.0415e-04 - val_loss: 7.7226e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1498/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9291e-04 - accuracy: 4.4917e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1499/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0380e-04 - accuracy: 1.1972e-04 - val_loss: 6.5250e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1500/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9536e-04 - accuracy: 1.4250e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1501/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1919e-04 - accuracy: 0.0017 - val_loss: 8.2987e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1502/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8867e-04 - accuracy: 8.2668e-04 - val_loss: 8.0793e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1503/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1493e-04 - accuracy: 9.7194e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1504/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0866e-04 - accuracy: 1.0868e-04 - val_loss: 6.8669e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1505/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8589e-04 - accuracy: 8.7278e-05 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1506/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9789e-04 - accuracy: 4.6904e-05 - val_loss: 5.5166e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1507/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7880e-04 - accuracy: 6.1911e-04 - val_loss: 7.1284e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1508/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1188e-04 - accuracy: 2.1740e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1509/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1814e-04 - accuracy: 2.1740e-04 - val_loss: 6.4671e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1510/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8563e-04 - accuracy: 0.0017 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1511/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2399e-04 - accuracy: 6.6707e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1512/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1107e-04 - accuracy: 9.1897e-04 - val_loss: 6.5646e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1513/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9991e-04 - accuracy: 6.6707e-05 - val_loss: 8.9799e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1514/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4878e-04 - accuracy: 1.3098e-04 - val_loss: 7.6028e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1515/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0986e-04 - accuracy: 0.0019 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1516/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8746e-04 - accuracy: 6.4853e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1517/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9551e-04 - accuracy: 2.8908e-04 - val_loss: 6.8550e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1518/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0633e-04 - accuracy: 4.9242e-04 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1519/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0823e-04 - accuracy: 3.2070e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1520/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9748e-04 - accuracy: 3.9026e-04 - val_loss: 6.0446e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1521/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9689e-04 - accuracy: 1.5427e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 1522/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1873e-04 - accuracy: 3.0465e-04 - val_loss: 6.5855e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1523/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9890e-04 - accuracy: 9.7194e-04 - val_loss: 9.3411e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1524/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9015e-04 - accuracy: 2.0415e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1525/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9664e-04 - accuracy: 3.7274e-05 - val_loss: 8.1698e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1526/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0815e-04 - accuracy: 7.6892e-05 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 1527/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0525e-04 - accuracy: 5.3953e-04 - val_loss: 4.8734e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1528/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8158e-04 - accuracy: 0.0019 - val_loss: 7.1826e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1529/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8767e-04 - accuracy: 0.0010 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1530/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6033e-04 - accuracy: 4.6904e-05 - val_loss: 8.6101e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1531/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7876e-04 - accuracy: 2.5923e-04 - val_loss: 5.7155e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1532/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8818e-04 - accuracy: 5.6475e-04 - val_loss: 7.6193e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1533/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7618e-04 - accuracy: 6.4853e-04 - val_loss: 9.7244e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1534/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8922e-04 - accuracy: 0.0014 - val_loss: 6.3187e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1535/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7677e-04 - accuracy: 0.0019 - val_loss: 6.3333e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1536/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8856e-04 - accuracy: 2.0415e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1537/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2036e-04 - accuracy: 5.3953e-04 - val_loss: 5.7235e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1538/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1146e-04 - accuracy: 4.4917e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1539/2000\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.7466e-04 - accuracy: 3.3726e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1540/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9937e-04 - accuracy: 3.2070e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1541/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1215e-04 - accuracy: 1.4250e-04 - val_loss: 6.7496e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1542/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7884e-04 - accuracy: 2.0415e-04 - val_loss: 6.4989e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1543/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4334e-04 - accuracy: 4.4917e-04 - val_loss: 6.6332e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1544/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1332e-04 - accuracy: 1.4250e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1545/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9735e-04 - accuracy: 9.7871e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1546/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8823e-04 - accuracy: 1.6631e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1547/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6445e-04 - accuracy: 9.7871e-05 - val_loss: 7.1298e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1548/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1936e-04 - accuracy: 1.7862e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1549/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2686e-04 - accuracy: 0.0017 - val_loss: 7.1500e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1550/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0682e-04 - accuracy: 2.4492e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1551/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9658e-04 - accuracy: 1.5427e-04 - val_loss: 7.1122e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1552/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0014e-04 - accuracy: 3.2070e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1553/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9215e-04 - accuracy: 6.6707e-05 - val_loss: 8.3682e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1554/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9650e-04 - accuracy: 5.1545e-04 - val_loss: 7.2565e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1555/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0144e-04 - accuracy: 1.5427e-04 - val_loss: 7.1671e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1556/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8642e-04 - accuracy: 8.7278e-05 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1557/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1167e-04 - accuracy: 6.7969e-04 - val_loss: 7.1063e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1558/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1396e-04 - accuracy: 0.0025 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1559/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8228e-04 - accuracy: 4.0918e-04 - val_loss: 7.9800e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1560/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5309e-04 - accuracy: 3.5434e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1561/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6640e-04 - accuracy: 3.9026e-04 - val_loss: 8.7549e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1562/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0615e-04 - accuracy: 3.0465e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1563/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.6617e-04 - accuracy: 0.0025 - val_loss: 5.9897e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1564/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1051e-04 - accuracy: 2.7816e-05 - val_loss: 6.2833e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1565/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8171e-04 - accuracy: 4.0918e-04 - val_loss: 6.0471e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1566/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9599e-04 - accuracy: 7.8594e-04 - val_loss: 5.9627e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1567/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7461e-04 - accuracy: 3.9026e-04 - val_loss: 8.6362e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1568/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2070e-04 - accuracy: 7.4811e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1569/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4528e-04 - accuracy: 0.0014 - val_loss: 5.5562e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1570/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9463e-04 - accuracy: 5.9123e-04 - val_loss: 8.9816e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1571/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0370e-04 - accuracy: 5.3953e-04 - val_loss: 6.8413e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1572/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7832e-04 - accuracy: 0.0015 - val_loss: 9.3718e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1573/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8814e-04 - accuracy: 7.1279e-04 - val_loss: 8.5766e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1574/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6880e-04 - accuracy: 9.1897e-04 - val_loss: 6.3323e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1575/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6208e-04 - accuracy: 5.9123e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1576/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2292e-04 - accuracy: 4.6904e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1577/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5691e-04 - accuracy: 2.7816e-05 - val_loss: 8.1847e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1578/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8983e-04 - accuracy: 7.6892e-05 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1579/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0220e-04 - accuracy: 0.0017 - val_loss: 7.6550e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1580/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8755e-04 - accuracy: 3.0465e-04 - val_loss: 6.0921e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1581/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9441e-04 - accuracy: 9.7194e-04 - val_loss: 7.3174e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1582/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7240e-04 - accuracy: 1.0868e-04 - val_loss: 8.3256e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1583/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4941e-04 - accuracy: 4.4917e-04 - val_loss: 8.8331e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1584/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8292e-04 - accuracy: 8.7082e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1585/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8226e-04 - accuracy: 4.2880e-04 - val_loss: 7.0788e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1586/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0621e-04 - accuracy: 1.3098e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1587/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9204e-04 - accuracy: 1.9124e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1588/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8764e-04 - accuracy: 2.7816e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1589/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2702e-04 - accuracy: 1.5427e-04 - val_loss: 6.0086e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1590/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8892e-04 - accuracy: 0.0010 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1591/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1624e-04 - accuracy: 5.1545e-04 - val_loss: 6.9584e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1592/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7094e-04 - accuracy: 1.7862e-04 - val_loss: 5.9682e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1593/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9127e-04 - accuracy: 1.9124e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 1594/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7100e-04 - accuracy: 5.3953e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1595/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0423e-04 - accuracy: 9.7871e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1596/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8888e-04 - accuracy: 2.4492e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1597/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8417e-04 - accuracy: 2.0415e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1598/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3424e-04 - accuracy: 2.5923e-04 - val_loss: 9.6487e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1599/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7307e-04 - accuracy: 7.6892e-05 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1600/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6641e-04 - accuracy: 4.6904e-05 - val_loss: 6.5083e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1601/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9062e-04 - accuracy: 2.4492e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1602/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4161e-04 - accuracy: 3.0465e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1603/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.8668e-04 - accuracy: 8.7082e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1604/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7785e-04 - accuracy: 1.7862e-04 - val_loss: 6.1773e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1605/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0307e-04 - accuracy: 2.8908e-04 - val_loss: 6.5863e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1606/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5954e-04 - accuracy: 9.7194e-04 - val_loss: 7.7336e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1607/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8313e-04 - accuracy: 1.9124e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1608/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8414e-04 - accuracy: 0.0019 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1609/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0960e-04 - accuracy: 7.1279e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1610/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9498e-04 - accuracy: 1.9124e-04 - val_loss: 5.2555e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1611/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9197e-04 - accuracy: 2.1740e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1612/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.8180e-04 - accuracy: 4.7035e-04 - val_loss: 8.5772e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1613/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4018e-04 - accuracy: 0.0010 - val_loss: 9.9697e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1614/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8386e-04 - accuracy: 4.9242e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1615/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6280e-04 - accuracy: 1.0868e-04 - val_loss: 0.0024 - val_accuracy: 0.0000e+00\n",
            "Epoch 1616/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0611e-04 - accuracy: 1.9124e-04 - val_loss: 9.8754e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1617/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9548e-04 - accuracy: 3.7274e-05 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1618/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1486e-04 - accuracy: 2.7394e-04 - val_loss: 6.8824e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1619/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6437e-04 - accuracy: 2.8908e-04 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1620/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9166e-04 - accuracy: 1.9124e-04 - val_loss: 6.6288e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1621/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.7845e-04 - accuracy: 1.9124e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1622/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1353e-04 - accuracy: 3.0465e-04 - val_loss: 5.8014e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1623/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0346e-04 - accuracy: 6.7969e-04 - val_loss: 5.9006e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1624/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0368e-04 - accuracy: 3.3726e-04 - val_loss: 7.9521e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1625/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7490e-04 - accuracy: 9.7871e-05 - val_loss: 7.2021e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1626/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7285e-04 - accuracy: 5.9123e-04 - val_loss: 8.3640e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1627/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6010e-04 - accuracy: 1.0868e-04 - val_loss: 9.4278e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1628/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0545e-04 - accuracy: 1.4250e-04 - val_loss: 8.8209e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1629/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8060e-04 - accuracy: 2.0415e-04 - val_loss: 6.5582e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1630/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5695e-04 - accuracy: 4.7035e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1631/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3581e-04 - accuracy: 2.4492e-04 - val_loss: 8.6658e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1632/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9492e-04 - accuracy: 5.1545e-04 - val_loss: 6.5842e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1633/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7379e-04 - accuracy: 4.6904e-05 - val_loss: 6.6959e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1634/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6297e-04 - accuracy: 4.0918e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1635/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5784e-04 - accuracy: 2.1740e-04 - val_loss: 7.7435e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1636/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5893e-04 - accuracy: 7.6892e-05 - val_loss: 7.1256e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1637/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6395e-04 - accuracy: 5.6475e-04 - val_loss: 7.6740e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1638/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9129e-04 - accuracy: 0.0014 - val_loss: 6.8184e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1639/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9659e-04 - accuracy: 3.5434e-04 - val_loss: 7.1971e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1640/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7352e-04 - accuracy: 0.0013 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1641/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7204e-04 - accuracy: 8.2668e-04 - val_loss: 6.8618e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1642/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.8264e-04 - accuracy: 3.3726e-04 - val_loss: 7.3019e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1643/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.7828e-04 - accuracy: 4.4917e-04 - val_loss: 6.3819e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1644/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.7890e-04 - accuracy: 3.9026e-04 - val_loss: 5.9471e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1645/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2687e-04 - accuracy: 3.9026e-04 - val_loss: 6.0138e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1646/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5895e-04 - accuracy: 3.9026e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1647/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1018e-04 - accuracy: 4.7035e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1648/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9835e-04 - accuracy: 1.1972e-04 - val_loss: 8.0490e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1649/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8877e-04 - accuracy: 1.4250e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1650/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7869e-04 - accuracy: 7.6892e-05 - val_loss: 7.3569e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1651/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9505e-04 - accuracy: 1.0868e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1652/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8962e-04 - accuracy: 1.1972e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1653/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8992e-04 - accuracy: 9.7871e-05 - val_loss: 8.4456e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1654/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9035e-04 - accuracy: 0.0011 - val_loss: 6.9510e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1655/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8240e-04 - accuracy: 1.0868e-04 - val_loss: 6.8378e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1656/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5756e-04 - accuracy: 1.9124e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1657/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8920e-04 - accuracy: 4.6904e-05 - val_loss: 9.5443e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1658/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5876e-04 - accuracy: 3.2070e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1659/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1196e-04 - accuracy: 2.4492e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 1660/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0565e-04 - accuracy: 8.7082e-04 - val_loss: 6.4447e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1661/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0187e-04 - accuracy: 0.0015 - val_loss: 7.0942e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1662/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9429e-04 - accuracy: 2.8908e-04 - val_loss: 8.5405e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1663/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6258e-04 - accuracy: 2.4492e-04 - val_loss: 6.9187e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1664/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8502e-04 - accuracy: 7.8594e-04 - val_loss: 6.5131e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1665/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0083e-04 - accuracy: 2.7394e-04 - val_loss: 7.7564e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1666/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5229e-04 - accuracy: 4.0918e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1667/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8962e-04 - accuracy: 1.5427e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1668/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6922e-04 - accuracy: 4.2880e-04 - val_loss: 5.2606e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1669/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4942e-04 - accuracy: 7.4811e-04 - val_loss: 5.1713e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1670/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7293e-04 - accuracy: 1.3098e-04 - val_loss: 8.1267e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1671/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7874e-04 - accuracy: 0.0014 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1672/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1382e-04 - accuracy: 1.4250e-04 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 1673/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0821e-04 - accuracy: 3.5434e-04 - val_loss: 6.8379e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1674/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6491e-04 - accuracy: 4.4917e-04 - val_loss: 8.0890e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1675/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.5714e-04 - accuracy: 2.4492e-04 - val_loss: 6.4130e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1676/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8190e-04 - accuracy: 8.7278e-05 - val_loss: 9.2702e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1677/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8273e-04 - accuracy: 2.4492e-04 - val_loss: 7.1859e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1678/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8637e-04 - accuracy: 0.0019 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1679/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8005e-04 - accuracy: 4.0918e-04 - val_loss: 6.9380e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1680/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6304e-04 - accuracy: 7.1279e-04 - val_loss: 9.4052e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1681/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6731e-04 - accuracy: 2.7816e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1682/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.7117e-04 - accuracy: 7.6892e-05 - val_loss: 7.1291e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1683/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0703e-04 - accuracy: 3.3726e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1684/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5525e-04 - accuracy: 8.7278e-05 - val_loss: 5.9949e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1685/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7530e-04 - accuracy: 0.0010 - val_loss: 6.2884e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1686/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7486e-04 - accuracy: 1.5427e-04 - val_loss: 9.5543e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1687/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1235e-04 - accuracy: 2.1740e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1688/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4248e-04 - accuracy: 1.0868e-04 - val_loss: 8.2806e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1689/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6953e-04 - accuracy: 0.0017 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1690/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7711e-04 - accuracy: 1.8524e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1691/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8597e-04 - accuracy: 0.0014 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1692/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2736e-04 - accuracy: 8.2668e-04 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 1693/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2037e-04 - accuracy: 2.8908e-04 - val_loss: 6.4280e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1694/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.7632e-04 - accuracy: 0.0011 - val_loss: 6.6902e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1695/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.9362e-04 - accuracy: 6.1911e-04 - val_loss: 9.5354e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1696/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6209e-04 - accuracy: 3.7274e-05 - val_loss: 7.6942e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1697/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.8904e-04 - accuracy: 0.0012 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1698/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6849e-04 - accuracy: 4.9242e-04 - val_loss: 0.0022 - val_accuracy: 0.0000e+00\n",
            "Epoch 1699/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.7881e-04 - accuracy: 2.7394e-04 - val_loss: 6.7082e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1700/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3851e-04 - accuracy: 2.0415e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1701/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8145e-04 - accuracy: 4.7035e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 1702/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1264e-04 - accuracy: 5.6713e-05 - val_loss: 8.3701e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1703/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9744e-04 - accuracy: 0.0012 - val_loss: 7.0857e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1704/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7833e-04 - accuracy: 3.5434e-04 - val_loss: 5.9935e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1705/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6822e-04 - accuracy: 3.2070e-04 - val_loss: 6.7513e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1706/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7811e-04 - accuracy: 7.6892e-05 - val_loss: 5.5973e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1707/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8459e-04 - accuracy: 1.5427e-04 - val_loss: 7.9070e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1708/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6029e-04 - accuracy: 1.7862e-04 - val_loss: 7.9320e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1709/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7495e-04 - accuracy: 3.7274e-05 - val_loss: 6.6205e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1710/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7443e-04 - accuracy: 8.7278e-05 - val_loss: 8.2812e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1711/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7124e-04 - accuracy: 1.6631e-04 - val_loss: 6.0393e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1712/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7593e-04 - accuracy: 5.9123e-04 - val_loss: 6.9142e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1713/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5180e-04 - accuracy: 3.7274e-05 - val_loss: 7.7465e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1714/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4000e-04 - accuracy: 4.2880e-04 - val_loss: 7.0995e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1715/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9027e-04 - accuracy: 1.4250e-04 - val_loss: 7.6839e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1716/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1170e-04 - accuracy: 2.8908e-04 - val_loss: 6.0288e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1717/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7508e-04 - accuracy: 0.0025 - val_loss: 8.8147e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1718/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6862e-04 - accuracy: 1.4250e-04 - val_loss: 6.7716e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1719/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1517e-04 - accuracy: 0.0025 - val_loss: 7.9666e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1720/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0208e-04 - accuracy: 6.1911e-04 - val_loss: 8.4769e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1721/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7465e-04 - accuracy: 5.6713e-05 - val_loss: 6.5885e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1722/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9583e-04 - accuracy: 2.3098e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1723/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9670e-04 - accuracy: 0.0025 - val_loss: 6.0362e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1724/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6858e-04 - accuracy: 0.0010 - val_loss: 9.2770e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1725/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7512e-04 - accuracy: 5.1545e-04 - val_loss: 7.4173e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1726/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4857e-04 - accuracy: 3.0465e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1727/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0965e-04 - accuracy: 4.6904e-05 - val_loss: 6.9015e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1728/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7864e-04 - accuracy: 8.7082e-04 - val_loss: 5.8778e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1729/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5502e-04 - accuracy: 2.8908e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1730/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6867e-04 - accuracy: 2.3098e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1731/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8221e-04 - accuracy: 3.0465e-04 - val_loss: 8.0572e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1732/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9413e-04 - accuracy: 1.0868e-04 - val_loss: 7.1866e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1733/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5139e-04 - accuracy: 5.1545e-04 - val_loss: 9.8669e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1734/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0611e-04 - accuracy: 1.5427e-04 - val_loss: 5.5714e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1735/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0095e-04 - accuracy: 1.6631e-04 - val_loss: 5.8229e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1736/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5223e-04 - accuracy: 1.7862e-04 - val_loss: 9.0988e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1737/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7949e-04 - accuracy: 3.5434e-04 - val_loss: 5.6963e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1738/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6583e-04 - accuracy: 0.0025 - val_loss: 7.4782e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1739/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8761e-04 - accuracy: 3.7200e-04 - val_loss: 6.7676e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1740/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8182e-04 - accuracy: 6.1911e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1741/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7898e-04 - accuracy: 2.1740e-04 - val_loss: 7.3824e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1742/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6378e-04 - accuracy: 3.3726e-04 - val_loss: 8.3159e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1743/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.8963e-04 - accuracy: 1.5427e-04 - val_loss: 6.9241e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1744/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.0435e-04 - accuracy: 4.7035e-04 - val_loss: 5.9794e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1745/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7312e-04 - accuracy: 5.6713e-05 - val_loss: 9.7395e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1746/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6347e-04 - accuracy: 0.0010 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1747/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 3.0132e-04 - accuracy: 3.0465e-04 - val_loss: 6.3001e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1748/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8319e-04 - accuracy: 8.2668e-04 - val_loss: 6.4747e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1749/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9619e-04 - accuracy: 0.0014 - val_loss: 6.4064e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1750/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5442e-04 - accuracy: 0.0012 - val_loss: 6.4819e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1751/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7098e-04 - accuracy: 4.7035e-04 - val_loss: 6.5926e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1752/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9254e-04 - accuracy: 0.0014 - val_loss: 8.3319e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1753/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5775e-04 - accuracy: 5.1545e-04 - val_loss: 7.7549e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1754/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8713e-04 - accuracy: 4.0918e-04 - val_loss: 8.8949e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1755/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6124e-04 - accuracy: 0.0014 - val_loss: 6.3607e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1756/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3641e-04 - accuracy: 1.5427e-04 - val_loss: 6.9597e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1757/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5086e-04 - accuracy: 9.7194e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1758/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9291e-04 - accuracy: 8.7278e-05 - val_loss: 9.1957e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1759/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5069e-04 - accuracy: 6.1911e-04 - val_loss: 7.0381e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1760/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7028e-04 - accuracy: 1.5427e-04 - val_loss: 6.4105e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1761/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0209e-04 - accuracy: 6.6707e-05 - val_loss: 6.5053e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1762/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0502e-04 - accuracy: 8.7082e-04 - val_loss: 8.5288e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1763/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7401e-04 - accuracy: 2.4492e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1764/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7579e-04 - accuracy: 1.0868e-04 - val_loss: 8.4968e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1765/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8991e-04 - accuracy: 0.0015 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1766/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8142e-04 - accuracy: 2.8908e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1767/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6862e-04 - accuracy: 0.0014 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1768/2000\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 3.2499e-04 - accuracy: 1.0868e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1769/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9580e-04 - accuracy: 0.0012 - val_loss: 6.8105e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1770/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7483e-04 - accuracy: 3.5434e-04 - val_loss: 7.6566e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1771/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.5750e-04 - accuracy: 2.0415e-04 - val_loss: 6.3482e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1772/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4038e-04 - accuracy: 0.0015 - val_loss: 8.2663e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1773/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6040e-04 - accuracy: 6.7969e-04 - val_loss: 7.1149e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1774/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8034e-04 - accuracy: 1.9124e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1775/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9335e-04 - accuracy: 3.5434e-04 - val_loss: 0.0032 - val_accuracy: 0.0000e+00\n",
            "Epoch 1776/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.3999e-04 - accuracy: 0.0017 - val_loss: 7.6531e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1777/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2091e-04 - accuracy: 5.9123e-04 - val_loss: 6.1182e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1778/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1855e-04 - accuracy: 7.6892e-05 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1779/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8537e-04 - accuracy: 1.1972e-04 - val_loss: 6.8440e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1780/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4800e-04 - accuracy: 5.6713e-05 - val_loss: 7.6416e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1781/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8808e-04 - accuracy: 4.4917e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1782/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.4152e-04 - accuracy: 1.1972e-04 - val_loss: 7.2529e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1783/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5668e-04 - accuracy: 2.5923e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1784/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6184e-04 - accuracy: 3.7274e-05 - val_loss: 8.7062e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1785/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5658e-04 - accuracy: 1.7862e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1786/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9901e-04 - accuracy: 3.7274e-05 - val_loss: 6.5880e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1787/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6329e-04 - accuracy: 9.1897e-04 - val_loss: 6.9346e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1788/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5523e-04 - accuracy: 1.5427e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1789/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2032e-04 - accuracy: 1.0868e-04 - val_loss: 6.4218e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1790/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6555e-04 - accuracy: 7.6892e-05 - val_loss: 7.2553e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1791/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5233e-04 - accuracy: 8.7082e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1792/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6591e-04 - accuracy: 2.4492e-04 - val_loss: 6.7925e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1793/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.4389e-04 - accuracy: 0.0014 - val_loss: 6.4710e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1794/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3516e-04 - accuracy: 4.2880e-04 - val_loss: 6.7458e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1795/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6018e-04 - accuracy: 2.3098e-04 - val_loss: 7.5172e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1796/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7018e-04 - accuracy: 2.4492e-04 - val_loss: 7.6342e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1797/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6385e-04 - accuracy: 1.8524e-05 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1798/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4579e-04 - accuracy: 7.1279e-04 - val_loss: 8.3153e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1799/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5652e-04 - accuracy: 0.0025 - val_loss: 9.4642e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1800/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6668e-04 - accuracy: 0.0015 - val_loss: 7.5331e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1801/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6345e-04 - accuracy: 1.0868e-04 - val_loss: 6.7765e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1802/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6986e-04 - accuracy: 7.6892e-05 - val_loss: 9.6153e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1803/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8090e-04 - accuracy: 3.7200e-04 - val_loss: 6.6506e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1804/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5519e-04 - accuracy: 6.4853e-04 - val_loss: 9.6435e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1805/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9284e-04 - accuracy: 0.0013 - val_loss: 6.4649e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1806/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6402e-04 - accuracy: 1.4250e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1807/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5288e-04 - accuracy: 1.3098e-04 - val_loss: 8.0866e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1808/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7127e-04 - accuracy: 4.7035e-04 - val_loss: 8.0144e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1809/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7370e-04 - accuracy: 2.8908e-04 - val_loss: 8.2516e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1810/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5220e-04 - accuracy: 0.0012 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1811/2000\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 2.8464e-04 - accuracy: 0.0015 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1812/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8328e-04 - accuracy: 9.7871e-05 - val_loss: 6.7089e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1813/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7336e-04 - accuracy: 5.1545e-04 - val_loss: 6.8827e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1814/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4850e-04 - accuracy: 1.4250e-04 - val_loss: 5.7235e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1815/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8192e-04 - accuracy: 3.7200e-04 - val_loss: 6.8865e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1816/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4917e-04 - accuracy: 1.0868e-04 - val_loss: 8.0507e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1817/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.1342e-04 - accuracy: 5.9123e-04 - val_loss: 9.2723e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1818/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3256e-04 - accuracy: 0.0011 - val_loss: 9.6192e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1819/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.4951e-04 - accuracy: 0.0013 - val_loss: 6.9636e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1820/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5516e-04 - accuracy: 4.2880e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1821/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7105e-04 - accuracy: 0.0019 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1822/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6503e-04 - accuracy: 5.1545e-04 - val_loss: 7.4813e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1823/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7870e-04 - accuracy: 5.1545e-04 - val_loss: 8.0094e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1824/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4946e-04 - accuracy: 7.1279e-04 - val_loss: 5.7384e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1825/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4302e-04 - accuracy: 5.3953e-04 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 1826/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.1320e-04 - accuracy: 2.4492e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1827/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6421e-04 - accuracy: 3.7274e-05 - val_loss: 8.3049e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1828/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5145e-04 - accuracy: 2.5923e-04 - val_loss: 5.7533e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1829/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7949e-04 - accuracy: 4.0918e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1830/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9780e-04 - accuracy: 4.6904e-05 - val_loss: 6.2716e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1831/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7948e-04 - accuracy: 6.7969e-04 - val_loss: 6.7707e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1832/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6743e-04 - accuracy: 0.0019 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1833/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5740e-04 - accuracy: 0.0012 - val_loss: 6.1278e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1834/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9477e-04 - accuracy: 0.0015 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1835/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8646e-04 - accuracy: 2.0415e-04 - val_loss: 7.9718e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1836/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7290e-04 - accuracy: 4.4917e-04 - val_loss: 6.0238e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1837/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5930e-04 - accuracy: 2.0415e-04 - val_loss: 8.6800e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1838/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.6323e-04 - accuracy: 8.7278e-05 - val_loss: 7.2934e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1839/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6292e-04 - accuracy: 5.6713e-05 - val_loss: 6.2627e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1840/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6730e-04 - accuracy: 4.4917e-04 - val_loss: 6.3200e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1841/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5826e-04 - accuracy: 2.1740e-04 - val_loss: 6.8534e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1842/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3308e-04 - accuracy: 1.6631e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1843/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4172e-04 - accuracy: 6.6707e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1844/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.1168e-04 - accuracy: 3.2070e-04 - val_loss: 0.0025 - val_accuracy: 0.0000e+00\n",
            "Epoch 1845/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9892e-04 - accuracy: 3.0465e-04 - val_loss: 6.6153e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1846/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3883e-04 - accuracy: 2.7394e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1847/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4159e-04 - accuracy: 1.6631e-04 - val_loss: 8.6172e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1848/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5072e-04 - accuracy: 5.1545e-04 - val_loss: 7.0089e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1849/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6293e-04 - accuracy: 4.9242e-04 - val_loss: 8.4291e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1850/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7909e-04 - accuracy: 1.4250e-04 - val_loss: 6.5544e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1851/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4766e-04 - accuracy: 1.8524e-05 - val_loss: 6.0130e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1852/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3415e-04 - accuracy: 8.2668e-04 - val_loss: 7.5632e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1853/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6826e-04 - accuracy: 0.0017 - val_loss: 8.6567e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1854/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3425e-04 - accuracy: 0.0010 - val_loss: 9.9785e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1855/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.0990e-04 - accuracy: 8.7278e-05 - val_loss: 5.2974e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1856/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.6121e-04 - accuracy: 4.4917e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1857/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7974e-04 - accuracy: 6.7969e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1858/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5141e-04 - accuracy: 2.7816e-05 - val_loss: 9.0637e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1859/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4426e-04 - accuracy: 1.1972e-04 - val_loss: 5.6567e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1860/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6087e-04 - accuracy: 0.0010 - val_loss: 6.0816e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1861/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5107e-04 - accuracy: 6.7969e-04 - val_loss: 6.7792e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1862/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4522e-04 - accuracy: 3.7274e-05 - val_loss: 8.7595e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1863/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6337e-04 - accuracy: 0.0019 - val_loss: 9.1484e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1864/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7125e-04 - accuracy: 1.6631e-04 - val_loss: 6.2044e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1865/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4943e-04 - accuracy: 0.0019 - val_loss: 7.7003e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1866/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3944e-04 - accuracy: 2.7816e-05 - val_loss: 9.3111e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1867/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7036e-04 - accuracy: 0.0025 - val_loss: 7.2280e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1868/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5889e-04 - accuracy: 5.6475e-04 - val_loss: 9.5614e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1869/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6893e-04 - accuracy: 3.0465e-04 - val_loss: 6.6629e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1870/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2984e-04 - accuracy: 6.6707e-05 - val_loss: 6.5674e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1871/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5194e-04 - accuracy: 1.9124e-04 - val_loss: 5.8988e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1872/2000\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.5368e-04 - accuracy: 6.7969e-04 - val_loss: 7.5778e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1873/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6226e-04 - accuracy: 7.6892e-05 - val_loss: 6.2532e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1874/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7946e-04 - accuracy: 7.6892e-05 - val_loss: 9.0914e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1875/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5736e-04 - accuracy: 2.7816e-05 - val_loss: 7.6846e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1876/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.5898e-04 - accuracy: 4.6904e-05 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1877/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5821e-04 - accuracy: 3.7200e-04 - val_loss: 9.7020e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1878/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8997e-04 - accuracy: 3.7200e-04 - val_loss: 9.9323e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1879/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4160e-04 - accuracy: 2.4492e-04 - val_loss: 7.5858e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1880/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3466e-04 - accuracy: 5.6475e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1881/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.6126e-04 - accuracy: 4.4917e-04 - val_loss: 8.6196e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1882/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9175e-04 - accuracy: 0.0013 - val_loss: 7.6780e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1883/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4294e-04 - accuracy: 0.0010 - val_loss: 6.3491e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1884/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3437e-04 - accuracy: 3.5434e-04 - val_loss: 6.1807e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1885/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5187e-04 - accuracy: 6.1911e-04 - val_loss: 6.1865e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1886/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4885e-04 - accuracy: 2.7394e-04 - val_loss: 9.1875e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1887/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4626e-04 - accuracy: 6.1911e-04 - val_loss: 7.1931e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1888/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4614e-04 - accuracy: 0.0025 - val_loss: 6.4164e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1889/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4380e-04 - accuracy: 2.7394e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1890/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6727e-04 - accuracy: 8.7082e-04 - val_loss: 6.2474e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1891/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3221e-04 - accuracy: 6.7969e-04 - val_loss: 7.3722e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1892/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8465e-04 - accuracy: 3.0465e-04 - val_loss: 7.8021e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1893/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8295e-04 - accuracy: 1.7862e-04 - val_loss: 6.2856e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1894/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7471e-04 - accuracy: 9.1897e-04 - val_loss: 6.9213e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1895/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3712e-04 - accuracy: 7.8594e-04 - val_loss: 9.1918e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1896/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7066e-04 - accuracy: 1.9124e-04 - val_loss: 8.7874e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1897/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3966e-04 - accuracy: 2.4492e-04 - val_loss: 6.0832e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1898/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3597e-04 - accuracy: 5.9123e-04 - val_loss: 5.4027e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1899/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8033e-04 - accuracy: 8.7082e-04 - val_loss: 6.4562e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1900/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6416e-04 - accuracy: 5.6475e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1901/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7880e-04 - accuracy: 5.3953e-04 - val_loss: 5.5122e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1902/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0650e-04 - accuracy: 5.9123e-04 - val_loss: 5.8678e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1903/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6359e-04 - accuracy: 1.6631e-04 - val_loss: 8.3869e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1904/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2630e-04 - accuracy: 0.0015 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1905/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7477e-04 - accuracy: 7.6892e-05 - val_loss: 8.3276e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1906/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6159e-04 - accuracy: 5.6475e-04 - val_loss: 8.8265e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1907/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.2903e-04 - accuracy: 0.0012 - val_loss: 5.2716e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1908/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.6769e-04 - accuracy: 5.1545e-04 - val_loss: 5.9577e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1909/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.7303e-04 - accuracy: 1.1972e-04 - val_loss: 5.4409e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1910/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4064e-04 - accuracy: 0.0019 - val_loss: 6.4380e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1911/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3468e-04 - accuracy: 1.5427e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1912/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7892e-04 - accuracy: 2.0415e-04 - val_loss: 5.5368e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1913/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.0422e-04 - accuracy: 9.1897e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1914/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 3.2843e-04 - accuracy: 5.9123e-04 - val_loss: 7.0149e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1915/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9331e-04 - accuracy: 6.1911e-04 - val_loss: 6.6248e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1916/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2728e-04 - accuracy: 6.7969e-04 - val_loss: 7.2064e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1917/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.9072e-04 - accuracy: 2.8908e-04 - val_loss: 7.2849e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1918/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3137e-04 - accuracy: 7.4811e-04 - val_loss: 6.9083e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1919/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5980e-04 - accuracy: 5.1545e-04 - val_loss: 7.4030e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1920/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3191e-04 - accuracy: 8.2668e-04 - val_loss: 6.9846e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1921/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4571e-04 - accuracy: 5.6475e-04 - val_loss: 9.2779e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1922/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7030e-04 - accuracy: 6.7969e-04 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 1923/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5258e-04 - accuracy: 1.3098e-04 - val_loss: 9.6251e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1924/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8638e-04 - accuracy: 0.0025 - val_loss: 6.9501e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1925/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5620e-04 - accuracy: 1.1972e-04 - val_loss: 5.9460e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1926/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3963e-04 - accuracy: 3.9026e-04 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 1927/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5348e-04 - accuracy: 3.3726e-04 - val_loss: 7.9181e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1928/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.5434e-04 - accuracy: 3.2070e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1929/2000\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.9572e-04 - accuracy: 3.9026e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1930/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 3.2495e-04 - accuracy: 8.2668e-04 - val_loss: 7.2586e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1931/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9894e-04 - accuracy: 2.4492e-04 - val_loss: 5.0650e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1932/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5100e-04 - accuracy: 8.7082e-04 - val_loss: 6.5387e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1933/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3489e-04 - accuracy: 3.0465e-04 - val_loss: 6.9122e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1934/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5535e-04 - accuracy: 1.3098e-04 - val_loss: 6.9411e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1935/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.1990e-04 - accuracy: 1.6631e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1936/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8812e-04 - accuracy: 8.7082e-04 - val_loss: 8.5098e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1937/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2905e-04 - accuracy: 7.4811e-04 - val_loss: 7.6625e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1938/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3808e-04 - accuracy: 5.6713e-05 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1939/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4759e-04 - accuracy: 9.7871e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1940/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9058e-04 - accuracy: 3.7274e-05 - val_loss: 5.6897e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1941/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5212e-04 - accuracy: 0.0025 - val_loss: 9.6116e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1942/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2646e-04 - accuracy: 4.2880e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 1943/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3632e-04 - accuracy: 6.6707e-05 - val_loss: 8.3516e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1944/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.7840e-04 - accuracy: 3.3726e-04 - val_loss: 8.1883e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1945/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6773e-04 - accuracy: 5.9123e-04 - val_loss: 8.8891e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1946/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5184e-04 - accuracy: 0.0012 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1947/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.9386e-04 - accuracy: 1.4250e-04 - val_loss: 5.8198e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1948/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2138e-04 - accuracy: 5.1545e-04 - val_loss: 7.4713e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1949/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7747e-04 - accuracy: 4.6904e-05 - val_loss: 6.4880e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1950/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2521e-04 - accuracy: 1.6631e-04 - val_loss: 5.4309e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1951/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5678e-04 - accuracy: 8.7278e-05 - val_loss: 8.5935e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1952/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.3643e-04 - accuracy: 4.0918e-04 - val_loss: 7.1062e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1953/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5862e-04 - accuracy: 4.0918e-04 - val_loss: 8.9639e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1954/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3362e-04 - accuracy: 7.1279e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1955/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5303e-04 - accuracy: 3.0465e-04 - val_loss: 0.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 1956/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6254e-04 - accuracy: 7.6892e-05 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 1957/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5377e-04 - accuracy: 0.0017 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 1958/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4967e-04 - accuracy: 0.0010 - val_loss: 8.7383e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1959/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6116e-04 - accuracy: 3.0465e-04 - val_loss: 6.2567e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1960/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4646e-04 - accuracy: 4.9242e-04 - val_loss: 5.5314e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1961/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.4763e-04 - accuracy: 5.9123e-04 - val_loss: 6.6050e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1962/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.4860e-04 - accuracy: 3.9026e-04 - val_loss: 9.7831e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1963/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5818e-04 - accuracy: 4.0918e-04 - val_loss: 5.7737e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1964/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3893e-04 - accuracy: 3.7274e-05 - val_loss: 6.9733e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1965/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8184e-04 - accuracy: 2.7816e-05 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1966/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4929e-04 - accuracy: 8.7278e-05 - val_loss: 5.1964e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1967/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5809e-04 - accuracy: 0.0010 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 1968/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5457e-04 - accuracy: 7.4811e-04 - val_loss: 5.8047e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1969/2000\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 2.6318e-04 - accuracy: 3.0465e-04 - val_loss: 8.0817e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1970/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4823e-04 - accuracy: 1.0868e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1971/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6827e-04 - accuracy: 9.1897e-04 - val_loss: 7.4571e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1972/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.7509e-04 - accuracy: 6.4853e-04 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 1973/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8255e-04 - accuracy: 9.1897e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 1974/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4259e-04 - accuracy: 6.7969e-04 - val_loss: 7.0328e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1975/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5555e-04 - accuracy: 0.0025 - val_loss: 6.1715e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1976/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5106e-04 - accuracy: 4.6904e-05 - val_loss: 5.9055e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1977/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5654e-04 - accuracy: 5.6713e-05 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1978/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.4833e-04 - accuracy: 2.8908e-04 - val_loss: 6.4714e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1979/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8656e-04 - accuracy: 1.6631e-04 - val_loss: 6.3931e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1980/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.2202e-04 - accuracy: 1.9124e-04 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 1981/2000\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 2.5770e-04 - accuracy: 3.3726e-04 - val_loss: 0.0026 - val_accuracy: 0.0000e+00\n",
            "Epoch 1982/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.7055e-04 - accuracy: 3.3726e-04 - val_loss: 5.8999e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1983/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6549e-04 - accuracy: 2.7816e-05 - val_loss: 6.0986e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1984/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5416e-04 - accuracy: 2.1740e-04 - val_loss: 6.1349e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1985/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5471e-04 - accuracy: 2.1740e-04 - val_loss: 9.6048e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1986/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3018e-04 - accuracy: 4.9242e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1987/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.0576e-04 - accuracy: 5.9123e-04 - val_loss: 7.5963e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1988/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4934e-04 - accuracy: 4.0918e-04 - val_loss: 0.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 1989/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.5457e-04 - accuracy: 3.0465e-04 - val_loss: 8.2251e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1990/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4439e-04 - accuracy: 8.7278e-05 - val_loss: 5.6813e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1991/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.4347e-04 - accuracy: 5.1545e-04 - val_loss: 9.4508e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1992/2000\n",
            "58/58 [==============================] - 1s 8ms/step - loss: 2.5351e-04 - accuracy: 8.7082e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 1993/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.6407e-04 - accuracy: 3.2070e-04 - val_loss: 4.7301e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1994/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3579e-04 - accuracy: 4.4917e-04 - val_loss: 6.1551e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1995/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.3537e-04 - accuracy: 5.6713e-05 - val_loss: 7.3499e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1996/2000\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 2.8904e-04 - accuracy: 5.9123e-04 - val_loss: 9.2209e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1997/2000\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 2.6299e-04 - accuracy: 0.0017 - val_loss: 5.2424e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1998/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5509e-04 - accuracy: 8.7082e-04 - val_loss: 7.5989e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 1999/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.5107e-04 - accuracy: 1.6631e-04 - val_loss: 0.0012 - val_accuracy: 0.0000e+00\n",
            "Epoch 2000/2000\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 2.8781e-04 - accuracy: 1.0868e-04 - val_loss: 7.6512e-04 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRN_3BGCaMK9"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "XIsvI4vzaMNs",
        "outputId": "f4e747c6-e40f-455a-ecec-4e0c27adf3c2"
      },
      "source": [
        "plt.title('model loss')\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.ylim(0,None)\r\n",
        "plt.legend(['train', 'test'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "predictions = model.predict(testX.tolist())\r\n",
        "\r\n",
        "plt.title('Comparison true values and predicted values')\r\n",
        "plt.plot(Dates.tolist(), predictions, label='predicted values')\r\n",
        "plt.plot(Dates.tolist(), Y_test.tolist(), label='true values')\r\n",
        "plt.plot(Dates.tolist(), Open_test.tolist(), label='Opening values')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('date')\r\n",
        "plt.ylabel('closeing price')\r\n",
        "plt.gca().set_xticks(Dates[::20])\r\n",
        "plt.gca().set_xticklabels(Dates[::20], rotation=30)\r\n",
        "plt.show()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B26v_UTQLTgV",
        "outputId": "26d29b43-6d0f-4e58-e0ea-7117986e14e1"
      },
      "source": [
        "np.min(history.history['loss'])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00022265323786996305"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89aiXnJNaMV6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "c472d1a2-dc55-49da-c176-ae5769a94d97"
      },
      "source": [
        "print(np.sum(np.power(Y_test.tolist() - predictions,2)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b94c3473cba7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKI68JCXU2LH"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZnyDN4hb3g2"
      },
      "source": [
        "\r\n",
        "model = Sequential(name=\"simple lstm\")\r\n",
        "model.add(Embedding(input_dim=187, output_dim=64))\r\n",
        "model.add(LSTM(128))\r\n",
        "model.add(Dense(1))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k9sUdH0kH3l"
      },
      "source": [
        "#history = model.fit(data[\"X_train\"], data[\"y_train\"],\r\n",
        " #                   batch_size=BATCH_SIZE,\r\n",
        "  #                  epochs=EPOCHS,\r\n",
        "   #                 validation_data=(data[\"X_test\"], data[\"y_test\"]),\r\n",
        "    #                callbacks=[checkpointer, tensorboard],\r\n",
        "     #               verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTDMrMsJb3kZ"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "              optimizer=tf.keras.optimizers.Adam(0.00001),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLwB5RISb3m-"
      },
      "source": [
        "history = model.fit(X_train.values.tolist(), Y_train.values.tolist(), epochs=20, validation_data=(X_test.values.tolist(), Y_test.values.tolist()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi1jVfTEb3qV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRgbiWEvb3t4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvTVrCXeb3w2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02mGitxZb3zo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y4AOOudKEbw"
      },
      "source": [
        "# In the two cells below we importing the library nltk and through it we convert the news to numerical value between 1 to -1 according to how much is good or bad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PPyrouheS8-"
      },
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sna = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwmeA59bWJji"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6lqrVeDWJoN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKw55Q6YWJrg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgTom4oVeTCb"
      },
      "source": [
        "df_Combined2 = df_Combined.copy()\n",
        "for i in range(0, df_Combined2.shape[0]):\n",
        "  # News_Date_array = df_RedditNews[df_RedditNews[\"Date\"] == df_Combined2[\"Date\"][i]][\"News\"].to_numpy()\n",
        "\n",
        "  for j in range(0, 25):\n",
        "    df_Combined2[\"Top\"+str(j+1)][i] = sna.polarity_scores(df_Combined2[\"Top\"+str(j+1)][i])[\"compound\"]\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQpHpkCMLcRb"
      },
      "source": [
        "# In the cell below we divide the data to training, testing, x and y. for the learning processes\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_nos3er2mkS"
      },
      "source": [
        "df_final = df_Combined2.drop(['Date', 'High', 'Low', 'Volume', 'Adj Close'], axis=1)\n",
        "X_df = df_final.drop(['Close'], axis=1)\n",
        "Y_df = df_final['Close']\n",
        "rowsSize = X_df.shape[0]\n",
        "test_size = 0.2\n",
        "train_rowsSize = rowsSize*(1-test_size)\n",
        "test_rowsSize = rowsSize*test_size\n",
        "x_train, x_test, y_train, y_test = (X_df.tail(int(train_rowsSize)), X_df.head(int(test_rowsSize)), Y_df.tail(int(train_rowsSize)), Y_df.head(int(test_rowsSize)))\n",
        "data_x_train = x_train.copy()\n",
        "data_y_train = np.array(y_train.copy(), ndmin=2).reshape((y_train.shape[0], 1))\n",
        "data_x_test = x_test.copy()\n",
        "data_y_test = np.array(y_test.copy(), ndmin=2).reshape((y_test.shape[0], 1))\n",
        "data_test_dates = np.flip(df_Combined2['Date'].head(int(test_rowsSize)).tail(int(test_rowsSize)))\n",
        "opening_price_test = data_x_test.copy()['Open']\n",
        "features = x_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvw8LWYxQWNN"
      },
      "source": [
        "# In the cell below we importing the libraries that creating ours models, visualize ours results and displaying the time it took to train the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQffrPhz3ZRU"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()  \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQSWyNGAS3le"
      },
      "source": [
        "# In the cells below we:\r\n",
        "# 1) prepering our linear-regresion model\r\n",
        "# 2) training our linear-regresion model\r\n",
        "# 3) displaying the mean squared error progress graph\r\n",
        "# 4) displaying the results of our linear-regresion model with the real testing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogkI0cqtbTwV"
      },
      "source": [
        "start_time = time.time()\n",
        "x = tf.placeholder(tf.float32, [None, features])\n",
        "y_ = tf.placeholder(tf.float32, [None, 1])\n",
        "W = tf.Variable(tf.zeros([features,1]))\n",
        "b = tf.Variable(tf.zeros([1]))\n",
        "y = tf.matmul(x,W) + b\n",
        "loss = tf.reduce_mean(tf.pow(y - y_, 2))\n",
        "update = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS2V83Y9bTy3"
      },
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "i = 0\n",
        "minLoss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\n",
        "print('iter:', i,', loss:', minLoss)\n",
        "for _ in range(3000):\n",
        "    i += 1\n",
        "    sess.run(update, feed_dict = {x:data_x_train, y_:data_y_train})\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\n",
        "    train_losses.append(temp_loss)\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\n",
        "    test_losses.append(temp_loss)\n",
        "    print('iter:', i,', loss:', temp_loss)\n",
        "    if ((i % 10 == 0) & (temp_loss < minLoss)):\n",
        "      minLoss = temp_loss\n",
        "      saver.save(sess, \"gdrive/My Drive/Deep learning poj/LR.ckpt\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dat1eNqD38l6"
      },
      "source": [
        " print(\"linear regrression training time:' %s seconds \" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tSr4Qj6vNyG"
      },
      "source": [
        "iter = np.arange(1,len(test_losses)+1)\n",
        "plt.title('Linear Regresion Mean Squerd Error minimization')\n",
        "plt.plot(iter, test_losses, label='Testing loss')\n",
        "plt.plot(iter, train_losses, label='Training loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Mean Squerd Error')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClVf6nHvN15"
      },
      "source": [
        "# https://stackoverflow.com/questions/50128668/how-to-adjust-tick-frequency-for-string-x-axis\r\n",
        "saver.restore(sess, \"gdrive/My Drive/Deep learning poj/LR.ckpt\")\r\n",
        "predicted_values = sess.run(y, feed_dict = {x: data_x_test})\r\n",
        "plt.title('Comparison true values and predicted values')\r\n",
        "plt.plot(data_test_dates, predicted_values, label='predicted values')\r\n",
        "plt.plot(data_test_dates, data_y_test, label='true values')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('date')\r\n",
        "plt.ylabel('closeing price')\r\n",
        "plt.gca().set_xticks(data_test_dates[::100])\r\n",
        "plt.gca().set_xticklabels(data_test_dates[::100], rotation=45)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrIp1mXffw_x"
      },
      "source": [
        "# In the cells below we:\r\n",
        "# 1) prepering neural network with 1 hidden layer\r\n",
        "# 2) show how we training the model\r\n",
        "# 3) displaying the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5vzlppZRKzV"
      },
      "source": [
        "start_time = time.time()\n",
        "step_size = 0.1\n",
        "(hidden1_size, hidden2_size) = (300, 1)\n",
        "\n",
        "minVal=-0.0001\n",
        "maxVal=0.0001\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[None, features])\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
        "\n",
        "W1 = tf.Variable(tf.random.uniform(shape=[features, hidden1_size], minval=minVal, maxval=maxVal))\n",
        "b1 = tf.Variable(tf.random.uniform(shape=[hidden1_size], minval=minVal, maxval=maxVal))\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
        "\n",
        "W2 = tf.Variable(tf.random.uniform([hidden1_size, hidden2_size], minval=minVal, maxval=maxVal))\n",
        "b2 = tf.Variable(tf.random.uniform(shape=[hidden2_size], minval=minVal, maxval=maxVal))\n",
        "\n",
        "predict = tf.matmul(z1,W2) + b2\n",
        "\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "sess.run(init)\n",
        "i = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T08q2k1D_ZN"
      },
      "source": [
        "while (True):\r\n",
        "  for _ in range(2):\r\n",
        "    for _ in range(10):\r\n",
        "      sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "  \r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "    train_losses.append(temp_loss)\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\r\n",
        "    test_losses.append(temp_loss)\r\n",
        "    print('iter:', i+1,', loss:', temp_loss)\r\n",
        "    i += 1\r\n",
        "    if (i % 10 == 0):\r\n",
        "      minLoss = temp_loss\r\n",
        "      tf.train.Saver().save(sess, \"gdrive/My Drive/Deep learning poj/NN 1 hidden layer.ckpt\") \r\n",
        "  if (test_losses[-2] - test_losses[-1] < 0):\r\n",
        "    break\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GEccefEBxYN"
      },
      "source": [
        "step_size = 0.05\r\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\r\n",
        "minLoss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "while (True):\r\n",
        "  for _ in range(3):\r\n",
        "    for _ in range(10):\r\n",
        "      sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "    train_losses.append(temp_loss)\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\r\n",
        "    test_losses.append(temp_loss)\r\n",
        "    i += 1\r\n",
        "    print('iter:', i,', loss:', temp_loss)\r\n",
        "    if (i % 10 == 0):\r\n",
        "      minLoss = temp_loss\r\n",
        "      tf.train.Saver().save(sess, \"gdrive/My Drive/Deep learning poj/NN 1 hidden layer.ckpt\") \r\n",
        "  if ((test_losses[-2] - test_losses[-1] < 0) & (test_losses[-3] - test_losses[-2] < 0)):\r\n",
        "    break\r\n",
        "\r\n",
        "print(\"get to model :nuriel network training :' %s seconds \"  % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr__jRbdMe0u"
      },
      "source": [
        "iter = np.arange(1,len(test_losses)+1)\n",
        "plt.title('Neural Network loss error minimization')\n",
        "plt.plot(iter, test_losses, label='Testing loss')\n",
        "plt.plot(iter, train_losses, label='Training loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Number of iterations')\n",
        "plt.ylabel('Mean Squerd Error')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0uQG8nzLzN_"
      },
      "source": [
        "# https://stackoverflow.com/questions/50128668/how-to-adjust-tick-frequency-for-string-x-axis\r\n",
        "saver.restore(sess, \"gdrive/My Drive/Deep learning poj/NN 1 hidden layer.ckpt\") \r\n",
        "predicted_values = sess.run(predict, feed_dict = {x: data_x_test})\r\n",
        "plt.title('Comparison true values and predicted values')\r\n",
        "plt.plot(data_test_dates, predicted_values, label='predicted values')\r\n",
        "plt.plot(data_test_dates, data_y_test, label='true values')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('date')\r\n",
        "plt.ylabel('closeing price')\r\n",
        "plt.gca().set_xticks(data_test_dates[::100])\r\n",
        "plt.gca().set_xticklabels(data_test_dates[::100], rotation=45)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0MNFYyBjk-_"
      },
      "source": [
        "# In the cells below we:\r\n",
        "# 1) prepering neural network with 2 hidden layer\r\n",
        "# 2) show how we training the model\r\n",
        "# 3) displaying the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7LUdaITxUxm"
      },
      "source": [
        "step_size = 0.1\r\n",
        "(hidden1_size, hidden2_size) = (300, 1)\r\n",
        "\r\n",
        "minVal=-0.0001\r\n",
        "maxVal=0.0001\r\n",
        "\r\n",
        "x = tf.placeholder(tf.float32, shape=[None, features])\r\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1])\r\n",
        "W1 = tf.Variable(tf.random.uniform(shape=[features, hidden1_size], minval=minVal, maxval=maxVal))\r\n",
        "b1 = tf.Variable(tf.random.uniform(shape=[hidden1_size], minval=minVal, maxval=maxVal))\r\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\r\n",
        "\r\n",
        "W2 = tf.Variable(tf.random.uniform([hidden1_size, hidden2_size], minval=minVal, maxval=maxVal))\r\n",
        "b2 = tf.Variable(tf.random.uniform(shape=[hidden2_size], minval=minVal, maxval=maxVal))\r\n",
        "\r\n",
        "predict = tf.matmul(z1,W2) + b2\r\n",
        "\r\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\r\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\r\n",
        "sess = tf.Session()\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "sess.run(init)\r\n",
        "\r\n",
        "saver.restore(sess, \"gdrive/My Drive/Deep learning poj/NN 1 hidden layer.ckpt\")\r\n",
        "weights = sess.run(W1)\r\n",
        "baieses = sess.run(b1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_gom9OHjbBS"
      },
      "source": [
        "step_size = 0.2\r\n",
        "(hidden1_size, hidden2_size, hidden3_size) = (300, 100, 1)\r\n",
        "\r\n",
        "minVal=-0.0001\r\n",
        "maxVal=0.0001\r\n",
        "minVal2=-0.1\r\n",
        "maxVal2=0.1\r\n",
        "\r\n",
        "x = tf.placeholder(tf.float32, shape=[None, features])\r\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1])\r\n",
        "\r\n",
        "W1 = tf.Variable(weights)\r\n",
        "b1 = tf.Variable(baieses)\r\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\r\n",
        "\r\n",
        "W2 = tf.Variable(tf.random.uniform([hidden1_size, hidden2_size], minval=minVal2, maxval=maxVal2))\r\n",
        "b2 = tf.Variable(tf.random.uniform(shape=[hidden2_size], minval=minVal2, maxval=maxVal2))\r\n",
        "z2 = tf.nn.relu(tf.matmul(z1,W2)+b2)\r\n",
        "\r\n",
        "W3 = tf.Variable(tf.random.uniform([hidden2_size, hidden3_size], minval=minVal2, maxval=maxVal2))\r\n",
        "b3 = tf.Variable(tf.random.uniform(shape=[hidden3_size], minval=minVal2, maxval=maxVal2))\r\n",
        "predict = tf.matmul(z2,W3) + b3\r\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\r\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\r\n",
        "\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "sess = tf.Session()\r\n",
        "train_losses = []\r\n",
        "test_losses = []\r\n",
        "sess.run(init)\r\n",
        "i = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjIxE91VEaU7"
      },
      "source": [
        "while (True):\r\n",
        "  for _ in range(2):\r\n",
        "    for _ in range(10):\r\n",
        "      sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "    train_losses.append(temp_loss)\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\r\n",
        "    test_losses.append(temp_loss)\r\n",
        "    i += 1\r\n",
        "    print('iter:', i,', loss:', temp_loss)\r\n",
        "    if (i % 10 == 0):\r\n",
        "      if (minLoss > temp_loss):\r\n",
        "        minLoss = temp_loss\r\n",
        "        tf.train.Saver().save(sess, \"gdrive/My Drive/Deep learning poj/NN 2 hidden layer.ckpt\")\r\n",
        "  if (test_losses[-2] - test_losses[-1] < 0):\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA3Lcp-_jbD_"
      },
      "source": [
        "minLoss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "step_size = 0.05\r\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\r\n",
        "# tf.train.Saver().restore(sess, \"gdrive/My Drive/Deep learning poj/NN 2 hidden layer.ckpt\")\r\n",
        "while (True):\r\n",
        "  for _ in range(3):\r\n",
        "    for _ in range(50):\r\n",
        "      sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "    train_losses.append(temp_loss)\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\r\n",
        "    test_losses.append(temp_loss)\r\n",
        "    i += 1\r\n",
        "    print('iter:', i,', loss:', temp_loss)\r\n",
        "    if (i % 10 == 0):\r\n",
        "      if (minLoss > temp_loss):\r\n",
        "        minLoss = temp_loss\r\n",
        "        tf.train.Saver().save(sess, \"gdrive/My Drive/Deep learning poj/NN 2 hidden layer.ckpt\")\r\n",
        "  if ((test_losses[-2] - test_losses[-1] < 0) & (test_losses[-3] - test_losses[-2] < 0)):\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXfB_FhVjbJP"
      },
      "source": [
        "# saver.restore(sess, \"gdrive/My Drive/Deep learning poj/NN 2 hidden layer.ckpt\") \r\n",
        "predicted_values = sess.run(predict, feed_dict = {x: data_x_test})\r\n",
        "plt.title('Comparison true values and predicted values')\r\n",
        "plt.plot(data_test_dates, predicted_values, label='predicted values')\r\n",
        "plt.plot(data_test_dates, data_y_test, label='true values')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('date')\r\n",
        "plt.ylabel('closeing price')\r\n",
        "plt.gca().set_xticks(data_test_dates[::100])\r\n",
        "plt.gca().set_xticklabels(data_test_dates[::100], rotation=30)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPCFfxBSCF0s"
      },
      "source": [
        "# In the cells below we:\r\n",
        "# 1) prepering neural network with 3 hidden layer\r\n",
        "# 2) show how we training the model\r\n",
        "# 3) displaying the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r1F9hB5jbGm"
      },
      "source": [
        "weights1 = sess.run(W1)\r\n",
        "baieses1 = sess.run(b1)\r\n",
        "weights2 = sess.run(W2)\r\n",
        "baieses2 = sess.run(b2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrAXnPDjEyzT"
      },
      "source": [
        "step_size = 0.05\r\n",
        "(hidden1_size, hidden2_size, hidden3_size, hidden4_size) = (300, 100, 10, 1)\r\n",
        "\r\n",
        "minVal=-0.1\r\n",
        "maxVal=0.1\r\n",
        "\r\n",
        "x = tf.placeholder(tf.float32, shape=[None, x_train.shape[1]])\r\n",
        "y_ = tf.placeholder(tf.float32, shape=[None, 1])\r\n",
        "\r\n",
        "W1 = tf.Variable(weights1)\r\n",
        "b1 = tf.Variable(baieses1)\r\n",
        "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\r\n",
        "\r\n",
        "W2 = tf.Variable(weights2)\r\n",
        "b2 = tf.Variable(baieses2)\r\n",
        "z2 = tf.nn.relu(tf.matmul(z1,W2)+b2)\r\n",
        "\r\n",
        "W3 = tf.Variable(tf.random.uniform([hidden2_size, hidden3_size], minval=minVal, maxval=maxVal))\r\n",
        "b3 = tf.Variable(tf.random.uniform(shape=[hidden3_size], minval=minVal, maxval=maxVal))\r\n",
        "z3 = tf.nn.relu(tf.matmul(z2,W3)+b3)\r\n",
        "\r\n",
        "W4 = tf.Variable(tf.random.uniform([hidden3_size, hidden4_size], minval=minVal, maxval=maxVal))\r\n",
        "b4 = tf.Variable(tf.random.uniform(shape=[hidden4_size], minval=minVal, maxval=maxVal))\r\n",
        "predict = tf.matmul(z3,W4) + b4\r\n",
        "\r\n",
        "loss = tf.reduce_mean(tf.pow(predict - y_, 2))\r\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\r\n",
        "\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "\r\n",
        "sess = tf.Session()\r\n",
        "train_losses = []\r\n",
        "test_losses = []\r\n",
        "sess.run(init)\r\n",
        "i = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC8zcdFPFVVJ"
      },
      "source": [
        "while (True):\r\n",
        "  for _ in range(2):\r\n",
        "    for _ in range(10):\r\n",
        "      sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "    train_losses.append(temp_loss)\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\r\n",
        "    test_losses.append(temp_loss)\r\n",
        "    i += 1\r\n",
        "    print('iter:', i,', loss:', temp_loss)\r\n",
        "    if (i % 10 == 0):\r\n",
        "      if (minLoss > temp_loss):\r\n",
        "        minLoss = temp_loss\r\n",
        "        tf.train.Saver().save(sess, \"gdrive/My Drive/Deep learning poj/NN 3 hidden layer.ckpt\")\r\n",
        "  if (test_losses[-2] - test_losses[-1] <= 0):\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4P2rLE6GFMP"
      },
      "source": [
        "step_size = 0.001\r\n",
        "train_step = tf.train.GradientDescentOptimizer(step_size).minimize(loss)\r\n",
        "while (True):\r\n",
        "  for _ in range(3):\r\n",
        "    for _ in range(50):\r\n",
        "      sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    sess.run(train_step, feed_dict={x:data_x_train, y_:data_y_train})\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_train, y_: data_y_train})\r\n",
        "    train_losses.append(temp_loss)\r\n",
        "    temp_loss = sess.run(loss, feed_dict = {x: data_x_test, y_: data_y_test})\r\n",
        "    test_losses.append(temp_loss)\r\n",
        "    i += 1\r\n",
        "    print('iter:', i,', loss:', temp_loss)\r\n",
        "    if (i % 10 == 0):\r\n",
        "      if (minLoss > temp_loss):\r\n",
        "        minLoss = temp_loss\r\n",
        "        tf.train.Saver().save(sess, \"gdrive/My Drive/Deep learning poj/NN 3 hidden layer.ckpt\")\r\n",
        "  if ((test_losses[-2] - test_losses[-1] <= 0) and (test_losses[-3] - test_losses[-2] <= 0)):\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoXEQ4bs_U4M"
      },
      "source": [
        "# saver.restore(sess, \"gdrive/My Drive/Deep learning poj/NN 3 hidden layer.ckpt\")\r\n",
        "predicted_values = sess.run(predict, feed_dict = {x: data_x_test})\r\n",
        "plt.title('Comparison true values and predicted values')\r\n",
        "plt.plot(data_test_dates, predicted_values, label='predicted values')\r\n",
        "plt.plot(data_test_dates, data_y_test, label='true values')\r\n",
        "plt.legend()\r\n",
        "plt.xlabel('date')\r\n",
        "plt.ylabel('closeing price')\r\n",
        "plt.gca().set_xticks(data_test_dates[::100])\r\n",
        "plt.gca().set_xticklabels(data_test_dates[::100], rotation=30)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i25L0WFCGcVX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1SR6WElGcYt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDRK-FTlGccS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CthA8l8Old4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5Troh4OPHT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4ISrV5EYyVq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFP2ibeIYyYm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}